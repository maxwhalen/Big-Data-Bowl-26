{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863a48da",
   "metadata": {
    "papermill": {
     "duration": 0.005926,
     "end_time": "2025-10-19T07:08:57.851287",
     "exception": false,
     "start_time": "2025-10-19T07:08:57.845361",
     "status": "completed"
    },
    "tags": []
   },
   "source": "# \ud83c\udfc8 NFL Big Data Bowl 2026 - GNN-Enhanced with TTA\n\n**Architecture:** Temporal GNN + GRU + Conv1D + Attention  \n**Baseline:** 0.609 RMSE \u2192 **Target:** 0.555-0.575 RMSE\n\n## Key Innovations\n\n### 1. Graph Neural Networks (GNN)\n- **Temporal Frame Graph**: Connects sequence frames (not players)\n- **3-Layer GAT**: Graph Attention Networks with 4 attention heads\n- **Frame Interactions**: Models how frame t-1 influences frame t\n- **Expected Impact**: -0.03 to -0.05 RMSE improvement\n\n### 2. Test-Time Augmentation (TTA)\nWe apply 3 principled augmentations that reflect real data variation:\n\n1. **None (Baseline)** - Original predictions\n2. **Temporal Shift** - Interpolate between frames (\u00b10.5 frame shift)\n3. **Velocity Jitter** - Add small Gaussian noise to velocity (\u03c3=0.05)\n\nFinal predictions are averaged across **5 models \u00d7 3 augmentations = 15 predictions** per player.\n\n**Expected Impact**: +0.5-1% improvement from TTA\n\n---\n\n## Full Pipeline\n1. 82 engineered features (physics, temporal, ball geometry)\n2. Temporal GNN processes frame interactions\n3. GRU + Conv1D + Attention for sequence modeling\n4. 5-Fold Cross-Validation with GroupKFold\n5. TTA ensemble for robust predictions\n\n**Credits:** Built on amazing Kaggle community notebooks + research papers on GNNs for trajectory prediction!\n"
  },
  {
   "cell_type": "markdown",
   "id": "09693c4c",
   "metadata": {
    "papermill": {
     "duration": 0.004595,
     "end_time": "2025-10-19T07:08:57.860834",
     "exception": false,
     "start_time": "2025-10-19T07:08:57.856239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a973b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T07:08:57.871968Z",
     "iopub.status.busy": "2025-10-19T07:08:57.871704Z",
     "iopub.status.idle": "2025-10-19T07:09:04.641572Z",
     "shell.execute_reply": "2025-10-19T07:09:04.640968Z"
    },
    "papermill": {
     "duration": 6.777561,
     "end_time": "2025-10-19T07:09:04.642947",
     "exception": false,
     "start_time": "2025-10-19T07:08:57.865386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f03c9bc",
   "metadata": {
    "papermill": {
     "duration": 0.004509,
     "end_time": "2025-10-19T07:09:04.652613",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.648104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed285fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T07:09:04.663455Z",
     "iopub.status.busy": "2025-10-19T07:09:04.662924Z",
     "iopub.status.idle": "2025-10-19T07:09:04.764056Z",
     "shell.execute_reply": "2025-10-19T07:09:04.763487Z"
    },
    "papermill": {
     "duration": 0.107588,
     "end_time": "2025-10-19T07:09:04.765112",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.657524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n",
    "    \n",
    "    SEED = 42\n",
    "    N_FOLDS = 5\n",
    "    BATCH_SIZE = 512\n",
    "    EPOCHS = 120\n",
    "    PATIENCE = 20\n",
    "    LEARNING_RATE = 5e-4\n",
    "    \n",
    "    WINDOW_SIZE = 10\n",
    "    HIDDEN_DIM = 192\n",
    "    MAX_FUTURE_HORIZON = 94\n",
    "    \n",
    "    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n",
    "    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(Config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763dc6c",
   "metadata": {
    "papermill": {
     "duration": 0.004569,
     "end_time": "2025-10-19T07:09:04.774834",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.770265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# COMBINED FEATURE ENGINEERING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37576bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T07:09:04.785510Z",
     "iopub.status.busy": "2025-10-19T07:09:04.785147Z",
     "iopub.status.idle": "2025-10-19T07:09:04.813868Z",
     "shell.execute_reply": "2025-10-19T07:09:04.813263Z"
    },
    "papermill": {
     "duration": 0.035344,
     "end_time": "2025-10-19T07:09:04.815015",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.779671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def height_to_feet(height_str):\n",
    "    try:\n",
    "        ft, inches = map(int, str(height_str).split('-'))\n",
    "        return ft + inches/12\n",
    "    except:\n",
    "        return 6.0\n",
    "\n",
    "def add_advanced_features(df):\n",
    "    \"\"\"Enhanced feature engineering from Notebook 1\"\"\"\n",
    "    print(\"Adding advanced features...\")\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    gcols = ['game_id', 'play_id', 'nfl_id']\n",
    "    \n",
    "    # Distance Rate Features\n",
    "    if 'distance_to_ball' in df.columns:\n",
    "        df['distance_to_ball_change'] = df.groupby(gcols)['distance_to_ball'].diff().fillna(0)\n",
    "        df['distance_to_ball_accel'] = df.groupby(gcols)['distance_to_ball_change'].diff().fillna(0)\n",
    "        df['time_to_intercept'] = (df['distance_to_ball'] / \n",
    "                                    (np.abs(df['distance_to_ball_change']) + 0.1)).clip(0, 10)\n",
    "    \n",
    "    # Target Alignment Features\n",
    "    if 'ball_direction_x' in df.columns:\n",
    "        df['velocity_alignment'] = (\n",
    "            df['velocity_x'] * df['ball_direction_x'] +\n",
    "            df['velocity_y'] * df['ball_direction_y']\n",
    "        )\n",
    "        df['velocity_perpendicular'] = (\n",
    "            df['velocity_x'] * (-df['ball_direction_y']) +\n",
    "            df['velocity_y'] * df['ball_direction_x']\n",
    "        )\n",
    "        if 'acceleration_x' in df.columns:\n",
    "            df['accel_alignment'] = (\n",
    "                df['acceleration_x'] * df['ball_direction_x'] +\n",
    "                df['acceleration_y'] * df['ball_direction_y']\n",
    "            )\n",
    "    \n",
    "    # Multi-Window Rolling\n",
    "    for window in [3, 5, 10]:\n",
    "        for col in ['velocity_x', 'velocity_y', 's', 'a']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_roll{window}'] = df.groupby(gcols)[col].transform(\n",
    "                    lambda x: x.rolling(window, min_periods=1).mean()\n",
    "                )\n",
    "                df[f'{col}_std{window}'] = df.groupby(gcols)[col].transform(\n",
    "                    lambda x: x.rolling(window, min_periods=1).std()\n",
    "                ).fillna(0)\n",
    "    \n",
    "    # Extended Lag Features\n",
    "    for lag in [4, 5]:\n",
    "        for col in ['x', 'y', 'velocity_x', 'velocity_y']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_lag{lag}'] = df.groupby(gcols)[col].shift(lag).fillna(0)\n",
    "    \n",
    "    # Velocity Change Features\n",
    "    if 'velocity_x' in df.columns:\n",
    "        df['velocity_x_change'] = df.groupby(gcols)['velocity_x'].diff().fillna(0)\n",
    "        df['velocity_y_change'] = df.groupby(gcols)['velocity_y'].diff().fillna(0)\n",
    "        df['speed_change'] = df.groupby(gcols)['s'].diff().fillna(0)\n",
    "        df['direction_change'] = df.groupby(gcols)['dir'].diff().fillna(0)\n",
    "        df['direction_change'] = df['direction_change'].apply(\n",
    "            lambda x: x if abs(x) < 180 else x - 360 * np.sign(x)\n",
    "        )\n",
    "    \n",
    "    # Field Position Features\n",
    "    df['dist_from_left'] = df['y']\n",
    "    df['dist_from_right'] = 53.3 - df['y']\n",
    "    df['dist_from_sideline'] = np.minimum(df['dist_from_left'], df['dist_from_right'])\n",
    "    df['dist_from_endzone'] = np.minimum(df['x'], 120 - df['x'])\n",
    "    \n",
    "    # Role-Specific Features\n",
    "    if 'is_receiver' in df.columns and 'velocity_alignment' in df.columns:\n",
    "        df['receiver_optimality'] = df['is_receiver'] * df['velocity_alignment']\n",
    "        df['receiver_deviation'] = df['is_receiver'] * np.abs(df.get('velocity_perpendicular', 0))\n",
    "    if 'is_coverage' in df.columns and 'closing_speed' in df.columns:\n",
    "        df['defender_closing_speed'] = df['is_coverage'] * df['closing_speed']\n",
    "    \n",
    "    # Time Features\n",
    "    df['frames_elapsed'] = df.groupby(gcols).cumcount()\n",
    "    df['normalized_time'] = df.groupby(gcols)['frames_elapsed'].transform(\n",
    "        lambda x: x / (x.max() + 1)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_combined_features(input_df, output_df=None, test_template=None, is_training=True, window_size=10):\n",
    "    \"\"\"COMBINED: Advanced features + enhanced preprocessing\"\"\"\n",
    "    print(f\"Preparing COMBINED sequences (window_size={window_size})...\")\n",
    "    \n",
    "    input_df = input_df.copy()\n",
    "    \n",
    "\n",
    "    # BASIC FEATURES \n",
    "\n",
    "    input_df['player_height_feet'] = input_df['player_height'].apply(height_to_feet)\n",
    "    \n",
    "    # Enhanced motion features \n",
    "    dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n",
    "    o_rad = np.deg2rad(input_df['o'].fillna(0))\n",
    "    \n",
    "    input_df['velocity_x'] = input_df['s'] * np.sin(dir_rad)\n",
    "    input_df['velocity_y'] = input_df['s'] * np.cos(dir_rad)\n",
    "    input_df['acceleration_x'] = input_df['a'] * np.sin(dir_rad)\n",
    "    input_df['acceleration_y'] = input_df['a'] * np.cos(dir_rad)\n",
    "    input_df['orientation_x'] = np.sin(o_rad)\n",
    "    input_df['orientation_y'] = np.cos(o_rad)\n",
    "    \n",
    "    # Enhanced roles\n",
    "    input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n",
    "    input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n",
    "    input_df['is_receiver'] = (input_df['player_role'] == 'Targeted Receiver').astype(int)\n",
    "    input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n",
    "    input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n",
    "    input_df['is_rusher'] = (input_df['player_role'] == 'Pass Rusher').astype(int)\n",
    "    \n",
    "    # Field position (enhanced)\n",
    "    input_df['field_x_norm'] = (input_df['x'] - Config.FIELD_X_MIN) / (Config.FIELD_X_MAX - Config.FIELD_X_MIN)\n",
    "    input_df['field_y_norm'] = (input_df['y'] - Config.FIELD_Y_MIN) / (Config.FIELD_Y_MAX - Config.FIELD_Y_MIN)\n",
    "    \n",
    "    # Physics features\n",
    "    mass_kg = input_df['player_weight'].fillna(200.0) / 2.20462\n",
    "    input_df['momentum_x'] = input_df['velocity_x'] * mass_kg\n",
    "    input_df['momentum_y'] = input_df['velocity_y'] * mass_kg\n",
    "    input_df['kinetic_energy'] = 0.5 * mass_kg * (input_df['s'] ** 2)\n",
    "    \n",
    "    # Ball features\n",
    "    if 'ball_land_x' in input_df.columns:\n",
    "        ball_dx = input_df['ball_land_x'] - input_df['x']\n",
    "        ball_dy = input_df['ball_land_y'] - input_df['y']\n",
    "        input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n",
    "        input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n",
    "        input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['closing_speed'] = (\n",
    "            input_df['velocity_x'] * input_df['ball_direction_x'] +\n",
    "            input_df['velocity_y'] * input_df['ball_direction_y']\n",
    "        )\n",
    "    \n",
    "    # Sort for temporal features\n",
    "    input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    gcols = ['game_id', 'play_id', 'nfl_id']\n",
    "    \n",
    "    # Enhanced temporal features \n",
    "    for lag in [1, 2, 3, 5]:\n",
    "        input_df[f'x_lag{lag}'] = input_df.groupby(gcols)['x'].shift(lag)\n",
    "        input_df[f'y_lag{lag}'] = input_df.groupby(gcols)['y'].shift(lag)\n",
    "        input_df[f'velocity_x_lag{lag}'] = input_df.groupby(gcols)['velocity_x'].shift(lag)\n",
    "        input_df[f'velocity_y_lag{lag}'] = input_df.groupby(gcols)['velocity_y'].shift(lag)\n",
    "        input_df[f's_lag{lag}'] = input_df.groupby(gcols)['s'].shift(lag)\n",
    "    \n",
    "    # Multiple EMA smoothing \n",
    "    for alpha in [0.1, 0.3, 0.5]:\n",
    "        input_df[f'velocity_x_ema_{alpha}'] = input_df.groupby(gcols)['velocity_x'].transform(\n",
    "            lambda x: x.ewm(alpha=alpha, adjust=False).mean()\n",
    "        )\n",
    "        input_df[f'velocity_y_ema_{alpha}'] = input_df.groupby(gcols)['velocity_y'].transform(\n",
    "            lambda x: x.ewm(alpha=alpha, adjust=False).mean()\n",
    "        )\n",
    "    \n",
    "\n",
    "    # ADVANCED FEATURES \n",
    " \n",
    "    input_df = add_advanced_features(input_df)\n",
    "    \n",
    "\n",
    "    # COMBINED FEATURE LIST \n",
    "\n",
    "    feature_cols = [\n",
    "        # Core tracking (8)\n",
    "        'x', 'y', 's', 'a', 'o', 'dir', 'frame_id',\n",
    "        'ball_land_x', 'ball_land_y',\n",
    "        \n",
    "        # Player attributes (2)\n",
    "        'player_height_feet', 'player_weight',\n",
    "        \n",
    "        # Enhanced motion (7)\n",
    "        'velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y',\n",
    "        'orientation_x', 'orientation_y',\n",
    "        'kinetic_energy',\n",
    "        \n",
    "        # Roles (6)\n",
    "        'is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer', 'is_rusher',\n",
    "        \n",
    "        # Field position (6)\n",
    "        'field_x_norm', 'field_y_norm', \n",
    "        'dist_from_sideline', 'dist_from_endzone',\n",
    "        'distance_to_sideline', 'distance_to_endzone',\n",
    "        \n",
    "        # Ball interaction (5)\n",
    "        'distance_to_ball', 'angle_to_ball', 'ball_direction_x', 'ball_direction_y', 'closing_speed',\n",
    "        \n",
    "        # Enhanced temporal (20)\n",
    "        'x_lag1', 'y_lag1', 'velocity_x_lag1', 'velocity_y_lag1', 's_lag1',\n",
    "        'x_lag2', 'y_lag2', 'velocity_x_lag2', 'velocity_y_lag2', 's_lag2',\n",
    "        'x_lag3', 'y_lag3', 'velocity_x_lag3', 'velocity_y_lag3', 's_lag3',\n",
    "        'x_lag5', 'y_lag5', 'velocity_x_lag5', 'velocity_y_lag5', 's_lag5',\n",
    "        \n",
    "        # Multiple EMAs (6)\n",
    "        'velocity_x_ema_0.1', 'velocity_y_ema_0.1',\n",
    "        'velocity_x_ema_0.3', 'velocity_y_ema_0.3', \n",
    "        'velocity_x_ema_0.5', 'velocity_y_ema_0.5',\n",
    "        \n",
    "        # Advanced features \n",
    "        'distance_to_ball_change', 'distance_to_ball_accel', 'time_to_intercept',\n",
    "        'velocity_alignment', 'velocity_perpendicular', 'accel_alignment',\n",
    "        'velocity_x_change', 'velocity_y_change', 'speed_change', 'direction_change',\n",
    "        'receiver_optimality', 'receiver_deviation', 'defender_closing_speed',\n",
    "        'frames_elapsed', 'normalized_time',\n",
    "        \n",
    "        # Rolling features (selective)\n",
    "        'velocity_x_roll5', 'velocity_y_roll5', 's_roll5', 'a_roll5',\n",
    "        'velocity_x_std5', 'velocity_y_std5', 's_std5', 'a_std5',\n",
    "    ]\n",
    "    \n",
    "    # Filter to existing columns\n",
    "    feature_cols = [c for c in feature_cols if c in input_df.columns]\n",
    "    print(f\"Using {len(feature_cols)} COMBINED features\")\n",
    "    \n",
    "    # CREATE SEQUENCES \n",
    " \n",
    "    input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n",
    "    grouped = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n",
    "    \n",
    "    target_rows = output_df if is_training else test_template\n",
    "    target_groups = target_rows[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n",
    "    \n",
    "    sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = [], [], [], [], []\n",
    "    \n",
    "    for _, row in tqdm(target_groups.iterrows(), total=len(target_groups)):\n",
    "        key = (row['game_id'], row['play_id'], row['nfl_id'])\n",
    "        \n",
    "        try:\n",
    "            group_df = grouped.get_group(key)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        input_window = group_df.tail(window_size)\n",
    "        \n",
    "        if len(input_window) < window_size:\n",
    "            if is_training:\n",
    "                continue\n",
    "            pad_len = window_size - len(input_window)\n",
    "            pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n",
    "            input_window = pd.concat([pad_df, input_window], ignore_index=True)\n",
    "        \n",
    "        # Enhanced imputation\n",
    "        input_window = input_window.fillna(method='ffill').fillna(method='bfill')\n",
    "        input_window = input_window.fillna(group_df.mean(numeric_only=True))\n",
    "        \n",
    "        seq = input_window[feature_cols].values\n",
    "        \n",
    "        if np.isnan(seq).any():\n",
    "            if is_training:\n",
    "                continue\n",
    "            seq = np.nan_to_num(seq, nan=0.0)\n",
    "        \n",
    "        sequences.append(seq)\n",
    "        \n",
    "        if is_training:\n",
    "            out_grp = output_df[\n",
    "                (output_df['game_id']==row['game_id']) &\n",
    "                (output_df['play_id']==row['play_id']) &\n",
    "                (output_df['nfl_id']==row['nfl_id'])\n",
    "            ].sort_values('frame_id')\n",
    "            \n",
    "            last_x = input_window.iloc[-1]['x']\n",
    "            last_y = input_window.iloc[-1]['y']\n",
    "            \n",
    "            dx = out_grp['x'].values - last_x\n",
    "            dy = out_grp['y'].values - last_y\n",
    "            \n",
    "            targets_dx.append(dx)\n",
    "            targets_dy.append(dy)\n",
    "            targets_frame_ids.append(out_grp['frame_id'].values)\n",
    "        \n",
    "        sequence_ids.append({\n",
    "            'game_id': key[0],\n",
    "            'play_id': key[1],\n",
    "            'nfl_id': key[2],\n",
    "            'frame_id': input_window.iloc[-1]['frame_id']\n",
    "        })\n",
    "    \n",
    "    print(f\"Created {len(sequences)} sequences\")\n",
    "    \n",
    "    if is_training:\n",
    "        return sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids, feature_cols\n",
    "    return sequences, sequence_ids, feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d99a7",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b018c8",
   "metadata": {
    "papermill": {
     "duration": 0.004289,
     "end_time": "2025-10-19T07:09:04.823988",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.819699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ENHANCED MODEL ARCHITECTURE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99761b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T07:09:04.833882Z",
     "iopub.status.busy": "2025-10-19T07:09:04.833660Z",
     "iopub.status.idle": "2025-10-19T07:09:04.842033Z",
     "shell.execute_reply": "2025-10-19T07:09:04.841511Z"
    },
    "papermill": {
     "duration": 0.01461,
     "end_time": "2025-10-19T07:09:04.843118",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.828508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnhancedSeqModel(nn.Module):\n",
    "    def __init__(self, input_dim, horizon):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, 192, num_layers=3, batch_first=True, dropout=0.2, bidirectional=False)\n",
    "        \n",
    "        self.conv1d = nn.Sequential(\n",
    "            nn.Conv1d(192, 128, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=5, padding=2),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        \n",
    "        self.pool_ln = nn.LayerNorm(192)\n",
    "        self.pool_attn = nn.MultiheadAttention(192, num_heads=8, batch_first=True, dropout=0.1)\n",
    "        self.pool_query = nn.Parameter(torch.randn(1, 1, 192))\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(192 + 128, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, horizon * 2)\n",
    "        )\n",
    "        \n",
    "        self.initialize_weights()\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.GRU):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h, _ = self.gru(x)\n",
    "        \n",
    "        h_conv = self.conv1d(h.transpose(1, 2)).transpose(1, 2)\n",
    "        h_conv_pool = h_conv.mean(dim=1)\n",
    "        \n",
    "        B = h.size(0)\n",
    "        q = self.pool_query.expand(B, -1, -1)\n",
    "        h_norm = self.pool_ln(h)\n",
    "        ctx, _ = self.pool_attn(q, h_norm, h_norm)\n",
    "        ctx = ctx.squeeze(1)\n",
    "        \n",
    "        combined = torch.cat([ctx, h_conv_pool], dim=1)\n",
    "        \n",
    "        out = self.head(combined)\n",
    "        out = out.view(B, 2, self.horizon)\n",
    "        \n",
    "        out = torch.cumsum(out, dim=2)\n",
    "        \n",
    "        return out[:, 0, :], out[:, 1, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f2d5a",
   "metadata": {},
   "source": [
    "# INSTALL PYTORCH GEOMETRIC FOR GNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e02090",
   "metadata": {},
   "outputs": [],
   "source": "# Install and Import PyTorch Geometric\nimport sys\nimport subprocess\n\nprint(\"Installing PyTorch Geometric...\")\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch-geometric\"])\n\nfrom torch_geometric.nn import GATConv, global_mean_pool\nfrom torch_geometric.data import Data, Batch\nimport torch.nn.functional as F\n\nprint(\"\u2713 PyTorch Geometric ready\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "adabfcb2",
   "metadata": {},
   "source": [
    "# GNN MODEL CLASSES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerInteractionGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Neural Network for modeling player interactions.\n",
    "    Uses Graph Attention Networks (GAT) with 3 layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_feature_dim, hidden_dim=128, num_heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 3-layer GAT with attention\n",
    "        self.gat1 = GATConv(node_feature_dim, hidden_dim, heads=num_heads, concat=False, dropout=0.1)\n",
    "        self.gat2 = GATConv(hidden_dim, hidden_dim, heads=num_heads, concat=False, dropout=0.1)\n",
    "        self.gat3 = GATConv(hidden_dim, hidden_dim, heads=1, dropout=0.1)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Node features (N, node_feature_dim)\n",
    "            edge_index: Edge connections (2, E)\n",
    "            edge_attr: Edge weights (E, 1) - optional\n",
    "        \n",
    "        Returns:\n",
    "            Node embeddings after message passing (N, hidden_dim)\n",
    "        \"\"\"\n",
    "        # Layer 1\n",
    "        h1 = F.relu(self.gat1(x, edge_index))\n",
    "        h1 = self.norm1(h1)\n",
    "        \n",
    "        # Layer 2 with residual\n",
    "        h2 = F.relu(self.gat2(h1, edge_index))\n",
    "        h2 = self.norm2(h2)\n",
    "        h2 = h2 + h1  # Residual connection\n",
    "        \n",
    "        # Layer 3\n",
    "        h3 = F.relu(self.gat3(h2, edge_index))\n",
    "        h3 = self.norm3(h3)\n",
    "        h3 = h3 + h2  # Residual connection\n",
    "        \n",
    "        return h3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEnhancedSeqModel(nn.Module):\n",
    "    \"\"\"\n",
    "    GNN-Enhanced Sequence Model with temporal frame graph.\n",
    "    Processes sequence frames as a connected graph before GRU.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, horizon):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Temporal GNN for frame interactions\n",
    "        self.temporal_gnn = PlayerInteractionGNN(\n",
    "            node_feature_dim=input_dim,\n",
    "            hidden_dim=128,\n",
    "            num_heads=4\n",
    "        )\n",
    "        \n",
    "        # Project GNN output to match input dim\n",
    "        self.gnn_proj = nn.Linear(128, input_dim)\n",
    "        \n",
    "        # GRU processes concatenated [original_features, gnn_features]\n",
    "        self.gru = nn.GRU(input_dim * 2, 192, num_layers=3, batch_first=True, dropout=0.2, bidirectional=False)\n",
    "        \n",
    "        self.conv1d = nn.Sequential(\n",
    "            nn.Conv1d(192, 128, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=5, padding=2),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        \n",
    "        self.pool_ln = nn.LayerNorm(192)\n",
    "        self.pool_attn = nn.MultiheadAttention(192, num_heads=8, batch_first=True, dropout=0.1)\n",
    "        self.pool_query = nn.Parameter(torch.randn(1, 1, 192))\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(192 + 128, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, horizon * 2)\n",
    "        )\n",
    "        \n",
    "        self.initialize_weights()\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.GRU):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param, 0)\n",
    "    \n",
    "    def build_temporal_edges(self, batch_size, seq_len, device):\n",
    "        \"\"\"\n",
    "        Build edges for temporal graph:\n",
    "        - Connect consecutive frames (t-1 -> t)\n",
    "        - Connect frames within window of 3\n",
    "        \"\"\"\n",
    "        edge_list = []\n",
    "        for b in range(batch_size):\n",
    "            offset = b * seq_len\n",
    "            for t in range(seq_len):\n",
    "                node_idx = offset + t\n",
    "                # Connect to previous frames (within window of 3)\n",
    "                for delta in range(1, min(4, t + 1)):\n",
    "                    prev_idx = offset + (t - delta)\n",
    "                    edge_list.append([prev_idx, node_idx])\n",
    "                    edge_list.append([node_idx, prev_idx])  # Bidirectional\n",
    "        \n",
    "        if len(edge_list) == 0:\n",
    "            # Fallback: self-loops\n",
    "            total_nodes = batch_size * seq_len\n",
    "            edge_index = torch.tensor([[i, i] for i in range(total_nodes)], dtype=torch.long, device=device).t()\n",
    "        else:\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.long, device=device).t()\n",
    "        \n",
    "        return edge_index\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, T, F) where B=batch, T=seq_len, F=features\n",
    "        \n",
    "        Returns:\n",
    "            pred_dx, pred_dy: (B, horizon) predictions\n",
    "        \"\"\"\n",
    "        B, T, F = x.shape\n",
    "        device = x.device\n",
    "        \n",
    "        # Apply temporal GNN\n",
    "        # Reshape to (B*T, F) for graph processing\n",
    "        x_flat = x.reshape(B * T, F)\n",
    "        \n",
    "        # Build temporal edges\n",
    "        edge_index = self.build_temporal_edges(B, T, device)\n",
    "        \n",
    "        # GNN forward\n",
    "        gnn_out = self.temporal_gnn(x_flat, edge_index)  # (B*T, 128)\n",
    "        gnn_out = self.gnn_proj(gnn_out)  # (B*T, F)\n",
    "        \n",
    "        # Reshape back to (B, T, F)\n",
    "        gnn_out = gnn_out.reshape(B, T, F)\n",
    "        \n",
    "        # Concatenate original features with GNN features\n",
    "        x_combined = torch.cat([x, gnn_out], dim=-1)  # (B, T, 2F)\n",
    "        \n",
    "        # GRU processing\n",
    "        h, _ = self.gru(x_combined)  # (B, T, 192)\n",
    "        \n",
    "        # Conv1D processing\n",
    "        h_conv = self.conv1d(h.transpose(1, 2)).transpose(1, 2)  # (B, T, 128)\n",
    "        h_conv_pool = h_conv.mean(dim=1)  # (B, 128)\n",
    "        \n",
    "        # Attention pooling\n",
    "        q = self.pool_query.expand(B, -1, -1)  # (B, 1, 192)\n",
    "        h_norm = self.pool_ln(h)\n",
    "        ctx, _ = self.pool_attn(q, h_norm, h_norm)  # (B, 1, 192)\n",
    "        ctx = ctx.squeeze(1)  # (B, 192)\n",
    "        \n",
    "        # Combine and predict\n",
    "        combined = torch.cat([ctx, h_conv_pool], dim=1)  # (B, 320)\n",
    "        out = self.head(combined)  # (B, horizon*2)\n",
    "        out = out.view(B, 2, self.horizon)\n",
    "        \n",
    "        # Cumulative sum for displacement\n",
    "        out = torch.cumsum(out, dim=2)\n",
    "        \n",
    "        return out[:, 0, :], out[:, 1, :]  # dx, dy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dd456",
   "metadata": {
    "papermill": {
     "duration": 0.004261,
     "end_time": "2025-10-19T07:09:04.852081",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.847820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# ENHANCED TRAINING \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb657339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T07:09:04.862045Z",
     "iopub.status.busy": "2025-10-19T07:09:04.861856Z",
     "iopub.status.idle": "2025-10-19T07:09:04.879324Z",
     "shell.execute_reply": "2025-10-19T07:09:04.878795Z"
    },
    "papermill": {
     "duration": 0.023725,
     "end_time": "2025-10-19T07:09:04.880278",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.856553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": "class EnhancedTemporalLoss(nn.Module):\n    def __init__(self, delta=0.5, time_decay=0.05, velocity_weight=0.1):\n        super().__init__()\n        self.delta = delta\n        self.time_decay = time_decay\n        self.velocity_weight = velocity_weight\n        self.huber = nn.SmoothL1Loss(reduction='none')\n    \n    def forward(self, pred_dx, pred_dy, target_dx, target_dy, mask):\n        L = pred_dx.size(1)\n        t = torch.arange(L, device=pred_dx.device).float()\n        time_weights = torch.exp(-self.time_decay * t).view(1, L)\n        \n        loss_dx = self.huber(pred_dx, target_dx) * time_weights\n        loss_dy = self.huber(pred_dy, target_dy) * time_weights\n        \n        masked_loss_dx = (loss_dx * mask).sum() / (mask.sum() + 1e-8)\n        masked_loss_dy = (loss_dy * mask).sum() / (mask.sum() + 1e-8)\n        \n        position_loss = (masked_loss_dx + masked_loss_dy) / 2\n        \n        if self.velocity_weight > 0:\n            pred_velocity_x = torch.diff(pred_dx, dim=1, prepend=torch.zeros_like(pred_dx[:, :1]))\n            pred_velocity_y = torch.diff(pred_dy, dim=1, prepend=torch.zeros_like(pred_dy[:, :1]))\n            target_velocity_x = torch.diff(target_dx, dim=1, prepend=torch.zeros_like(target_dx[:, :1]))\n            target_velocity_y = torch.diff(target_dy, dim=1, prepend=torch.zeros_like(target_dy[:, :1]))\n            \n            velocity_loss = (\n                self.huber(pred_velocity_x, target_velocity_x).mean() +\n                self.huber(pred_velocity_y, target_velocity_y).mean()\n            ) * self.velocity_weight\n            \n            total_loss = position_loss + velocity_loss\n        else:\n            total_loss = position_loss\n        \n        return total_loss\n\ndef compute_rmse(pred_dx, pred_dy, target_dx, target_dy, mask):\n    \"\"\"Calculate RMSE for position predictions\"\"\"\n    squared_errors = ((pred_dx - target_dx)**2 + (pred_dy - target_dy)**2) * mask\n    mse = squared_errors.sum() / (mask.sum() + 1e-8)\n    return torch.sqrt(mse).item()\n\ndef prepare_targets_enhanced(batch_dx, batch_dy, max_h):\n    tensors_dx, tensors_dy, masks = [], [], []\n    for dx_arr, dy_arr in zip(batch_dx, batch_dy):\n        L = len(dx_arr)\n        padded_dx = np.pad(dx_arr, (0, max_h - L), constant_values=0).astype(np.float32)\n        padded_dy = np.pad(dy_arr, (0, max_h - L), constant_values=0).astype(np.float32)\n        mask = np.zeros(max_h, dtype=np.float32)\n        mask[:L] = 1.0\n        tensors_dx.append(torch.tensor(padded_dx))\n        tensors_dy.append(torch.tensor(padded_dy))\n        masks.append(torch.tensor(mask))\n    return torch.stack(tensors_dx), torch.stack(tensors_dy), torch.stack(masks)\n\ndef train_model_combined(X_train, y_dx_train, y_dy_train, X_val, y_dx_val, y_dy_val, input_dim, horizon, config):\n    device = config.DEVICE\n    model = GNNEnhancedSeqModel(input_dim, horizon).to(device)\n    \n    criterion = EnhancedTemporalLoss(delta=0.5, time_decay=0.05, velocity_weight=0.05)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=config.LEARNING_RATE, \n        epochs=config.EPOCHS, steps_per_epoch=len(X_train)//config.BATCH_SIZE+1\n    )\n    \n    train_batches = []\n    for i in range(0, len(X_train), config.BATCH_SIZE):\n        end = min(i + config.BATCH_SIZE, len(X_train))\n        bx = torch.tensor(np.stack(X_train[i:end]).astype(np.float32))\n        by_dx, by_dy, bm = prepare_targets_enhanced(\n            [y_dx_train[j] for j in range(i, end)],\n            [y_dy_train[j] for j in range(i, end)], \n            horizon\n        )\n        train_batches.append((bx, by_dx, by_dy, bm))\n    \n    val_batches = []\n    for i in range(0, len(X_val), config.BATCH_SIZE):\n        end = min(i + config.BATCH_SIZE, len(X_val))\n        bx = torch.tensor(np.stack(X_val[i:end]).astype(np.float32))\n        by_dx, by_dy, bm = prepare_targets_enhanced(\n            [y_dx_val[j] for j in range(i, end)],\n            [y_dy_val[j] for j in range(i, end)],\n            horizon\n        )\n        val_batches.append((bx, by_dx, by_dy, bm))\n    \n    best_rmse, best_state, bad = float('inf'), None, 0\n    \n    for epoch in range(1, config.EPOCHS + 1):\n        model.train()\n        train_losses = []\n        \n        for bx, by_dx, by_dy, bm in train_batches:\n            bx, by_dx, by_dy, bm = bx.to(device), by_dx.to(device), by_dy.to(device), bm.to(device)\n            pred_dx, pred_dy = model(bx)\n            loss = criterion(pred_dx, pred_dy, by_dx, by_dy, bm)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            train_losses.append(loss.item())\n        \n        model.eval()\n        val_losses, val_rmses = [], []\n        with torch.no_grad():\n            for bx, by_dx, by_dy, bm in val_batches:\n                bx, by_dx, by_dy, bm = bx.to(device), by_dx.to(device), by_dy.to(device), bm.to(device)\n                pred_dx, pred_dy = model(bx)\n                loss = criterion(pred_dx, pred_dy, by_dx, by_dy, bm)\n                rmse = compute_rmse(pred_dx, pred_dy, by_dx, by_dy, bm)\n                val_losses.append(loss.item())\n                val_rmses.append(rmse)\n        \n        train_loss = np.mean(train_losses)\n        val_loss = np.mean(val_losses)\n        val_rmse = np.mean(val_rmses)\n        \n        if epoch % 10 == 0:\n            lr = scheduler.get_last_lr()[0]\n            print(f\"  Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, val_rmse={val_rmse:.4f}, lr={lr:.2e}\")\n        \n        if val_rmse < best_rmse:\n            best_rmse = val_rmse\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n            bad = 0\n        else:\n            bad += 1\n            if bad >= config.PATIENCE:\n                print(f\"  Early stop at epoch {epoch}\")\n                break\n    \n    if best_state:\n        model.load_state_dict(best_state)\n    \n    return model, best_rmse\n"
  },
  {
   "cell_type": "markdown",
   "id": "93a5672a",
   "metadata": {
    "papermill": {
     "duration": 0.004395,
     "end_time": "2025-10-19T07:09:04.889104",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.884709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tta_header_12",
   "metadata": {},
   "source": [
    "# TEST-TIME AUGMENTATION (TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tta_code_12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_sequence(seq, aug_type='none', seed=None):\n",
    "    \"\"\"\n",
    "    Apply test-time augmentation to input sequence.\n",
    "    \n",
    "    Args:\n",
    "        seq: (T, F) sequence array\n",
    "        aug_type: 'none', 'temporal_shift', 'velocity_jitter', 'field_mirror'\n",
    "        seed: random seed for reproducibility\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    aug_seq = seq.copy()\n",
    "    \n",
    "    if aug_type == 'none':\n",
    "        return aug_seq\n",
    "    \n",
    "    elif aug_type == 'temporal_shift_forward':\n",
    "        # Shift sequence forward by 1 frame (interpolate)\n",
    "        shift = 0.5\n",
    "        aug_seq[:-1] = aug_seq[:-1] * (1 - shift) + aug_seq[1:] * shift\n",
    "        return aug_seq\n",
    "    \n",
    "    elif aug_type == 'temporal_shift_backward':\n",
    "        # Shift sequence backward by 1 frame\n",
    "        shift = 0.5\n",
    "        aug_seq[1:] = aug_seq[1:] * (1 - shift) + aug_seq[:-1] * shift\n",
    "        return aug_seq\n",
    "    \n",
    "    elif aug_type == 'velocity_jitter':\n",
    "        # Add small noise to velocity features (indices 12-13 for velocity_x, velocity_y)\n",
    "        # Assuming features are ordered as shown in feature_cols\n",
    "        if seq.shape[1] > 13:\n",
    "            noise = np.random.normal(0, 0.05, size=(seq.shape[0], 2))\n",
    "            aug_seq[:, 12:14] += noise  # velocity_x, velocity_y\n",
    "        return aug_seq\n",
    "    \n",
    "    elif aug_type == 'field_mirror':\n",
    "        # Mirror y-coordinates (field width symmetry)\n",
    "        # y (index 1), field_y_norm (index varies), and y-related features\n",
    "        aug_seq[:, 1] = 53.3 - aug_seq[:, 1]  # y coordinate\n",
    "        if seq.shape[1] > 13:\n",
    "            aug_seq[:, 13] *= -1  # velocity_y\n",
    "        if seq.shape[1] > 15:\n",
    "            aug_seq[:, 15] *= -1  # acceleration_y\n",
    "        return aug_seq\n",
    "    \n",
    "    else:\n",
    "        return aug_seq\n",
    "\n",
    "def apply_tta_ensemble(models, scalers, X_test, aug_types=['none', 'temporal_shift_forward', 'velocity_jitter'], device=None):\n",
    "    \"\"\"\n",
    "    Apply test-time augmentation ensemble.\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained models\n",
    "        scalers: List of fitted scalers\n",
    "        X_test: Test sequences (list of arrays)\n",
    "        aug_types: List of augmentation types to apply\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        ens_dx, ens_dy: Averaged predictions across models and augmentations\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = Config.DEVICE\n",
    "    \n",
    "    all_predictions_dx = []\n",
    "    all_predictions_dy = []\n",
    "    \n",
    "    print(f\"\\nApplying TTA with {len(aug_types)} augmentations...\")\n",
    "    \n",
    "    for aug_idx, aug_type in enumerate(aug_types):\n",
    "        print(f\"  Augmentation {aug_idx+1}/{len(aug_types)}: {aug_type}\")\n",
    "        \n",
    "        # Apply augmentation to all test sequences\n",
    "        X_test_aug = [augment_sequence(seq, aug_type=aug_type, seed=42) for seq in X_test]\n",
    "        \n",
    "        # Predict with all models\n",
    "        for model, sc in zip(models, scalers):\n",
    "            X_scaled = np.stack([sc.transform(s) for s in X_test_aug])\n",
    "            X_tensor = torch.tensor(X_scaled.astype(np.float32)).to(device)\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                dx, dy = model(X_tensor)\n",
    "                all_predictions_dx.append(dx.cpu().numpy())\n",
    "                all_predictions_dy.append(dy.cpu().numpy())\n",
    "    \n",
    "    # Average all predictions (models \u00d7 augmentations)\n",
    "    ens_dx = np.mean(all_predictions_dx, axis=0)\n",
    "    ens_dy = np.mean(all_predictions_dy, axis=0)\n",
    "    \n",
    "    print(f\"  Total predictions averaged: {len(all_predictions_dx)} (models \u00d7 augmentations)\")\n",
    "    \n",
    "    return ens_dx, ens_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae41e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T07:09:04.899458Z",
     "iopub.status.busy": "2025-10-19T07:09:04.899028Z",
     "iopub.status.idle": "2025-10-19T08:24:42.728303Z",
     "shell.execute_reply": "2025-10-19T08:24:42.727462Z"
    },
    "papermill": {
     "duration": 4537.836223,
     "end_time": "2025-10-19T08:24:42.729860",
     "exception": false,
     "start_time": "2025-10-19T07:09:04.893637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMBINED ENSEMBLE PIPELINE WITH RMSE TRACKING\n",
      "================================================================================\n",
      "Combining:\n",
      "  \u2713 Advanced Feature Engineering (90+ features)\n",
      "  \u2713 Enhanced Model Architecture (GRU + Conv1D + Attention)\n",
      "  \u2713 Better Training Strategy (OneCycleLR, improved loss)\n",
      "  \u2713 OOF RMSE Logging for reliable evaluation\n",
      "\n",
      "[1/4] Loading data...\n",
      "\n",
      "[2/4] Preparing COMBINED sequences...\n",
      "Preparing COMBINED sequences (window_size=10)...\n",
      "Adding advanced features...\n",
      "Using 82 COMBINED features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085cf876a7164fb4843b7f59397f8bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 46022 sequences\n",
      "Feature dimension: 82\n",
      "\n",
      "[3/4] Training COMBINED model...\n",
      "\n",
      "Fold 1/5\n",
      "  Epoch 10: train_loss=0.2006, val_loss=0.1192, val_rmse=1.2950, lr=1.06e-04\n",
      "  Epoch 20: train_loss=0.1387, val_loss=0.0855, val_rmse=1.0951, lr=3.02e-04\n",
      "  Epoch 30: train_loss=0.1228, val_loss=0.0778, val_rmse=1.0397, lr=4.68e-04\n",
      "  Epoch 40: train_loss=0.1127, val_loss=0.0753, val_rmse=1.0273, lr=4.97e-04\n",
      "  Epoch 50: train_loss=0.1037, val_loss=0.0694, val_rmse=0.9953, lr=4.66e-04\n",
      "  Epoch 60: train_loss=0.0984, val_loss=0.0722, val_rmse=0.9946, lr=4.06e-04\n",
      "  Epoch 70: train_loss=0.0938, val_loss=0.0691, val_rmse=0.9818, lr=3.24e-04\n",
      "  Epoch 80: train_loss=0.0893, val_loss=0.0679, val_rmse=0.9711, lr=2.31e-04\n",
      "  Epoch 90: train_loss=0.0861, val_loss=0.0672, val_rmse=0.9744, lr=1.41e-04\n",
      "  Epoch 100: train_loss=0.0831, val_loss=0.0638, val_rmse=0.9476, lr=6.67e-05\n",
      "  Epoch 110: train_loss=0.0811, val_loss=0.0631, val_rmse=0.9478, lr=1.72e-05\n",
      "  Epoch 120: train_loss=0.0805, val_loss=0.0629, val_rmse=0.9500, lr=2.03e-09\n",
      "Fold 1 completed with val_RMSE: 0.9460\n",
      "\n",
      "Fold 2/5\n",
      "  Epoch 10: train_loss=0.1992, val_loss=0.1216, val_rmse=1.2552, lr=1.06e-04\n",
      "  Epoch 20: train_loss=0.1370, val_loss=0.0901, val_rmse=1.0618, lr=3.02e-04\n",
      "  Epoch 30: train_loss=0.1203, val_loss=0.0845, val_rmse=1.0062, lr=4.68e-04\n",
      "  Epoch 40: train_loss=0.1107, val_loss=0.0804, val_rmse=0.9711, lr=4.97e-04\n",
      "  Epoch 50: train_loss=0.1058, val_loss=0.0761, val_rmse=0.9616, lr=4.66e-04\n",
      "  Epoch 60: train_loss=0.0987, val_loss=0.0690, val_rmse=0.9122, lr=4.06e-04\n",
      "  Epoch 70: train_loss=0.0936, val_loss=0.0699, val_rmse=0.9146, lr=3.24e-04\n",
      "  Epoch 80: train_loss=0.0896, val_loss=0.0701, val_rmse=0.9194, lr=2.31e-04\n",
      "  Epoch 90: train_loss=0.0859, val_loss=0.0652, val_rmse=0.8841, lr=1.41e-04\n",
      "  Epoch 100: train_loss=0.0818, val_loss=0.0634, val_rmse=0.8711, lr=6.67e-05\n",
      "  Epoch 110: train_loss=0.0811, val_loss=0.0621, val_rmse=0.8655, lr=1.72e-05\n",
      "  Epoch 120: train_loss=0.0799, val_loss=0.0615, val_rmse=0.8613, lr=2.03e-09\n",
      "Fold 2 completed with val_RMSE: 0.8613\n",
      "\n",
      "Fold 3/5\n",
      "  Epoch 10: train_loss=0.2041, val_loss=0.1219, val_rmse=1.2988, lr=1.06e-04\n",
      "  Epoch 20: train_loss=0.1388, val_loss=0.0859, val_rmse=1.0615, lr=3.02e-04\n",
      "  Epoch 30: train_loss=0.1212, val_loss=0.0800, val_rmse=1.0144, lr=4.68e-04\n",
      "  Epoch 40: train_loss=0.1125, val_loss=0.0860, val_rmse=1.0363, lr=4.97e-04\n",
      "  Epoch 50: train_loss=0.1051, val_loss=0.0672, val_rmse=0.9230, lr=4.66e-04\n",
      "  Epoch 60: train_loss=0.0999, val_loss=0.0697, val_rmse=0.9337, lr=4.06e-04\n",
      "  Epoch 70: train_loss=0.0936, val_loss=0.0667, val_rmse=0.9197, lr=3.24e-04\n",
      "  Epoch 80: train_loss=0.0907, val_loss=0.0681, val_rmse=0.9253, lr=2.31e-04\n",
      "  Epoch 90: train_loss=0.0869, val_loss=0.0650, val_rmse=0.9092, lr=1.41e-04\n",
      "  Epoch 100: train_loss=0.0836, val_loss=0.0621, val_rmse=0.8892, lr=6.67e-05\n",
      "  Epoch 110: train_loss=0.0813, val_loss=0.0617, val_rmse=0.8932, lr=1.72e-05\n",
      "  Early stop at epoch 119\n",
      "Fold 3 completed with val_RMSE: 0.8884\n",
      "\n",
      "Fold 4/5\n",
      "  Epoch 10: train_loss=0.2015, val_loss=0.1239, val_rmse=1.2777, lr=1.06e-04\n",
      "  Epoch 20: train_loss=0.1385, val_loss=0.0818, val_rmse=1.0187, lr=3.02e-04\n",
      "  Epoch 30: train_loss=0.1238, val_loss=0.0769, val_rmse=0.9743, lr=4.68e-04\n",
      "  Epoch 40: train_loss=0.1107, val_loss=0.0739, val_rmse=0.9391, lr=4.97e-04\n",
      "  Epoch 50: train_loss=0.1050, val_loss=0.0777, val_rmse=0.9698, lr=4.66e-04\n",
      "  Epoch 60: train_loss=0.1016, val_loss=0.0719, val_rmse=0.9340, lr=4.06e-04\n",
      "  Epoch 70: train_loss=0.0951, val_loss=0.0667, val_rmse=0.8919, lr=3.24e-04\n",
      "  Epoch 80: train_loss=0.0901, val_loss=0.0671, val_rmse=0.8946, lr=2.31e-04\n",
      "  Epoch 90: train_loss=0.0857, val_loss=0.0642, val_rmse=0.8750, lr=1.41e-04\n",
      "  Epoch 100: train_loss=0.0832, val_loss=0.0629, val_rmse=0.8696, lr=6.67e-05\n",
      "  Epoch 110: train_loss=0.0816, val_loss=0.0620, val_rmse=0.8614, lr=1.72e-05\n",
      "  Epoch 120: train_loss=0.0800, val_loss=0.0614, val_rmse=0.8564, lr=2.03e-09\n",
      "Fold 4 completed with val_RMSE: 0.8563\n",
      "\n",
      "Fold 5/5\n",
      "  Epoch 10: train_loss=0.2000, val_loss=0.1162, val_rmse=1.2092, lr=1.06e-04\n",
      "  Epoch 20: train_loss=0.1380, val_loss=0.0876, val_rmse=1.0305, lr=3.02e-04\n",
      "  Epoch 30: train_loss=0.1206, val_loss=0.0794, val_rmse=0.9633, lr=4.68e-04\n",
      "  Epoch 40: train_loss=0.1119, val_loss=0.0742, val_rmse=0.9245, lr=4.97e-04\n",
      "  Epoch 50: train_loss=0.1057, val_loss=0.0721, val_rmse=0.9054, lr=4.66e-04\n",
      "  Epoch 60: train_loss=0.0989, val_loss=0.0682, val_rmse=0.8824, lr=4.06e-04\n",
      "  Epoch 70: train_loss=0.0930, val_loss=0.0661, val_rmse=0.8715, lr=3.24e-04\n",
      "  Epoch 80: train_loss=0.0889, val_loss=0.0663, val_rmse=0.8761, lr=2.31e-04\n",
      "  Epoch 90: train_loss=0.0859, val_loss=0.0648, val_rmse=0.8652, lr=1.41e-04\n",
      "  Epoch 100: train_loss=0.0821, val_loss=0.0632, val_rmse=0.8567, lr=6.67e-05\n",
      "  Epoch 110: train_loss=0.0812, val_loss=0.0617, val_rmse=0.8501, lr=1.72e-05\n",
      "  Epoch 120: train_loss=0.0799, val_loss=0.0618, val_rmse=0.8493, lr=2.03e-09\n",
      "Fold 5 completed with val_RMSE: 0.8492\n",
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION RESULTS\n",
      "================================================================================\n",
      "Fold 1 RMSE: 0.9460\n",
      "Fold 2 RMSE: 0.8613\n",
      "Fold 3 RMSE: 0.8884\n",
      "Fold 4 RMSE: 0.8563\n",
      "Fold 5 RMSE: 0.8492\n",
      "\n",
      "Mean CV RMSE: 0.8802 \u00b1 0.0354\n",
      "Overall OOF RMSE: 0.9143\n",
      "================================================================================\n",
      "\n",
      "\n",
      "[4/4] Generating final predictions...\n",
      "Preparing COMBINED sequences (window_size=10)...\n",
      "Adding advanced features...\n",
      "Using 82 COMBINED features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f53181a53744ac9a422cfe9dedb10b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 472 sequences\n",
      "===============================================\n",
      "\n",
      "\u2713 COMBINED submission saved\n",
      "  Rows: 5837\n",
      "  Features used: 82\n",
      "  OOF RMSE: 0.9143\n",
      "  Expected LB RMSE: 0.9143 (\u00b10.01)\n",
      "\n",
      "Key advantages:\n",
      "  \u2022 90+ engineered features for rich representation\n",
      "  \u2022 Multi-scale model (GRU + Conv1D + Attention)\n",
      "  \u2022 Velocity-consistent loss for smooth trajectories\n",
      "  \u2022 OneCycle LR for faster convergence\n",
      "  \u2022 OOF RMSE tracking for reliable validation\n",
      "===============================================\n"
     ]
    }
   ],
   "source": "def main():\n    config = Config()\n    \n    print(\"=\"*80)\n    print(\"GNN-ENHANCED ENSEMBLE PIPELINE WITH RMSE TRACKING\")\n    print(\"=\"*80)\n    print(\"Combining:\")\n    print(\"  \u2713 Advanced Feature Engineering (90+ features)\")\n    print(\"  \u2713 GNN-Enhanced Architecture (Temporal GNN + GRU + Conv1D + Attention)\") \n    print(\"  \u2713 Better Training Strategy (OneCycleLR, improved loss)\")\n    print(\"  \u2713 OOF RMSE Logging for reliable evaluation\")\n    \n    # Load data\n    print(\"\\n[1/4] Loading data...\")\n    train_input_files = [config.DATA_DIR / f\"train/input_2023_w{w:02d}.csv\" for w in range(1, 19)]\n    train_output_files = [config.DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n    \n    train_input = pd.concat([pd.read_csv(f) for f in train_input_files if f.exists()])\n    train_output = pd.concat([pd.read_csv(f) for f in train_output_files if f.exists()])\n    \n    test_input = pd.read_csv(config.DATA_DIR / \"test_input.csv\")\n    test_template = pd.read_csv(config.DATA_DIR / \"test.csv\")\n    \n    # Prepare combined sequences\n    print(\"\\n[2/4] Preparing COMBINED sequences...\")\n    sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids, feature_cols = prepare_combined_features(\n        train_input, train_output, is_training=True, window_size=config.WINDOW_SIZE\n    )\n    \n    sequences = np.array(sequences, dtype=object)\n    targets_dx = np.array(targets_dx, dtype=object)\n    targets_dy = np.array(targets_dy, dtype=object)\n    \n    print(f\"Feature dimension: {sequences[0].shape[-1]}\")\n    \n    # Train with combined approach\n    print(\"\\n[3/4] Training COMBINED model...\")\n    groups = np.array([d['game_id'] for d in sequence_ids])\n    gkf = GroupKFold(n_splits=config.N_FOLDS)\n    \n    models, scalers, fold_rmses = [], [], []\n    oof_predictions = np.zeros((len(sequences), config.MAX_FUTURE_HORIZON, 2))  # Store OOF predictions\n    \n    for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n        print(f\"\\nFold {fold}/{config.N_FOLDS}\")\n        \n        X_tr = sequences[tr]\n        X_va = sequences[va]\n        \n        scaler = StandardScaler()\n        scaler.fit(np.vstack([s for s in X_tr]))\n        \n        X_tr_scaled = np.stack([scaler.transform(s) for s in X_tr])\n        X_va_scaled = np.stack([scaler.transform(s) for s in X_va])\n        \n        model, val_rmse = train_model_combined(\n            X_tr_scaled, targets_dx[tr], targets_dy[tr], \n            X_va_scaled, targets_dx[va], targets_dy[va],\n            X_tr[0].shape[-1], config.MAX_FUTURE_HORIZON, config\n        )\n        \n        # Store OOF predictions for validation set\n        model.eval()\n        with torch.no_grad():\n            X_va_tensor = torch.tensor(X_va_scaled.astype(np.float32)).to(config.DEVICE)\n            pred_dx, pred_dy = model(X_va_tensor)\n            oof_predictions[va, :, 0] = pred_dx.cpu().numpy()\n            oof_predictions[va, :, 1] = pred_dy.cpu().numpy()\n        \n        models.append(model)\n        scalers.append(scaler)\n        fold_rmses.append(val_rmse)\n        \n        print(f\"Fold {fold} completed with val_RMSE: {val_rmse:.4f}\")\n    \n    # Calculate overall OOF RMSE\n    print(\"\\n\" + \"=\"*80)\n    print(\"CROSS-VALIDATION RESULTS\")\n    print(\"=\"*80)\n    for fold, rmse in enumerate(fold_rmses, 1):\n        print(f\"Fold {fold} RMSE: {rmse:.4f}\")\n    \n    mean_rmse = np.mean(fold_rmses)\n    std_rmse = np.std(fold_rmses)\n    print(f\"\\nMean CV RMSE: {mean_rmse:.4f} \u00b1 {std_rmse:.4f}\")\n    \n    # Calculate full OOF RMSE (across all folds)\n    all_squared_errors = []\n    for i in range(len(sequences)):\n        target_dx = targets_dx[i]\n        target_dy = targets_dy[i]\n        pred_dx = oof_predictions[i, :len(target_dx), 0]\n        pred_dy = oof_predictions[i, :len(target_dy), 1]\n        \n        squared_errors = (pred_dx - target_dx)**2 + (pred_dy - target_dy)**2\n        all_squared_errors.extend(squared_errors)\n    \n    oof_rmse = np.sqrt(np.mean(all_squared_errors))\n    print(f\"Overall OOF RMSE: {oof_rmse:.4f}\")\n    print(\"=\"*80 + \"\\n\")\n    \n    # Predict\n    print(\"\\n[4/4] Generating final predictions...\")\n    test_sequences, test_ids, _ = prepare_combined_features(\n        test_input, test_template=test_template, is_training=False, window_size=config.WINDOW_SIZE\n    )\n    \n    X_test = np.array(test_sequences, dtype=object)\n    x_last = np.array([s[-1, 0] for s in X_test])\n    y_last = np.array([s[-1, 1] for s in X_test])\n    \n    # TTA Ensemble predictions\n    tta_augmentations = ['none', 'temporal_shift_forward', 'velocity_jitter']\n    ens_dx, ens_dy = apply_tta_ensemble(\n        models, scalers, X_test, \n        aug_types=tta_augmentations, \n        device=config.DEVICE\n    )\n    \n    # Create submission\n    rows = []\n    H = ens_dx.shape[1]\n    \n    for i, sid in enumerate(test_ids):\n        fids = test_template[\n            (test_template['game_id'] == sid['game_id']) &\n            (test_template['play_id'] == sid['play_id']) &\n            (test_template['nfl_id'] == sid['nfl_id'])\n        ]['frame_id'].sort_values().tolist()\n        \n        for t, fid in enumerate(fids):\n            tt = min(t, H - 1)\n            px = np.clip(x_last[i] + ens_dx[i, tt], Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n            py = np.clip(y_last[i] + ens_dy[i, tt], Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n            \n            rows.append({\n                'id': f\"{sid['game_id']}_{sid['play_id']}_{sid['nfl_id']}_{fid}\",\n                'x': float(px),\n                'y': float(py)\n            })\n    \n    submission = pd.DataFrame(rows)\n    submission.to_csv(\"submission.csv\", index=False)\n    print(\"=\"*47)\n    print(f\"\\n\u2713 COMBINED submission saved\")\n    print(f\"  Rows: {len(submission)}\")\n    print(f\"  Features used: {len(feature_cols)}\")\n    print(f\"  OOF RMSE: {oof_rmse:.4f}\")\n    print(f\"  Expected LB RMSE: {oof_rmse:.4f} (\u00b10.01)\")\n    print(f\"\\nKey advantages:\")\n    print(f\"  \u2022 90+ engineered features for rich representation\")\n    print(f\"  \u2022 Multi-scale model (GRU + Conv1D + Attention)\")\n    print(f\"  \u2022 Velocity-consistent loss for smooth trajectories\")\n    print(f\"  \u2022 OneCycle LR for faster convergence\")\n    print(f\"  \u2022 OOF RMSE tracking for reliable validation\")\n    print(\"=\"*47)\n    \n    return submission\n\nif __name__ == \"__main__\":\n    main()"
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13825858,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4551.554343,
   "end_time": "2025-10-19T08:24:45.761930",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-19T07:08:54.207587",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02d3d4e2d9b0416da6c4de4690a272f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d5961b5255294ba6a977c972faa46ada",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_d81934d58eb44a7792056771240be023",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "085cf876a7164fb4843b7f59397f8bc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_02d3d4e2d9b0416da6c4de4690a272f8",
        "IPY_MODEL_0af3ea8a71884d5ab08edc97cb88a2bf",
        "IPY_MODEL_d0713c12222c46cc909b23e18b26b888"
       ],
       "layout": "IPY_MODEL_99e1aae0817a40a2bf0994307b5d837e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "09f9bbe691e54f7b8958a497b5c887b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_22888a423fb84f59bb310bd438f6a325",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_3ce5b8210fc14238b6159356fb5237fe",
       "tabbable": null,
       "tooltip": null,
       "value": "\u2007472/472\u2007[00:13&lt;00:00,\u200734.87it/s]"
      }
     },
     "0af3ea8a71884d5ab08edc97cb88a2bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_56120b4959c44621acd2777e2f3c7873",
       "max": 46045,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f788273fabf64957a6db5c81f5281cd4",
       "tabbable": null,
       "tooltip": null,
       "value": 46045
      }
     },
     "0eda08de998d4bfdbb4f225d92a0cf27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "22888a423fb84f59bb310bd438f6a325": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2cb89e834eb1426b9a20c389abe2d1d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f53181a53744ac9a422cfe9dedb10b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_312f804f77f14e64bb5324e73ec6332b",
        "IPY_MODEL_4139a28f2c034770a740eb37f06f89ab",
        "IPY_MODEL_09f9bbe691e54f7b8958a497b5c887b5"
       ],
       "layout": "IPY_MODEL_76c646c6d2cf49568ba28daec4c722fc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "312f804f77f14e64bb5324e73ec6332b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c4f165d8f12143c4be5dcfe9a4d70986",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_a53816dbfa544bb4b72b3ce204eb9476",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "3ce5b8210fc14238b6159356fb5237fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4139a28f2c034770a740eb37f06f89ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f00403d59c2b43648c92c8e9dc702933",
       "max": 472,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0eda08de998d4bfdbb4f225d92a0cf27",
       "tabbable": null,
       "tooltip": null,
       "value": 472
      }
     },
     "56120b4959c44621acd2777e2f3c7873": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f174bc9690740fa96915bfa0e6106c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "76c646c6d2cf49568ba28daec4c722fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99e1aae0817a40a2bf0994307b5d837e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a53816dbfa544bb4b72b3ce204eb9476": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c4f165d8f12143c4be5dcfe9a4d70986": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0713c12222c46cc909b23e18b26b888": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2cb89e834eb1426b9a20c389abe2d1d5",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_5f174bc9690740fa96915bfa0e6106c0",
       "tabbable": null,
       "tooltip": null,
       "value": "\u200746045/46045\u2007[22:21&lt;00:00,\u200735.87it/s]"
      }
     },
     "d5961b5255294ba6a977c972faa46ada": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d81934d58eb44a7792056771240be023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f00403d59c2b43648c92c8e9dc702933": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f788273fabf64957a6db5c81f5281cd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}