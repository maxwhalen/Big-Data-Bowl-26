{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GroupKFold\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor, Pool \u001b[38;5;28;01mas\u001b[39;00m CatPool\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_gpu_device_count\n\u001b[1;32m     17\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
          ]
        }
      ],
      "source": [
        "# NFL Big Data Bowl 2026 - Model Analysis Notebook\n",
        "# Physics-Informed Residual Trajectory Network (PIRTN)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from catboost import CatBoostRegressor, Pool as CatPool\n",
        "from catboost.utils import get_gpu_device_count\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction\")\n",
        "WORK_DIR = Path(\"/kaggle/working\") if DATA_DIR.exists() else Path.cwd()\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Data dir exists:\", DATA_DIR.exists())\n",
        "print(\"Work dir:\", WORK_DIR)\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "except Exception as e:\n",
        "    print(\"Torch not available:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_test_template(test_input: pd.DataFrame, test_template: pd.DataFrame, models_x, models_y, feature_columns):\n",
        "    # Build last-frame features from observed test_input\n",
        "    feats = engineer_physics_features(test_input)\n",
        "    feats = add_sequence_features(feats)\n",
        "    feats = add_formation_features(feats)\n",
        "    feats = add_time_features(feats)\n",
        "    feats = add_motion_ema_features(feats)\n",
        "    feats = add_orientation_features(feats)\n",
        "    feats = add_geometric_features(feats)\n",
        "\n",
        "    gnn = compute_neighbor_embeddings(feats)\n",
        "\n",
        "    last_frames = (feats.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
        "                   .groupby(['game_id', 'play_id', 'nfl_id'], as_index=False)\n",
        "                   .tail(1)\n",
        "                   .rename(columns={'frame_id': 'last_frame_id'}))\n",
        "\n",
        "    last_frames = last_frames.merge(gnn, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
        "    if 'gnn_opp_dist_min' in last_frames.columns:\n",
        "        last_frames['pressure'] = 1.0 / (last_frames['gnn_opp_dist_min'] + 0.1)\n",
        "\n",
        "    # Expand to all required horizons in test.csv\n",
        "    future_rows = test_template.merge(last_frames, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
        "\n",
        "    future_rows['last_frame_id'] = future_rows['last_frame_id'].fillna(future_rows['frame_id'])\n",
        "    future_rows['delta_frames'] = (future_rows['frame_id'] - future_rows['last_frame_id']).clip(lower=0)\n",
        "    future_rows['delta_t'] = (future_rows['delta_frames'] / 10.0).fillna(0.0)\n",
        "    future_rows['waypoint_idx'] = (np.maximum(future_rows['delta_frames'] - 1, 0) // 10).astype(int)\n",
        "    future_rows['is_waypoint'] = (future_rows['delta_frames'] % 10 == 0).astype(int)\n",
        "\n",
        "    for col in feature_columns:\n",
        "        if col not in future_rows.columns:\n",
        "            future_rows[col] = 0\n",
        "\n",
        "    X_test = future_rows[feature_columns].fillna(0).values\n",
        "\n",
        "    baseline_x, baseline_y = steered_kinematics_baseline(\n",
        "        future_rows['x'].values,\n",
        "        future_rows['y'].values,\n",
        "        future_rows['velocity_x'].values,\n",
        "        future_rows['velocity_y'].values,\n",
        "        future_rows['ball_land_x'].values,\n",
        "        future_rows['ball_land_y'].values,\n",
        "        np.nan_to_num(future_rows['delta_t'].values, nan=0.0)\n",
        "    )\n",
        "\n",
        "    pred_rx = np.mean([m.predict(X_test) for m in models_x], axis=0)\n",
        "    pred_ry = np.mean([m.predict(X_test) for m in models_y], axis=0)\n",
        "\n",
        "    pred_x = np.clip(pred_rx + baseline_x, 0, 120)\n",
        "    pred_y = np.clip(pred_ry + baseline_y, 0, 53.3)\n",
        "\n",
        "    submission = test_template.copy()\n",
        "    submission['id'] = (submission['game_id'].astype(str) + '_' +\n",
        "                        submission['play_id'].astype(str) + '_' +\n",
        "                        submission['nfl_id'].astype(str) + '_' +\n",
        "                        submission['frame_id'].astype(str))\n",
        "    submission['x'] = pred_x\n",
        "    submission['y'] = pred_y\n",
        "    submission['x'] = submission['x'].fillna(0.0)\n",
        "    submission['y'] = submission['y'].fillna(0.0)\n",
        "    return submission[['id', 'x', 'y']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GroupKFold\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor, Pool \u001b[38;5;28;01mas\u001b[39;00m CatPool\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_gpu_device_count\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Paths like Sample Notebooks\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
          ]
        }
      ],
      "source": [
        "# Self-contained pipeline (reads from /kaggle/input and writes submission.csv)\n",
        "\n",
        "# Paths like Sample Notebooks\n",
        "DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction\")\n",
        "SAVE_PATH = Path(\"/kaggle/working/submission.csv\")\n",
        "\n",
        "# Fallback for local dry-runs (optional)\n",
        "if not DATA_DIR.exists():\n",
        "    DATA_DIR = Path.cwd() / \"kaggle\" / \"input\" / \"nfl-big-data-bowl-2026-prediction\"\n",
        "    SAVE_PATH = Path.cwd() / \"submission.csv\"\n",
        "\n",
        "# Config\n",
        "N_FOLDS = 5\n",
        "ITERATIONS = 10000\n",
        "LEARNING_RATE = 0.05\n",
        "DEPTH = 8\n",
        "L2_REG = 5.0\n",
        "EARLY_STOPPING = 800\n",
        "SEED = 42\n",
        "\n",
        "V_MAX = 7.5\n",
        "A_MAX = 3.0\n",
        "TURN_MAX_DEG = 120.0\n",
        "K_NEIGHBORS = 6\n",
        "RADIUS_LIMIT = 30.0\n",
        "TAU = 8.0\n",
        "try:\n",
        "    USE_GPU = get_gpu_device_count() > 0\n",
        "except Exception:\n",
        "    USE_GPU = False\n",
        "\n",
        "# Feature engineering\n",
        "\n",
        "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    if 'num_frames_output' in df.columns:\n",
        "        max_frames = df['num_frames_output']\n",
        "    else:\n",
        "        max_frames = pd.Series(df.groupby(['game_id','play_id'])['frame_id'].transform('max'), index=df.index).fillna(30)\n",
        "    df['max_play_duration'] = max_frames / 10.0\n",
        "    df['frame_time'] = df['frame_id'] / 10.0\n",
        "    df['progress_ratio'] = (df['frame_id'] / np.maximum(max_frames, 1)).clip(0.0, 1.0)\n",
        "    df['time_remaining'] = (max_frames - df['frame_id']) / 10.0\n",
        "    df['frames_remaining'] = (max_frames - df['frame_id']).clip(lower=0)\n",
        "\n",
        "    # Ball-expected position and errors\n",
        "    df['expected_x_at_ball'] = df['x'] + df['velocity_x'] * df['frame_time']\n",
        "    df['expected_y_at_ball'] = df['y'] + df['velocity_y'] * df['frame_time']\n",
        "    if 'ball_land_x' in df.columns:\n",
        "        df['error_from_ball_x'] = df['expected_x_at_ball'] - df['ball_land_x']\n",
        "        df['error_from_ball_y'] = df['expected_y_at_ball'] - df['ball_land_y']\n",
        "        df['error_from_ball'] = np.sqrt(df['error_from_ball_x']**2 + df['error_from_ball_y']**2)\n",
        "        df['weighted_dist_by_time'] = df['dist_to_ball'] / (df['frame_time'] + 0.1)\n",
        "        df['dist_scaled_by_progress'] = df['dist_to_ball'] * (1.0 - df['progress_ratio'])\n",
        "    df['time_squared'] = df['frame_time'] ** 2\n",
        "    df['velocity_x_progress'] = df['velocity_x'] * df['progress_ratio']\n",
        "    df['velocity_y_progress'] = df['velocity_y'] * df['progress_ratio']\n",
        "    df['speed_scaled_by_time_left'] = df['s'] * df['time_remaining']\n",
        "    df['actual_play_length'] = max_frames\n",
        "    df['length_ratio'] = max_frames / 30.0\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_motion_ema_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    g = df.groupby(['game_id','play_id','nfl_id'])\n",
        "    df['velocity_x_ema'] = g['velocity_x'].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n",
        "    df['velocity_y_ema'] = g['velocity_y'].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n",
        "    df['speed_ema'] = g['s'].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_orientation_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    # orientation vs movement and towards ball\n",
        "    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n",
        "    df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n",
        "    dir_rad = np.radians(df['dir'].fillna(0.0))\n",
        "    df['velocity_alignment'] = np.cos(df['angle_to_ball'] - dir_rad)\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_geometric_endpoint(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    # time to endpoint (seconds) from available num_frames_output; fallback 3.0s\n",
        "    if 'num_frames_output' in df.columns:\n",
        "        t_total = df['num_frames_output'] / 10.0\n",
        "    else:\n",
        "        t_total = pd.Series(3.0, index=df.index)\n",
        "    df['geo_time_to_endpoint'] = t_total\n",
        "\n",
        "    # default: momentum projection\n",
        "    df['geo_endpoint_x'] = df['x'] + df['velocity_x'] * t_total\n",
        "    df['geo_endpoint_y'] = df['y'] + df['velocity_y'] * t_total\n",
        "\n",
        "    # targeted receiver ‚Üí ball landing\n",
        "    if 'player_role' in df.columns:\n",
        "        recv_mask = (df['player_role'] == 'Targeted Receiver')\n",
        "        if 'ball_land_x' in df.columns:\n",
        "            df.loc[recv_mask, 'geo_endpoint_x'] = df.loc[recv_mask, 'ball_land_x']\n",
        "            df.loc[recv_mask, 'geo_endpoint_y'] = df.loc[recv_mask, 'ball_land_y']\n",
        "\n",
        "    # clip to field\n",
        "    df['geo_endpoint_x'] = df['geo_endpoint_x'].clip(0.0, 120.0)\n",
        "    df['geo_endpoint_y'] = df['geo_endpoint_y'].clip(0.0, 53.3)\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_geometric_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = compute_geometric_endpoint(df)\n",
        "    # vector to geometric endpoint\n",
        "    df['geo_vector_x'] = df['geo_endpoint_x'] - df['x']\n",
        "    df['geo_vector_y'] = df['geo_endpoint_y'] - df['y']\n",
        "    df['geo_distance'] = np.sqrt(df['geo_vector_x']**2 + df['geo_vector_y']**2)\n",
        "\n",
        "    # required velocity to reach endpoint\n",
        "    t = df['geo_time_to_endpoint'].fillna(3.0) + 0.1\n",
        "    df['geo_required_vx'] = df['geo_vector_x'] / t\n",
        "    df['geo_required_vy'] = df['geo_vector_y'] / t\n",
        "\n",
        "    # velocity error relative to geometric path\n",
        "    df['geo_velocity_error_x'] = df['geo_required_vx'] - df['velocity_x']\n",
        "    df['geo_velocity_error_y'] = df['geo_required_vy'] - df['velocity_y']\n",
        "    df['geo_velocity_error'] = np.sqrt(df['geo_velocity_error_x']**2 + df['geo_velocity_error_y']**2)\n",
        "\n",
        "    # required constant acceleration to endpoint a = 2*dx/t^2\n",
        "    t_sq = t * t\n",
        "    df['geo_required_ax'] = (2.0 * df['geo_vector_x'] / t_sq).clip(-10.0, 10.0)\n",
        "    df['geo_required_ay'] = (2.0 * df['geo_vector_y'] / t_sq).clip(-10.0, 10.0)\n",
        "\n",
        "    # alignment with geometric path\n",
        "    vel_mag = np.sqrt(df['velocity_x']**2 + df['velocity_y']**2) + 0.1\n",
        "    geo_unit_x = df['geo_vector_x'] / (df['geo_distance'] + 0.1)\n",
        "    geo_unit_y = df['geo_vector_y'] / (df['geo_distance'] + 0.1)\n",
        "    df['geo_alignment'] = (df['velocity_x'] * geo_unit_x + df['velocity_y'] * geo_unit_y) / vel_mag\n",
        "    return df\n",
        "\n",
        "def height_to_inches(h):\n",
        "    try:\n",
        "        ft, inch = map(int, str(h).split('-'))\n",
        "        return ft * 12 + inch\n",
        "    except Exception:\n",
        "        return 72.0\n",
        "\n",
        "\n",
        "def engineer_physics_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df['height_inches'] = df['player_height'].map(height_to_inches)\n",
        "    df['bmi'] = (df['player_weight'] / (df['height_inches']**2)) * 703.0\n",
        "\n",
        "    dir_rad = np.radians(df['dir'].fillna(0.0))\n",
        "    df['velocity_x'] = df['s'] * np.sin(dir_rad)\n",
        "    df['velocity_y'] = df['s'] * np.cos(dir_rad)\n",
        "    df['acceleration_x'] = df['a'] * np.cos(dir_rad)\n",
        "    df['acceleration_y'] = df['a'] * np.sin(dir_rad)\n",
        "\n",
        "    dx = df['ball_land_x'] - df['x']\n",
        "    dy = df['ball_land_y'] - df['y']\n",
        "    dist = np.sqrt(dx**2 + dy**2)\n",
        "    df['dist_to_ball'] = dist\n",
        "    df['angle_to_ball'] = np.arctan2(dy, dx)\n",
        "\n",
        "    ux = dx / (dist + 1e-6)\n",
        "    uy = dy / (dist + 1e-6)\n",
        "    vx = -uy\n",
        "    vy = ux\n",
        "\n",
        "    df['velocity_parallel'] = df['velocity_x'] * ux + df['velocity_y'] * uy\n",
        "    df['velocity_perpendicular'] = df['velocity_x'] * vx + df['velocity_y'] * vy\n",
        "    df['acceleration_parallel'] = df['acceleration_x'] * ux + df['acceleration_y'] * uy\n",
        "    df['acceleration_perpendicular'] = df['acceleration_x'] * vx + df['acceleration_y'] * vy\n",
        "\n",
        "    df['speed_squared'] = df['s'] ** 2\n",
        "    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n",
        "    df['momentum_x'] = df['player_weight'] * df['velocity_x']\n",
        "    df['momentum_y'] = df['player_weight'] * df['velocity_y']\n",
        "    df['kinetic_energy'] = 0.5 * df['player_weight'] * df['speed_squared']\n",
        "\n",
        "    df['role_targeted_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n",
        "    df['role_defensive_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n",
        "    df['role_passer'] = (df['player_role'] == 'Passer').astype(int)\n",
        "    df['side_offense'] = (df['player_side'] == 'Offense').astype(int)\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_sequence_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id']).copy()\n",
        "    g = ['game_id', 'play_id', 'nfl_id']\n",
        "\n",
        "    for lag in [1, 2, 3, 4, 5]:\n",
        "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a',\n",
        "                    'velocity_parallel', 'velocity_perpendicular',\n",
        "                    'acceleration_parallel', 'acceleration_perpendicular']:\n",
        "            if col in df.columns:\n",
        "                df[f'{col}_lag{lag}'] = df.groupby(g)[col].shift(lag)\n",
        "\n",
        "    for window in [3, 5]:\n",
        "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's',\n",
        "                    'velocity_parallel', 'velocity_perpendicular']:\n",
        "            if col in df.columns:\n",
        "                df[f'{col}_rolling_mean_{window}'] = (\n",
        "                    df.groupby(g)[col].rolling(window, min_periods=1).mean().reset_index(level=[0, 1, 2], drop=True)\n",
        "                )\n",
        "                df[f'{col}_rolling_std_{window}'] = (\n",
        "                    df.groupby(g)[col].rolling(window, min_periods=1).std().reset_index(level=[0, 1, 2], drop=True)\n",
        "                )\n",
        "\n",
        "    for col in ['velocity_x', 'velocity_y', 'velocity_parallel', 'velocity_perpendicular']:\n",
        "        if col in df.columns:\n",
        "            df[f'{col}_delta'] = df.groupby(g)[col].diff()\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_formation_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    grp = df.groupby(['game_id', 'play_id', 'frame_id', 'player_side'])\n",
        "    df['team_centroid_x'] = grp['x'].transform('mean')\n",
        "    df['team_centroid_y'] = grp['y'].transform('mean')\n",
        "    df['team_width'] = grp['y'].transform('std').fillna(0.0)\n",
        "    df['team_length'] = grp['x'].transform('std').fillna(0.0)\n",
        "\n",
        "    df['rel_centroid_x'] = df['x'] - df['team_centroid_x']\n",
        "    df['rel_centroid_y'] = df['y'] - df['team_centroid_y']\n",
        "\n",
        "    bearing = np.arctan2(df['ball_land_y'] - df['team_centroid_y'], df['ball_land_x'] - df['team_centroid_x'])\n",
        "    df['formation_bearing_sin'] = np.sin(bearing)\n",
        "    df['formation_bearing_cos'] = np.cos(bearing)\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_neighbor_embeddings(input_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cols = ['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y', 'velocity_x', 'velocity_y', 'player_side']\n",
        "    src = input_df[cols].copy()\n",
        "\n",
        "    last_frames = (src.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
        "                   .groupby(['game_id', 'play_id', 'nfl_id'], as_index=False)\n",
        "                   .tail(1)\n",
        "                   .rename(columns={'frame_id': 'last_frame_id'}))\n",
        "\n",
        "    neighbors = last_frames.merge(src.rename(columns={'frame_id': 'nb_frame_id', 'nfl_id': 'nfl_id_nb',\n",
        "                                                      'x': 'x_nb', 'y': 'y_nb',\n",
        "                                                      'velocity_x': 'vx_nb', 'velocity_y': 'vy_nb',\n",
        "                                                      'player_side': 'player_side_nb'}),\n",
        "                                  left_on=['game_id', 'play_id', 'last_frame_id'],\n",
        "                                  right_on=['game_id', 'play_id', 'nb_frame_id'], how='left')\n",
        "    neighbors = neighbors[neighbors['nfl_id_nb'] != neighbors['nfl_id']]\n",
        "\n",
        "    neighbors['dx'] = neighbors['x_nb'] - neighbors['x']\n",
        "    neighbors['dy'] = neighbors['y_nb'] - neighbors['y']\n",
        "    neighbors['dvx'] = neighbors['vx_nb'] - neighbors['velocity_x']\n",
        "    neighbors['dvy'] = neighbors['vy_nb'] - neighbors['velocity_y']\n",
        "    neighbors['dist'] = np.sqrt(neighbors['dx']**2 + neighbors['dy']**2)\n",
        "\n",
        "    neighbors = neighbors[np.isfinite(neighbors['dist']) & (neighbors['dist'] > 1e-6) & (neighbors['dist'] <= RADIUS_LIMIT)]\n",
        "    neighbors['is_ally'] = (neighbors['player_side_nb'].fillna(\"\") == neighbors['player_side'].fillna(\"\")).astype(float)\n",
        "\n",
        "    keys = ['game_id', 'play_id', 'nfl_id']\n",
        "    neighbors['rank'] = neighbors.groupby(keys)['dist'].rank(method='first')\n",
        "    neighbors = neighbors[neighbors['rank'] <= K_NEIGHBORS]\n",
        "\n",
        "    neighbors['weight'] = np.exp(-neighbors['dist'] / TAU)\n",
        "    sumw = neighbors.groupby(keys)['weight']. transform('sum')\n",
        "    neighbors['weight_norm'] = np.where(sumw > 0, neighbors['weight'] / sumw, 0.0)\n",
        "\n",
        "    neighbors['weight_ally'] = neighbors['weight_norm'] * neighbors['is_ally']\n",
        "    neighbors['weight_opp'] = neighbors['weight_norm'] * (1.0 - neighbors['is_ally'])\n",
        "\n",
        "    for c in ['dx', 'dy', 'dvx', 'dvy']:\n",
        "        neighbors[f'{c}_ally_weighted'] = neighbors[c] * neighbors['weight_ally']\n",
        "        neighbors[f'{c}_opp_weighted'] = neighbors[c] * neighbors['weight_opp']\n",
        "\n",
        "    emb = neighbors.groupby(keys).agg(\n",
        "        gnn_ally_dx_mean=('dx_ally_weighted', 'sum'),\n",
        "        gnn_ally_dy_mean=('dy_ally_weighted', 'sum'),\n",
        "        gnn_ally_dvx_mean=('dvx_ally_weighted', 'sum'),\n",
        "        gnn_ally_dvy_mean=('dvy_ally_weighted', 'sum'),\n",
        "        gnn_opp_dx_mean=('dx_opp_weighted', 'sum'),\n",
        "        gnn_opp_dy_mean=('dy_opp_weighted', 'sum'),\n",
        "        gnn_opp_dvx_mean=('dvx_opp_weighted', 'sum'),\n",
        "        gnn_opp_dvy_mean=('dvy_opp_weighted', 'sum'),\n",
        "        gnn_ally_count=('is_ally', 'sum'),\n",
        "        gnn_opp_count=('is_ally', lambda x: len(x) - x.sum()),\n",
        "        gnn_ally_dist_min=('dist', lambda x: x[neighbors.loc[x.index, 'is_ally'] > 0.5].min() if (neighbors.loc[x.index, 'is_ally'] > 0.5).any() else RADIUS_LIMIT),\n",
        "        gnn_opp_dist_min=('dist', lambda x: x[neighbors.loc[x.index, 'is_ally'] < 0.5].min() if (neighbors.loc[x.index, 'is_ally'] < 0.5).any() else RADIUS_LIMIT)\n",
        "    ).reset_index()\n",
        "\n",
        "    for c in ['gnn_ally_dx_mean', 'gnn_ally_dy_mean', 'gnn_ally_dvx_mean', 'gnn_ally_dvy_mean', 'gnn_opp_dx_mean', 'gnn_opp_dy_mean', 'gnn_opp_dvx_mean', 'gnn_opp_dvy_mean']:\n",
        "        emb[c] = emb[c].fillna(0.0)\n",
        "    for c in ['gnn_ally_count', 'gnn_opp_count']:\n",
        "        emb[c] = emb[c].fillna(0.0)\n",
        "    for c in ['gnn_ally_dist_min', 'gnn_opp_dist_min']:\n",
        "        emb[c] = emb[c].fillna(RADIUS_LIMIT)\n",
        "    return emb\n",
        "\n",
        "# Physics baseline\n",
        "\n",
        "def steered_kinematics_baseline(x, y, vx, vy, ball_x, ball_y, dt, v_max=V_MAX, a_max=A_MAX, turn_rate_max_deg=TURN_MAX_DEG):\n",
        "    eps = 1e-6\n",
        "    speed = np.sqrt(vx**2 + vy**2)\n",
        "    cur_dir = np.where(speed > eps, np.arctan2(vx, vy), np.arctan2(ball_y - y, ball_x - x))\n",
        "    desired_dir = np.arctan2(ball_y - y, ball_x - x)\n",
        "\n",
        "    ang_diff = (desired_dir - cur_dir + np.pi) % (2 * np.pi) - np.pi\n",
        "    max_turn = np.radians(turn_rate_max_deg) * dt\n",
        "    ang_step = np.clip(ang_diff, -max_turn, max_turn)\n",
        "    new_dir = cur_dir + ang_step\n",
        "\n",
        "    target_speed = np.minimum(v_max, speed + a_max * dt)\n",
        "    vx_new = target_speed * np.sin(new_dir)\n",
        "    vy_new = target_speed * np.cos(new_dir)\n",
        "\n",
        "    pred_x = x + 0.5 * (vx + vx_new) * dt\n",
        "    pred_y = y + 0.5 * (vy + vy_new) * dt\n",
        "\n",
        "    pred_x = np.clip(pred_x, 0.0, 120.0)\n",
        "    pred_y = np.clip(pred_y, 0.0, 53.3)\n",
        "    return pred_x, pred_y\n",
        "\n",
        "# Feature list\n",
        "\n",
        "def build_feature_list(df: pd.DataFrame):\n",
        "    base = [\n",
        "        'x', 'y', 's', 'a', 'o', 'dir',\n",
        "        'velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y',\n",
        "        'velocity_parallel', 'velocity_perpendicular',\n",
        "        'acceleration_parallel', 'acceleration_perpendicular',\n",
        "        'player_weight', 'height_inches', 'bmi',\n",
        "        'ball_land_x', 'ball_land_y', 'dist_to_ball', 'angle_to_ball',\n",
        "        'speed_squared', 'accel_magnitude', 'momentum_x', 'momentum_y', 'kinetic_energy',\n",
        "        'role_targeted_receiver', 'role_defensive_coverage', 'role_passer', 'side_offense',\n",
        "        'team_centroid_x', 'team_centroid_y', 'team_width', 'team_length',\n",
        "        'rel_centroid_x', 'rel_centroid_y', 'formation_bearing_sin', 'formation_bearing_cos',\n",
        "        'delta_frames', 'delta_t', 'frame_id', 'waypoint_idx', 'is_waypoint',\n",
        "        'pressure'\n",
        "    ]\n",
        "    # Geometric features (inspired by leader notebook)\n",
        "    geo = [\n",
        "        'geo_time_to_endpoint', 'geo_endpoint_x', 'geo_endpoint_y',\n",
        "        'geo_vector_x', 'geo_vector_y', 'geo_distance',\n",
        "        'geo_required_vx', 'geo_required_vy',\n",
        "        'geo_velocity_error_x', 'geo_velocity_error_y', 'geo_velocity_error',\n",
        "        'geo_required_ax', 'geo_required_ay', 'geo_alignment'\n",
        "    ]\n",
        "    gnn = [c for c in df.columns if c.startswith('gnn_')]\n",
        "\n",
        "    lags = []\n",
        "    for lag in [1, 2, 3, 4, 5]:\n",
        "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a',\n",
        "                    'velocity_parallel', 'velocity_perpendicular',\n",
        "                    'acceleration_parallel', 'acceleration_perpendicular']:\n",
        "            lags.append(f'{col}_lag{lag}')\n",
        "\n",
        "    rolls = []\n",
        "    for window in [3, 5]:\n",
        "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's',\n",
        "                    'velocity_parallel', 'velocity_perpendicular']:\n",
        "            rolls.extend([f'{col}_rolling_mean_{window}', f'{col}_rolling_std_{window}'])\n",
        "\n",
        "    deltas = ['velocity_x_delta', 'velocity_y_delta', 'velocity_parallel_delta', 'velocity_perpendicular_delta']\n",
        "\n",
        "    all_cols = base + geo + gnn + lags + rolls + deltas\n",
        "    return [c for c in all_cols if c in df.columns]\n",
        "\n",
        "# Prepare training data\n",
        "\n",
        "def prepare_training_data(input_df: pd.DataFrame, output_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feats = engineer_physics_features(input_df)\n",
        "    feats = add_sequence_features(feats)\n",
        "    feats = add_formation_features(feats)\n",
        "    feats = add_time_features(feats)\n",
        "    feats = add_motion_ema_features(feats)\n",
        "    feats = add_orientation_features(feats)\n",
        "    feats = add_geometric_features(feats)\n",
        "\n",
        "    gnn = compute_neighbor_embeddings(feats)\n",
        "\n",
        "    last_frames = (feats.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
        "                   .groupby(['game_id', 'play_id', 'nfl_id'], as_index=False)\n",
        "                   .tail(1)\n",
        "                   .rename(columns={'frame_id': 'last_frame_id'}))\n",
        "\n",
        "    last_frames = last_frames.merge(gnn, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
        "    # pressure from nearest opponent distance\n",
        "    if 'gnn_opp_dist_min' in last_frames.columns:\n",
        "        last_frames['pressure'] = 1.0 / (last_frames['gnn_opp_dist_min'] + 0.1)\n",
        "\n",
        "    out = output_df.rename(columns={'x': 'target_x', 'y': 'target_y'}).copy()\n",
        "\n",
        "    train = out.merge(last_frames, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
        "    train['delta_frames'] = (train['frame_id'] - train['last_frame_id']).clip(lower=0)\n",
        "    train['delta_t'] = train['delta_frames'] / 10.0\n",
        "    train['waypoint_idx'] = (np.maximum(train['delta_frames'] - 1, 0) // 10).astype(int)\n",
        "    train['is_waypoint'] = (train['delta_frames'] % 10 == 0).astype(int)\n",
        "    return train\n",
        "\n",
        "# Train CatBoost residual models\n",
        "\n",
        "def train_catboost_models(training_data: pd.DataFrame):\n",
        "    features = build_feature_list(training_data)\n",
        "    X = training_data[features].fillna(0).values\n",
        "    y_x = training_data['target_x'].values\n",
        "    y_y = training_data['target_y'].values\n",
        "\n",
        "    baseline_x, baseline_y = steered_kinematics_baseline(\n",
        "        training_data['x'].values,\n",
        "        training_data['y'].values,\n",
        "        training_data['velocity_x'].values,\n",
        "        training_data['velocity_y'].values,\n",
        "        training_data['ball_land_x'].values,\n",
        "        training_data['ball_land_y'].values,\n",
        "        training_data['delta_t'].values\n",
        "    )\n",
        "    residual_x = y_x - baseline_x\n",
        "    residual_y = y_y - baseline_y\n",
        "\n",
        "    groups = training_data['game_id'].astype(str) + '_' + training_data['play_id'].astype(str)\n",
        "    gkf = GroupKFold(n_splits=N_FOLDS)\n",
        "\n",
        "    params = {\n",
        "        'iterations': ITERATIONS,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'depth': DEPTH,\n",
        "        'l2_leaf_reg': L2_REG,\n",
        "        'random_seed': SEED,\n",
        "        'task_type': 'GPU' if USE_GPU else 'CPU',\n",
        "        'loss_function': 'RMSE',\n",
        "        'early_stopping_rounds': EARLY_STOPPING,\n",
        "        'verbose': 200\n",
        "    }\n",
        "\n",
        "    models_x, models_y, fold_scores = [], [], []\n",
        "\n",
        "    for fold, (tr, va) in enumerate(gkf.split(X, groups=groups), 1):\n",
        "        print(f\"\\nFold {fold}/{N_FOLDS}\")\n",
        "        X_tr, X_va = X[tr], X[va]\n",
        "        yx_tr, yx_va = residual_x[tr], residual_x[va]\n",
        "        yy_tr, yy_va = residual_y[tr], residual_y[va]\n",
        "\n",
        "        mx = CatBoostRegressor(**params)\n",
        "        my = CatBoostRegressor(**params)\n",
        "        mx.fit(CatPool(X_tr, yx_tr), eval_set=CatPool(X_va, yx_va))\n",
        "        my.fit(CatPool(X_tr, yy_tr), eval_set=CatPool(X_va, yy_va))\n",
        "\n",
        "        models_x.append(mx)\n",
        "        models_y.append(my)\n",
        "\n",
        "        pred_rx = mx.predict(X_va)\n",
        "        pred_ry = my.predict(X_va)\n",
        "        pred_x = np.clip(pred_rx + baseline_x[va], 0, 120)\n",
        "        pred_y = np.clip(pred_ry + baseline_y[va], 0, 53.3)\n",
        "        rmse = math.sqrt(0.5 * (mean_squared_error(y_x[va], pred_x) + mean_squared_error(y_y[va], pred_y)))\n",
        "        print(f\"Fold {fold} RMSE: {rmse:.5f}\")\n",
        "        fold_scores.append(rmse)\n",
        "\n",
        "    print(f\"\\nCV Scores: {[f'{s:.5f}' for s in fold_scores]}\")\n",
        "    print(f\"Mean CV RMSE: {np.mean(fold_scores):.5f} ¬± {np.std(fold_scores):.5f}\")\n",
        "    return models_x, models_y, features\n",
        "\n",
        "# Predict test\n",
        "\n",
        "def predict_test(test_input: pd.DataFrame, test_template: pd.DataFrame, models_x, models_y, feature_columns):\n",
        "    feats = engineer_physics_features(test_input)\n",
        "    feats = add_sequence_features(feats)\n",
        "    feats = add_formation_features(feats)\n",
        "    feats = add_time_features(feats)\n",
        "    feats = add_motion_ema_features(feats)\n",
        "    feats = add_orientation_features(feats)\n",
        "    feats = add_geometric_features(feats)\n",
        "\n",
        "    gnn = compute_neighbor_embeddings(feats)\n",
        "\n",
        "    last_frames = (feats.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
        "                   .groupby(['game_id', 'play_id', 'nfl_id'], as_index=False)\n",
        "                   .tail(1)\n",
        "                   .rename(columns={'frame_id': 'last_frame_id'}))\n",
        "\n",
        "    last_frames = last_frames.merge(gnn, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
        "    # pressure from nearest opponent distance\n",
        "    if 'gnn_opp_dist_min' in last_frames.columns:\n",
        "        last_frames['pressure'] = 1.0 / (last_frames['gnn_opp_dist_min'] + 0.1)\n",
        "\n",
        "    test_prepared = test_input.merge(last_frames, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
        "\n",
        "    # Fill missing last_frame_id with current frame to ensure zero delta\n",
        "    test_prepared['last_frame_id'] = test_prepared['last_frame_id'].fillna(test_prepared['frame_id'])\n",
        "    test_prepared['delta_frames'] = (test_prepared['frame_id'] - test_prepared['last_frame_id']).clip(lower=0)\n",
        "    test_prepared['delta_t'] = (test_prepared['delta_frames'] / 10.0).fillna(0.0)\n",
        "    test_prepared['waypoint_idx'] = (np.maximum(test_prepared['delta_frames'] - 1, 0) // 10).astype(int)\n",
        "    test_prepared['is_waypoint'] = (test_prepared['delta_frames'] % 10 == 0).astype(int)\n",
        "\n",
        "    for col in feature_columns:\n",
        "        if col not in test_prepared.columns:\n",
        "            test_prepared[col] = 0\n",
        "\n",
        "    X_test = test_prepared[feature_columns].fillna(0).values\n",
        "\n",
        "    baseline_x, baseline_y = steered_kinematics_baseline(\n",
        "        test_prepared['x'].values,\n",
        "        test_prepared['y'].values,\n",
        "        test_prepared['velocity_x'].values,\n",
        "        test_prepared['velocity_y'].values,\n",
        "        test_prepared['ball_land_x'].values,\n",
        "        test_prepared['ball_land_y'].values,\n",
        "        np.nan_to_num(test_prepared['delta_t'].values, nan=0.0)\n",
        "    )\n",
        "\n",
        "    pred_rx = np.mean([m.predict(X_test) for m in models_x], axis=0)\n",
        "    pred_ry = np.mean([m.predict(X_test) for m in models_y], axis=0)\n",
        "\n",
        "    pred_x = np.clip(pred_rx + baseline_x, 0, 120)\n",
        "    pred_y = np.clip(pred_ry + baseline_y, 0, 53.3)\n",
        "\n",
        "    # Build id for all rows in test_input\n",
        "    pred_df = pd.DataFrame({\n",
        "        'id': test_input['game_id'].astype(str) + '_' + test_input['play_id'].astype(str) + '_' + test_input['nfl_id'].astype(str) + '_' + test_input['frame_id'].astype(str),\n",
        "        'x': pred_x,\n",
        "        'y': pred_y\n",
        "    })\n",
        "\n",
        "    # Create submission in exact test_template order\n",
        "    sub_ids = (test_template['game_id'].astype(str) + '_' +\n",
        "               test_template['play_id'].astype(str) + '_' +\n",
        "               test_template['nfl_id'].astype(str) + '_' +\n",
        "               test_template['frame_id'].astype(str))\n",
        "\n",
        "    submission = pd.DataFrame({'id': sub_ids})\n",
        "    submission = submission.merge(pred_df, on='id', how='left')\n",
        "\n",
        "    # Any missing predictions default to zeros (rare)\n",
        "    submission['x'] = submission['x'].fillna(0.0)\n",
        "    submission['y'] = submission['y'].fillna(0.0)\n",
        "    return submission\n",
        "\n",
        "# Load data exactly like Sample Notebooks\n",
        "print(\"\\n[1/3] Loading data...\")\n",
        "train_input_files = [DATA_DIR / f\"train/input_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
        "train_output_files = [DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
        "\n",
        "train_input = pd.concat([pd.read_csv(f) for f in train_input_files if f.exists()])\n",
        "train_output = pd.concat([pd.read_csv(f) for f in train_output_files if f.exists()])\n",
        "\n",
        "test_input = pd.read_csv(DATA_DIR / \"test_input.csv\")\n",
        "test_template = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "\n",
        "print(\"[2/3] Preparing training data and training CatBoost (residuals)...\")\n",
        "training_data = prepare_training_data(train_input, train_output)\n",
        "models_x, models_y, feature_columns = train_catboost_models(training_data)\n",
        "\n",
        "print(\"[3/3] Predicting on test and writing submission.csv ...\")\n",
        "submission = predict_test_template(test_input, test_template, models_x, models_y, feature_columns)\n",
        "submission = submission[['id', 'x', 'y']].astype({'id': str, 'x': float, 'y': float})\n",
        "submission.to_csv(SAVE_PATH, index=False)\n",
        "print(f\"Saved submission to {SAVE_PATH}\")\n",
        "\n",
        "# Kaggle expects a root-level submission.csv\n",
        "if str(SAVE_PATH) != 'submission.csv':\n",
        "    try:\n",
        "        import shutil\n",
        "        shutil.copy(str(SAVE_PATH), 'submission.csv')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# After Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MODEL PERFORMANCE ANALYSIS & VISUALIZATION\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL PERFORMANCE ANALYSIS ON TRAINING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Prepare training data for prediction\n",
        "print(\"\\n[1/4] Preparing training data for model evaluation...\")\n",
        "train_eval_data = prepare_training_data(train_input, train_output)\n",
        "\n",
        "# Get predictions on training data\n",
        "print(\"[2/4] Generating predictions on training data...\")\n",
        "features = build_feature_list(train_eval_data)\n",
        "X_train = train_eval_data[features].fillna(0).values\n",
        "\n",
        "# Get baseline predictions\n",
        "baseline_x, baseline_y = steered_kinematics_baseline(\n",
        "    train_eval_data['x'].values,\n",
        "    train_eval_data['y'].values,\n",
        "    train_eval_data['velocity_x'].values,\n",
        "    train_eval_data['velocity_y'].values,\n",
        "    train_eval_data['ball_land_x'].values,\n",
        "    train_eval_data['ball_land_y'].values,\n",
        "    train_eval_data['delta_t'].values\n",
        ")\n",
        "\n",
        "# Get model predictions (residuals)\n",
        "pred_rx = np.mean([m.predict(X_train) for m in models_x], axis=0)\n",
        "pred_ry = np.mean([m.predict(X_train) for m in models_y], axis=0)\n",
        "\n",
        "# Combine baseline + residuals for final predictions\n",
        "pred_x = np.clip(pred_rx + baseline_x, 0, 120)\n",
        "pred_y = np.clip(pred_ry + baseline_y, 0, 53.3)\n",
        "\n",
        "# Calculate errors\n",
        "actual_x = train_eval_data['target_x'].values\n",
        "actual_y = train_eval_data['target_y'].values\n",
        "error_x = pred_x - actual_x\n",
        "error_y = pred_y - actual_y\n",
        "error_distance = np.sqrt(error_x**2 + error_y**2)\n",
        "\n",
        "# Add predictions and errors to dataframe\n",
        "train_eval_data = train_eval_data.copy()\n",
        "train_eval_data['pred_x'] = pred_x\n",
        "train_eval_data['pred_y'] = pred_y\n",
        "train_eval_data['error_x'] = error_x\n",
        "train_eval_data['error_y'] = error_y\n",
        "train_eval_data['error_distance'] = error_distance\n",
        "\n",
        "print(\"[3/4] Analyzing worst predictions by player and play...\")\n",
        "\n",
        "# Calculate cumulative residuals per player per play (adjusted for play length)\n",
        "play_analysis = train_eval_data.groupby(['game_id', 'play_id', 'nfl_id']).agg({\n",
        "    'error_distance': ['sum', 'mean', 'max', 'count'],\n",
        "    'delta_t': 'max',  # Play duration\n",
        "    'player_name': 'first',\n",
        "    'player_position': 'first',\n",
        "    'player_role': 'first'\n",
        "}).round(4)\n",
        "\n",
        "# Flatten column names\n",
        "play_analysis.columns = ['cumulative_error', 'mean_error', 'max_error', 'frame_count', 'play_duration', 'player_name', 'position', 'role']\n",
        "\n",
        "# Adjust for play length: longer plays naturally have higher cumulative errors\n",
        "# Normalize by play duration and frame count\n",
        "play_analysis['error_per_second'] = play_analysis['cumulative_error'] / (play_analysis['play_duration'] + 0.1)\n",
        "play_analysis['error_per_frame'] = play_analysis['cumulative_error'] / (play_analysis['frame_count'] + 0.1)\n",
        "\n",
        "# Create a composite score that balances cumulative error with play length\n",
        "play_analysis['problem_score'] = (\n",
        "    play_analysis['cumulative_error'] * 0.4 +  # Raw cumulative error\n",
        "    play_analysis['error_per_second'] * 0.3 +  # Error rate per second\n",
        "    play_analysis['max_error'] * 0.3           # Worst single prediction\n",
        ")\n",
        "\n",
        "# Sort by problem score (highest = most problematic)\n",
        "worst_predictions = play_analysis.sort_values('problem_score', ascending=False).head(20)\n",
        "\n",
        "print(f\"\\nüèÜ TOP 20 MOST PROBLEMATIC PREDICTIONS:\")\n",
        "print(\"=\"*100)\n",
        "print(f\"{'Rank':<4} {'Player':<20} {'Pos':<4} {'Role':<15} {'Game':<8} {'Play':<6} {'CumError':<10} {'MaxError':<10} {'Frames':<6} {'Duration':<8} {'Score':<8}\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "for i, (idx, row) in enumerate(worst_predictions.iterrows(), 1):\n",
        "    game_id, play_id, nfl_id = idx\n",
        "    print(f\"{i:<4} {row['player_name']:<20} {row['position']:<4} {row['role']:<15} {game_id:<8} {play_id:<6} {row['cumulative_error']:<10.2f} {row['max_error']:<10.2f} {row['frame_count']:<6.0f} {row['play_duration']:<8.2f} {row['problem_score']:<8.2f}\")\n",
        "\n",
        "print(f\"\\nüìä SUMMARY STATISTICS:\")\n",
        "print(f\"  ‚Ä¢ Total plays analyzed: {len(play_analysis):,}\")\n",
        "print(f\"  ‚Ä¢ Mean cumulative error: {play_analysis['cumulative_error'].mean():.2f} yards\")\n",
        "print(f\"  ‚Ä¢ Mean error per second: {play_analysis['error_per_second'].mean():.2f} yards/sec\")\n",
        "print(f\"  ‚Ä¢ Worst single prediction: {play_analysis['max_error'].max():.2f} yards\")\n",
        "print(f\"  ‚Ä¢ Most problematic player: {worst_predictions.iloc[0]['player_name']} (Score: {worst_predictions.iloc[0]['problem_score']:.2f})\")\n",
        "\n",
        "# Show the worst prediction details\n",
        "worst_idx = worst_predictions.index[0]\n",
        "worst_details = train_eval_data[\n",
        "    (train_eval_data['game_id'] == worst_idx[0]) & \n",
        "    (train_eval_data['play_id'] == worst_idx[1]) & \n",
        "    (train_eval_data['nfl_id'] == worst_idx[2])\n",
        "].sort_values('frame_id')\n",
        "\n",
        "print(f\"\\nüîç DETAILED BREAKDOWN OF WORST PREDICTION:\")\n",
        "print(f\"   Player: {worst_predictions.iloc[0]['player_name']} ({worst_predictions.iloc[0]['position']})\")\n",
        "print(f\"   Game: {worst_idx[0]}, Play: {worst_idx[1]}\")\n",
        "print(f\"   Role: {worst_predictions.iloc[0]['role']}\")\n",
        "print(f\"   Play Duration: {worst_predictions.iloc[0]['play_duration']:.2f}s ({worst_predictions.iloc[0]['frame_count']:.0f} frames)\")\n",
        "print(f\"   Cumulative Error: {worst_predictions.iloc[0]['cumulative_error']:.2f} yards\")\n",
        "print(f\"   Max Single Error: {worst_predictions.iloc[0]['max_error']:.2f} yards\")\n",
        "\n",
        "print(f\"\\n   Frame-by-frame errors:\")\n",
        "print(f\"   {'Frame':<6} {'Actual X':<8} {'Pred X':<8} {'Actual Y':<8} {'Pred Y':<8} {'Error':<8}\")\n",
        "print(f\"   {'-'*6} {'-'*8} {'-'*8} {'-'*8} {'-'*8} {'-'*8}\")\n",
        "for _, row in worst_details.head(10).iterrows():\n",
        "    print(f\"   {row['frame_id']:<6.0f} {row['target_x']:<8.2f} {row['pred_x']:<8.2f} {row['target_y']:<8.2f} {row['pred_y']:<8.2f} {row['error_distance']:<8.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PLAYER MOVEMENT VISUALIZATION\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üèà PLAYER MOVEMENT VISUALIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Additional imports for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.lines import Line2D\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "# Role colors for visualization\n",
        "ROLE_COLORS = {\n",
        "    \"Targeted Receiver\": \"red\",\n",
        "    \"Passer\": \"blue\", \n",
        "    \"Defensive Coverage\": \"darkred\",\n",
        "    \"Other Route Runner\": \"orange\",\n",
        "}\n",
        "\n",
        "def draw_field(ax, start_x=0.0, end_x=120.0, play_direction=\"right\"):\n",
        "    \"\"\"Draw an NFL field with endzones, yard lines, and hash marks.\"\"\"\n",
        "    field_len = end_x - start_x\n",
        "    left_goal, right_goal = start_x + 10.0, end_x - 10.0\n",
        "\n",
        "    # Field + endzones\n",
        "    if play_direction == \"right\":\n",
        "        left_color, right_color = \"lightblue\", \"#f4cccc\"\n",
        "    else:\n",
        "        left_color, right_color = \"#f4cccc\", \"lightblue\"\n",
        "    ax.add_patch(Rectangle((start_x, 0), field_len, 53.3, facecolor='forestgreen', edgecolor='black', lw=2, zorder=0))\n",
        "    ax.add_patch(Rectangle((start_x, 0), 10, 53.3, facecolor=left_color, zorder=1))\n",
        "    ax.add_patch(Rectangle((end_x - 10, 0), 10, 53.3, facecolor=right_color, zorder=1))\n",
        "\n",
        "    # Sideline ticks\n",
        "    for x in np.arange(start_x, end_x + 0.1, 1.0):\n",
        "        for y in [0.4, 53.3 - 0.4]:\n",
        "            ax.plot([x, x], [y, y + 0.5], color='white', lw=0.4, zorder=2)\n",
        "\n",
        "    # Yard lines\n",
        "    for x in np.arange(start_x + 10.0, end_x, 10.0):\n",
        "        ax.plot([x, x], [0, 53.3], color='white', lw=1.6, zorder=2)\n",
        "\n",
        "    # Yard numbers\n",
        "    num_positions = np.arange(start_x + 20.0, end_x - 9.99, 10.0)\n",
        "    for p in num_positions:\n",
        "        d = p - left_goal\n",
        "        label = int(min(d, 100.0 - d))\n",
        "        ax.text(p, 5, str(label), color='white', fontsize=12, ha='center', va='center')\n",
        "        ax.text(p, 53.3 - 5, str(label), color='white', fontsize=12, ha='center', va='center')\n",
        "\n",
        "    # Inbounds hash marks (subtle, semi-transparent)\n",
        "    hash_y = [18.37, 34.93]\n",
        "    for x in np.arange(start_x + 10, end_x - 10 + 0.1, 1.0):\n",
        "        for y in hash_y:\n",
        "            ax.plot([x, x], [y, y + 0.4], color='white', lw=0.8, alpha=0.5, zorder=2)\n",
        "\n",
        "    # Limits / aspect\n",
        "    ax.set_xlim(start_x, end_x)\n",
        "    ax.set_ylim(0, 53.3)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.axis('off')\n",
        "\n",
        "def draw_legend(ax):\n",
        "    \"\"\"Legend for player roles.\"\"\"\n",
        "    handles = [Line2D([0], [0], marker='o', color='w', label=role,\n",
        "                      markerfacecolor=color, markersize=10)\n",
        "               for role, color in ROLE_COLORS.items()]\n",
        "    ax.legend(handles=handles, loc='upper center', bbox_to_anchor=(0.5, 1.07),\n",
        "              ncol=len(handles), framealpha=0.9, frameon=False)\n",
        "\n",
        "def visualize_play_with_predictions(game_id, play_id, df_in, df_out, train_eval_data, \n",
        "                                   show_predictions=True, figsize=(15, 6), subsample=1):\n",
        "    \"\"\"Visualize a play with actual vs predicted trajectories.\"\"\"\n",
        "    \n",
        "    # Get input data\n",
        "    in_play = df_in.query(\"game_id==@game_id & play_id==@play_id\").sort_values(\"frame_id\")\n",
        "    out_play = df_out.query(\"game_id==@game_id & play_id==@play_id\").sort_values(\"frame_id\")\n",
        "    play_dir = in_play.play_direction.iloc[0]\n",
        "    \n",
        "    # Get predictions for this play\n",
        "    play_predictions = train_eval_data[\n",
        "        (train_eval_data['game_id'] == game_id) & \n",
        "        (train_eval_data['play_id'] == play_id)\n",
        "    ].sort_values('frame_id')\n",
        "    \n",
        "    if subsample > 1:\n",
        "        in_play = in_play[in_play[\"frame_id\"] % subsample == 0]\n",
        "        if not out_play.empty:\n",
        "            out_play = out_play[out_play[\"frame_id\"] % subsample == 0]\n",
        "        play_predictions = play_predictions[play_predictions[\"frame_id\"] % subsample == 0]\n",
        "\n",
        "    # Build frames\n",
        "    frames = []\n",
        "    for frame_id in sorted(in_play.frame_id.unique()):\n",
        "        frame_data = []\n",
        "        \n",
        "        # Add actual positions\n",
        "        frame_in = in_play[in_play.frame_id == frame_id]\n",
        "        for _, r in frame_in.iterrows():\n",
        "            frame_data.append({\n",
        "                'x': r.x, 'y': r.y,\n",
        "                'color': ROLE_COLORS.get(r.player_role, 'gray'),\n",
        "                'nfl_id': r.nfl_id,\n",
        "                'o': getattr(r, \"o\", None),\n",
        "                'type': 'actual'\n",
        "            })\n",
        "        \n",
        "        # Add predicted positions if available\n",
        "        if show_predictions and not play_predictions.empty:\n",
        "            frame_pred = play_predictions[play_predictions.frame_id == frame_id]\n",
        "            for _, r in frame_pred.iterrows():\n",
        "                frame_data.append({\n",
        "                    'x': r.pred_x, 'y': r.pred_y,\n",
        "                    'color': ROLE_COLORS.get(r.player_role, 'gray'),\n",
        "                    'nfl_id': f\"{r.nfl_id}_pred\",\n",
        "                    'o': None,\n",
        "                    'type': 'predicted',\n",
        "                    'error': r.error_distance\n",
        "                })\n",
        "        \n",
        "        # Add output data (future frames)\n",
        "        if not out_play.empty:\n",
        "            frame_out = out_play[out_play.frame_id == frame_id]\n",
        "            for _, r in frame_out.iterrows():\n",
        "                frame_data.append({\n",
        "                    'x': r.x, 'y': r.y,\n",
        "                    'color': 'black',\n",
        "                    'nfl_id': f\"{r.nfl_id}_future\",\n",
        "                    'o': None,\n",
        "                    'type': 'future'\n",
        "                })\n",
        "        \n",
        "        frames.append(frame_data)\n",
        "\n",
        "    # Create visualization\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
        "    \n",
        "    # Left plot: Input frames only\n",
        "    draw_field(ax1, play_direction=play_dir)\n",
        "    draw_legend(ax1)\n",
        "    ax1.set_title(f\"Input Frames - Game: {game_id}, Play: {play_id}\", fontsize=12, fontweight=\"bold\")\n",
        "    \n",
        "    # Right plot: Predictions vs Actual\n",
        "    draw_field(ax2, play_direction=play_dir)\n",
        "    draw_legend(ax2)\n",
        "    ax2.set_title(\"Predictions vs Actual (Future Frames)\", fontsize=12, fontweight=\"bold\")\n",
        "    \n",
        "    # Plot static positions\n",
        "    input_frames = [f for f in frames if any(p['type'] == 'actual' for p in f)]\n",
        "    pred_frames = [f for f in frames if any(p['type'] == 'predicted' for p in f)]\n",
        "    \n",
        "    if input_frames:\n",
        "        input_data = input_frames[-1]  # Last input frame\n",
        "        actual_x = [p['x'] for p in input_data if p['type'] == 'actual']\n",
        "        actual_y = [p['y'] for p in input_data if p['type'] == 'actual']\n",
        "        actual_colors = [p['color'] for p in input_data if p['type'] == 'actual']\n",
        "        ax1.scatter(actual_x, actual_y, c=actual_colors, s=100, zorder=5)\n",
        "        \n",
        "        # Add player IDs\n",
        "        for p in input_data:\n",
        "            if p['type'] == 'actual':\n",
        "                ax1.text(p['x'] + 0.5, p['y'] + 0.5, str(p['nfl_id']), \n",
        "                        fontsize=8, ha='center', va='center', zorder=6)\n",
        "    \n",
        "    if pred_frames:\n",
        "        pred_data = pred_frames[0]  # First prediction frame\n",
        "        pred_x = [p['x'] for p in pred_data if p['type'] == 'predicted']\n",
        "        pred_y = [p['y'] for p in pred_data if p['type'] == 'predicted']\n",
        "        pred_colors = [p['color'] for p in pred_data if p['type'] == 'predicted']\n",
        "        ax2.scatter(pred_x, pred_y, c=pred_colors, s=100, marker='o', \n",
        "                   alpha=0.7, label='Predicted', zorder=5)\n",
        "        \n",
        "        # Add actual future positions\n",
        "        future_x = [p['x'] for p in pred_data if p['type'] == 'future']\n",
        "        future_y = [p['y'] for p in pred_data if p['type'] == 'future']\n",
        "        future_colors = [p['color'] for p in pred_data if p['type'] == 'future']\n",
        "        ax2.scatter(future_x, future_y, c=future_colors, s=100, marker='x', \n",
        "                   alpha=0.9, label='Actual', zorder=5)\n",
        "        \n",
        "        # Draw error lines\n",
        "        for p in pred_data:\n",
        "            if p['type'] == 'predicted':\n",
        "                actual_p = next((a for a in pred_data if a['nfl_id'] == p['nfl_id'].replace('_pred', '_future')), None)\n",
        "                if actual_p:\n",
        "                    ax2.plot([p['x'], actual_p['x']], [p['y'], actual_p['y']], \n",
        "                            'r--', alpha=0.5, linewidth=1)\n",
        "                    ax2.text((p['x'] + actual_p['x'])/2, (p['y'] + actual_p['y'])/2, \n",
        "                            f\"{p['error']:.1f}\", fontsize=6, ha='center', va='center',\n",
        "                            bbox=dict(boxstyle=\"round,pad=0.2\", facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax2.legend(loc='upper right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return fig\n",
        "\n",
        "print(\"[4/4] Setting up visualization functions...\")\n",
        "print(\"‚úÖ Visualization functions ready!\")\n",
        "print(\"\\nTo visualize a specific play, use:\")\n",
        "print(\"visualize_play_with_predictions(game_id, play_id, train_input, train_output, train_eval_data)\")\n",
        "print(\"\\nExample with worst prediction:\")\n",
        "if 'worst_idx' in locals():\n",
        "    print(f\"visualize_play_with_predictions({worst_idx[0]}, {worst_idx[1]}, train_input, train_output, train_eval_data)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data-science",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
