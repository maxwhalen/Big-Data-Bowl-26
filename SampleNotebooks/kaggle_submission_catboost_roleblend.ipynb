{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NFL Big Data Bowl 2026 — CatBoost Residual + Role Heads (Kaggle Submission)\n",
        "\n",
        "- Full pipeline: Constant-Acceleration baseline + CatBoost residuals\n",
        "- Enhancements: ball-frame features, formation features, GNN-lite, role-specific heads (TR/DC) blended with global\n",
        "- Device auto-detection for CatBoost (CPU/GPU, multi-GPU if available)\n",
        "- Writes `submission.csv` to `/kaggle/working`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, warnings, math, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from multiprocessing import Pool as MP, cpu_count\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import GroupKFold, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from catboost import CatBoostRegressor, Pool as CatPool\n",
        "from catboost.utils import get_gpu_device_count\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# CONFIG\n",
        "BASEDIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction\")\n",
        "SAVE_DIR = Path(\"/kaggle/working\")\n",
        "N_WEEKS = 18\n",
        "SEED = 42\n",
        "N_FOLDS = 5\n",
        "USE_GROUP_KFOLD = True\n",
        "ITERATIONS = 20000\n",
        "LR = 0.10\n",
        "DEPTH = 8\n",
        "L2 = 8.0\n",
        "EARLY = 700\n",
        "BORDER_CT = 254\n",
        "K_NEIGH = 6\n",
        "RADIUS  = 30.0\n",
        "TAU     = 8.0\n",
        "ALPHA_TR = 0.5\n",
        "ALPHA_DC = 0.5\n",
        "W_H = 0.25\n",
        "\n",
        "# Device detection\n",
        "try:\n",
        "    n_gpu = int(get_gpu_device_count())\n",
        "except Exception:\n",
        "    n_gpu = 0\n",
        "if n_gpu >= 2:\n",
        "    USE_GPU, DEVICES = True, \":\".join(str(i) for i in range(n_gpu))\n",
        "elif n_gpu == 1:\n",
        "    USE_GPU, DEVICES = True, \"0\"\n",
        "else:\n",
        "    USE_GPU, DEVICES = False, None\n",
        "print(f\"[CatBoost] GPUs: {n_gpu} | DEVICES={DEVICES}\")\n",
        "\n",
        "# IO utils\n",
        "def load_week(week_num: int):\n",
        "    fin = BASEDIR / f\"train/input_2023_w{week_num:02d}.csv\"\n",
        "    fout = BASEDIR / f\"train/output_2023_w{week_num:02d}.csv\"\n",
        "    return pd.read_csv(fin), pd.read_csv(fout)\n",
        "\n",
        "def load_all_train():\n",
        "    with MP(min(cpu_count(), N_WEEKS)) as pool:\n",
        "        res = list(tqdm(pool.imap(load_week, range(1, N_WEEKS+1)), total=N_WEEKS))\n",
        "    return pd.concat([r[0] for r in res], ignore_index=True), pd.concat([r[1] for r in res], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Feature engineering ---\n",
        "\n",
        "def to_inches(h):\n",
        "    try:\n",
        "        a,b = str(h).split(\"-\")\n",
        "        return float(a)*12.0 + float(b)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def engineer_advanced_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    for c in ['x','y','s','a','o','dir','ball_land_x','ball_land_y','frame_id',\n",
        "              'player_height','player_weight','player_role','player_side']:\n",
        "        if c not in df.columns:\n",
        "            if c == 'player_height': df[c] = '6-0'\n",
        "            elif c in ['player_role','player_side']: df[c] = ''\n",
        "            else: df[c] = 0.0\n",
        "\n",
        "    h = df['player_height'].map(to_inches).fillna(72.0)\n",
        "    w = pd.to_numeric(df['player_weight'], errors='coerce').fillna(200.0)\n",
        "    df['height_inches'] = h\n",
        "    df['bmi'] = (w / (h**2 + 1e-6)) * 703.0\n",
        "\n",
        "    dir_rad = np.radians(pd.to_numeric(df['dir'], errors='coerce').fillna(0.0))\n",
        "    df['heading_x'] = np.sin(dir_rad)\n",
        "    df['heading_y'] = np.cos(dir_rad)\n",
        "\n",
        "    s = pd.to_numeric(df['s'], errors='coerce').fillna(0.0)\n",
        "    a = pd.to_numeric(df['a'], errors='coerce').fillna(0.0)\n",
        "    df['velocity_x'] = s * df['heading_x']\n",
        "    df['velocity_y'] = s * df['heading_y']\n",
        "    df['acceleration_x'] = a * df['heading_x']\n",
        "    df['acceleration_y'] = a * df['heading_y']\n",
        "\n",
        "    x  = pd.to_numeric(df['x'], errors='coerce').fillna(0.0)\n",
        "    y  = pd.to_numeric(df['y'], errors='coerce').fillna(0.0)\n",
        "    bx = pd.to_numeric(df['ball_land_x'], errors='coerce').fillna(0.0)\n",
        "    by = pd.to_numeric(df['ball_land_y'], errors='coerce').fillna(0.0)\n",
        "    dx = bx - x; dy = by - y\n",
        "    dist = np.sqrt(dx*dx + dy*dy)\n",
        "    df['dist_to_ball'] = dist\n",
        "    df['angle_to_ball'] = np.arctan2(dy, dx)\n",
        "\n",
        "    ux = dx / (dist + 1e-6); uy = dy / (dist + 1e-6)\n",
        "    vx = -uy; vy = ux\n",
        "\n",
        "    df['v_para']  = df['velocity_x']*ux + df['velocity_y']*uy\n",
        "    df['v_perp']  = df['velocity_x']*vx + df['velocity_y']*vy\n",
        "    df['a_para']  = df['acceleration_x']*ux + df['acceleration_y']*uy\n",
        "    df['a_perp']  = df['acceleration_x']*vx + df['acceleration_y']*vy\n",
        "    df['heading_alignment'] = df['heading_x']*ux + df['heading_y']*uy\n",
        "\n",
        "    df['speed_squared']   = s**2\n",
        "    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n",
        "    df['momentum_x'] = w * df['velocity_x']\n",
        "    df['momentum_y'] = w * df['velocity_y']\n",
        "    df['kinetic_energy'] = 0.5 * w * df['speed_squared']\n",
        "\n",
        "    pr = df['player_role'].astype(str)\n",
        "    ps = df['player_side'].astype(str)\n",
        "    df['role_targeted_receiver']   = (pr == 'Targeted Receiver').astype(np.int8)\n",
        "    df['role_defensive_coverage']  = (pr == 'Defensive Coverage').astype(np.int8)\n",
        "    df['role_passer']              = (pr == 'Passer').astype(np.int8)\n",
        "    df['side_offense']             = (ps == 'Offense').astype(np.int8)\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_sequence_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]).copy()\n",
        "    gcols = [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "\n",
        "    for lag in [1,2,3,4,5]:\n",
        "        for c in [\"x\",\"y\",\"velocity_x\",\"velocity_y\",\"s\",\"a\",\"v_para\",\"v_perp\",\"a_para\",\"a_perp\"]:\n",
        "            if c in df.columns:\n",
        "                df[f\"{c}_lag{lag}\"] = df.groupby(gcols)[c].shift(lag)\n",
        "\n",
        "    for win in [3,5]:\n",
        "        for c in [\"x\",\"y\",\"velocity_x\",\"velocity_y\",\"s\",\"v_para\",\"v_perp\"]:\n",
        "            if c in df.columns:\n",
        "                df[f\"{c}_rolling_mean_{win}\"] = (\n",
        "                    df.groupby(gcols)[c].rolling(win, min_periods=1).mean()\n",
        "                      .reset_index(level=[0,1,2], drop=True)\n",
        "                )\n",
        "                df[f\"{c}_rolling_std_{win}\"] = (\n",
        "                    df.groupby(gcols)[c].rolling(win, min_periods=1).std()\n",
        "                      .reset_index(level=[0,1,2], drop=True)\n",
        "                )\n",
        "\n",
        "    for c in [\"velocity_x\",\"velocity_y\",\"v_para\",\"v_perp\"]:\n",
        "        if c in df.columns:\n",
        "            df[f\"{c}_delta\"] = df.groupby(gcols)[c].diff()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_formation_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    grp = df.groupby(['game_id','play_id','frame_id','player_side'], sort=False)\n",
        "    df['team_centroid_x'] = grp['x'].transform('mean')\n",
        "    df['team_centroid_y'] = grp['y'].transform('mean')\n",
        "    df['team_width']      = grp['y'].transform('std').fillna(0.0)\n",
        "    df['team_length']     = grp['x'].transform('std').fillna(0.0)\n",
        "    df['rel_cx'] = df['x'] - df['team_centroid_x']\n",
        "    df['rel_cy'] = df['y'] - df['team_centroid_y']\n",
        "    bx = pd.to_numeric(df['ball_land_x'], errors='coerce').fillna(0.0)\n",
        "    by = pd.to_numeric(df['ball_land_y'], errors='coerce').fillna(0.0)\n",
        "    bearing = np.arctan2(by - df['team_centroid_y'], bx - df['team_centroid_x'])\n",
        "    df['form_bear_sin'] = np.sin(bearing)\n",
        "    df['form_bear_cos'] = np.cos(bearing)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- GNN-lite and helpers ---\n",
        "\n",
        "def compute_neighbor_embeddings(input_df: pd.DataFrame, k_neigh:int=K_NEIGH, radius:float=RADIUS, tau:float=TAU) -> pd.DataFrame:\n",
        "    cols_needed = [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\"x\",\"y\",\"velocity_x\",\"velocity_y\",\"player_side\"]\n",
        "    src = input_df[cols_needed].copy()\n",
        "\n",
        "    last = (src.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"])  \n",
        "               .groupby([\"game_id\",\"play_id\",\"nfl_id\"], as_index=False)  \n",
        "               .tail(1)  \n",
        "               .rename(columns={\"frame_id\":\"last_frame_id\"})  \n",
        "               .reset_index(drop=True))\n",
        "\n",
        "    tmp = last.merge(\n",
        "        src.rename(columns={\n",
        "            \"frame_id\":\"nb_frame_id\",\"nfl_id\":\"nfl_id_nb\",\"x\":\"x_nb\",\"y\":\"y_nb\",\n",
        "            \"velocity_x\":\"vx_nb\",\"velocity_y\":\"vy_nb\",\"player_side\":\"player_side_nb\"\n",
        "        }),\n",
        "        left_on=[\"game_id\",\"play_id\",\"last_frame_id\"],\n",
        "        right_on=[\"game_id\",\"play_id\",\"nb_frame_id\"],\n",
        "        how=\"left\",\n",
        "    )\n",
        "    tmp = tmp[tmp[\"nfl_id_nb\"] != tmp[\"nfl_id\"]]\n",
        "\n",
        "    tmp[\"dx\"]  = tmp[\"x_nb\"] - tmp[\"x\"]\n",
        "    tmp[\"dy\"]  = tmp[\"y_nb\"] - tmp[\"y\"]\n",
        "    tmp[\"dvx\"] = tmp[\"vx_nb\"] - tmp[\"velocity_x\"]\n",
        "    tmp[\"dvy\"] = tmp[\"vy_nb\"] - tmp[\"velocity_y\"]\n",
        "    tmp[\"dist\"] = np.sqrt(tmp[\"dx\"]**2 + tmp[\"dy\"]**2)\n",
        "    tmp = tmp[np.isfinite(tmp[\"dist\"]) & (tmp[\"dist\"] > 1e-6)]\n",
        "    if radius is not None: tmp = tmp[tmp[\"dist\"] <= radius]\n",
        "\n",
        "    tmp[\"is_ally\"] = (tmp[\"player_side_nb\"].fillna(\"\") == tmp[\"player_side\"].fillna(\"\")).astype(np.float32)\n",
        "    keys = [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "    tmp[\"rnk\"] = tmp.groupby(keys)[\"dist\"].rank(method=\"first\")\n",
        "    if k_neigh is not None: tmp = tmp[tmp[\"rnk\"] <= float(k_neigh)]\n",
        "\n",
        "    tmp[\"w\"] = np.exp(-tmp[\"dist\"] / float(tau))\n",
        "    sum_w = tmp.groupby(keys)[\"w\"].transform(\"sum\"); tmp[\"wn\"] = np.where(sum_w>0, tmp[\"w\"]/sum_w, 0.0)\n",
        "    tmp[\"wn_ally\"] = tmp[\"wn\"] * tmp[\"is_ally\"]; tmp[\"wn_opp\"]  = tmp[\"wn\"] * (1.0 - tmp[\"is_ally\"])\n",
        "    for col in [\"dx\",\"dy\",\"dvx\",\"dvy\"]:\n",
        "        tmp[f\"{col}_ally_w\"] = tmp[col] * tmp[\"wn_ally\"]\n",
        "        tmp[f\"{col}_opp_w\"]  = tmp[col] * tmp[\"wn_opp\"]\n",
        "    tmp[\"dist_ally\"] = np.where(tmp[\"is_ally\"] > 0.5, tmp[\"dist\"], np.nan)\n",
        "    tmp[\"dist_opp\"]  = np.where(tmp[\"is_ally\"] < 0.5, tmp[\"dist\"], np.nan)\n",
        "\n",
        "    ag = tmp.groupby(keys).agg(\n",
        "        gnn_ally_dx_mean=(\"dx_ally_w\",\"sum\"),\n",
        "        gnn_ally_dy_mean=(\"dy_ally_w\",\"sum\"),\n",
        "        gnn_ally_dvx_mean=(\"dvx_ally_w\",\"sum\"),\n",
        "        gnn_ally_dvy_mean=(\"dvy_ally_w\",\"sum\"),\n",
        "        gnn_opp_dx_mean=(\"dx_opp_w\",\"sum\"),\n",
        "        gnn_opp_dy_mean=(\"dy_opp_w\",\"sum\"),\n",
        "        gnn_opp_dvx_mean=(\"dvx_opp_w\",\"sum\"),\n",
        "        gnn_opp_dvy_mean=(\"dvy_opp_w\",\"sum\"),\n",
        "        gnn_ally_cnt=(\"is_ally\",\"sum\"),\n",
        "        gnn_opp_cnt=(\"is_ally\", lambda s: float(len(s) - s.sum())),\n",
        "        gnn_ally_dmin=(\"dist_ally\",\"min\"),\n",
        "        gnn_ally_dmean=(\"dist_ally\",\"mean\"),\n",
        "        gnn_opp_dmin=(\"dist_opp\",\"min\"),\n",
        "        gnn_opp_dmean=(\"dist_opp\",\"mean\"),\n",
        "    ).reset_index()\n",
        "\n",
        "    near = tmp.loc[tmp[\"rnk\"]<=3, keys+[\"rnk\",\"dist\"]].copy()\n",
        "    near[\"rnk\"] = near[\"rnk\"].astype(int)\n",
        "    dwide = near.pivot_table(index=keys, columns=\"rnk\", values=\"dist\", aggfunc=\"first\")\n",
        "    dwide = dwide.rename(columns={1:\"gnn_d1\",2:\"gnn_d2\",3:\"gnn_d3\"}).reset_index()\n",
        "    ag = ag.merge(dwide, on=keys, how=\"left\")\n",
        "\n",
        "    for c in [\"gnn_ally_dx_mean\",\"gnn_ally_dy_mean\",\"gnn_ally_dvx_mean\",\"gnn_ally_dvy_mean\",\n",
        "              \"gnn_opp_dx_mean\",\"gnn_opp_dy_mean\",\"gnn_opp_dvx_mean\",\"gnn_opp_dvy_mean\"]:\n",
        "        ag[c] = ag[c].fillna(0.0)\n",
        "    for c in [\"gnn_ally_cnt\",\"gnn_opp_cnt\"]:\n",
        "        ag[c] = ag[c].fillna(0.0)\n",
        "    for c in [\"gnn_ally_dmin\",\"gnn_opp_dmin\",\"gnn_ally_dmean\",\"gnn_opp_dmean\",\"gnn_d1\",\"gnn_d2\",\"gnn_d3\"]:\n",
        "        ag[c] = ag[c].fillna(radius if radius is not None else 30.0)\n",
        "    return ag\n",
        "\n",
        "\n",
        "def create_training_rows(input_df: pd.DataFrame, output_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    agg = (\n",
        "        input_df.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"])  \n",
        "                .groupby([\"game_id\",\"play_id\",\"nfl_id\"], as_index=False)  \n",
        "                .tail(1)  \n",
        "                .reset_index(drop=True)  \n",
        "                .rename(columns={\"frame_id\":\"last_frame_id\"})\n",
        "    )\n",
        "\n",
        "    out = output_df.copy()\n",
        "    out = out.rename(columns={\"x\":\"target_x\",\"y\":\"target_y\"})\n",
        "    out[\"id\"] = (\n",
        "        out[\"game_id\"].astype(str) + \"_\" + out[\"play_id\"].astype(str) + \"_\" +\n",
        "        out[\"nfl_id\"].astype(str) + \"_\" + out[\"frame_id\"].astype(str)\n",
        "    )\n",
        "    m = out.merge(agg, on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\", suffixes=(\"\",\"_last\"))\n",
        "    m[\"delta_frames\"] = (m[\"frame_id\"] - m[\"last_frame_id\"]).clip(lower=0).astype(float)\n",
        "    m[\"delta_t\"] = m[\"delta_frames\"] / 10.0\n",
        "    return m\n",
        "\n",
        "\n",
        "def ca_baseline(x_last, y_last, vx_last, vy_last, dt, ax_last, ay_last):\n",
        "    px = x_last + vx_last*dt + 0.5*ax_last*(dt**2)\n",
        "    py = y_last + vy_last*dt + 0.5*ay_last*(dt**2)\n",
        "    return np.clip(px, 0.0, 120.0), np.clip(py, 0.0, 53.3)\n",
        "\n",
        "\n",
        "def build_feature_list(train_df: pd.DataFrame):\n",
        "    base = [\n",
        "        \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n",
        "        \"velocity_x\",\"velocity_y\",\"acceleration_x\",\"acceleration_y\",\n",
        "        \"heading_x\",\"heading_y\",\"heading_alignment\",\n",
        "        \"v_para\",\"v_perp\",\"a_para\",\"a_perp\",\n",
        "        \"player_weight\",\"height_inches\",\"bmi\",\n",
        "        \"ball_land_x\",\"ball_land_y\",\"dist_to_ball\",\"angle_to_ball\",\n",
        "        \"speed_squared\",\"accel_magnitude\",\"momentum_x\",\"momentum_y\",\"kinetic_energy\",\n",
        "        \"role_targeted_receiver\",\"role_defensive_coverage\",\"role_passer\",\"side_offense\",\n",
        "        \"team_centroid_x\",\"team_centroid_y\",\"team_width\",\"team_length\",\n",
        "        \"rel_cx\",\"rel_cy\",\"form_bear_sin\",\"form_bear_cos\",\n",
        "        \"delta_frames\",\"delta_t\",\"frame_id\",\n",
        "        \"gnn_ally_dx_mean\",\"gnn_ally_dy_mean\",\"gnn_ally_dvx_mean\",\"gnn_ally_dvy_mean\",\n",
        "        \"gnn_opp_dx_mean\",\"gnn_opp_dy_mean\",\"gnn_opp_dvx_mean\",\"gnn_opp_dvy_mean\",\n",
        "        \"gnn_ally_cnt\",\"gnn_opp_cnt\",\"gnn_ally_dmin\",\"gnn_ally_dmean\",\"gnn_opp_dmin\",\"gnn_opp_dmean\",\n",
        "        \"gnn_d1\",\"gnn_d2\",\"gnn_d3\",\n",
        "    ]\n",
        "    for lag in [1,2,3,4,5]:\n",
        "        for c in [\"x\",\"y\",\"velocity_x\",\"velocity_y\",\"s\",\"a\",\"v_para\",\"v_perp\",\"a_para\",\"a_perp\"]:\n",
        "            base.append(f\"{c}_lag{lag}\")\n",
        "    for win in [3,5]:\n",
        "        for c in [\"x\",\"y\",\"velocity_x\",\"velocity_y\",\"s\",\"v_para\",\"v_perp\"]:\n",
        "            base.append(f\"{c}_rolling_mean_{win}\")\n",
        "            base.append(f\"{c}_rolling_std_{win}\")\n",
        "    base += [\"velocity_x_delta\",\"velocity_y_delta\",\"v_para_delta\",\"v_perp_delta\"]\n",
        "\n",
        "    feats = [c for c in base if c in train_df.columns]\n",
        "    feats = list(dict.fromkeys(feats + [c for c in train_df.columns if c.startswith(\"gnn_\")]))\n",
        "    return feats\n",
        "\n",
        "\n",
        "def _cat_params():\n",
        "    p = dict(\n",
        "        iterations=ITERATIONS, learning_rate=LR, depth=DEPTH, l2_leaf_reg=L2,\n",
        "        random_seed=SEED, task_type=(\"GPU\" if USE_GPU else \"CPU\"),\n",
        "        loss_function=\"RMSE\", early_stopping_rounds=EARLY, verbose=200,\n",
        "        border_count=BORDER_CT\n",
        "    )\n",
        "    if USE_GPU and DEVICES is not None:\n",
        "        p[\"devices\"] = DEVICES\n",
        "    return p\n",
        "\n",
        "\n",
        "def train_folded(X, yx, yy, sample_w, ids_group=None, base_x=None, base_y=None):\n",
        "    if ids_group is not None and USE_GROUP_KFOLD:\n",
        "        folds = GroupKFold(n_splits=N_FOLDS).split(X, groups=ids_group)\n",
        "    else:\n",
        "        folds = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED).split(X)\n",
        "\n",
        "    models_x, models_y, fold_rmse = [], [], []\n",
        "    params = _cat_params()\n",
        "    for i,(tr,va) in enumerate(folds, 1):\n",
        "        print(f\"\\nFold {i}/{N_FOLDS} — train {len(tr):,} | val {len(va):,}\")\n",
        "        p_tr_x = CatPool(X[tr], yx[tr], weight=None if sample_w is None else sample_w[tr])\n",
        "        p_va_x = CatPool(X[va], yx[va])\n",
        "        p_tr_y = CatPool(X[tr], yy[tr], weight=None if sample_w is None else sample_w[tr])\n",
        "        p_va_y = CatPool(X[va], yy[va])\n",
        "\n",
        "        mx = CatBoostRegressor(**params).fit(p_tr_x, eval_set=p_va_x, verbose=200)\n",
        "        my = CatBoostRegressor(**params).fit(p_tr_y, eval_set=p_va_y, verbose=200)\n",
        "        models_x.append(mx); models_y.append(my)\n",
        "\n",
        "        prx = mx.predict(X[va]); pry = my.predict(X[va])\n",
        "        px  = np.clip(prx + base_x[va], 0, 120)\n",
        "        py  = np.clip(pry + base_y[va], 0, 53.3)\n",
        "        rmse = math.sqrt(0.5*(mean_squared_error(yx[va]+base_x[va], px) + mean_squared_error(yy[va]+base_y[va], py)))\n",
        "        print(f\"Fold {i} RMSE: {rmse:.5f}\")\n",
        "        fold_rmse.append(rmse)\n",
        "\n",
        "    print(\"\\nPer-fold:\", [f\"{v:.5f}\" for v in fold_rmse])\n",
        "    print(f\"Mean ± std: {np.mean(fold_rmse):.5f} ± {np.std(fold_rmse):.5f}\")\n",
        "    return models_x, models_y, fold_rmse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Train + Inference + Save submission ---\n",
        "\n",
        "# Load train\n",
        "tr_in, tr_out = load_all_train()\n",
        "print(f\"Train input:  {tr_in.shape}\")\n",
        "print(f\"Train output: {tr_out.shape}\")\n",
        "\n",
        "# FE train\n",
        "tr_in = engineer_advanced_features(tr_in)\n",
        "tr_in = add_formation_features(tr_in)\n",
        "tr_in = add_sequence_features(tr_in)\n",
        "\n",
        "# GNN train\n",
        "print(\"Computing neighbor embeddings (train)…\")\n",
        "agg_gnn_tr = compute_neighbor_embeddings(tr_in)\n",
        "\n",
        "# Build training rows\n",
        "train_df = create_training_rows(tr_in, tr_out)\n",
        "train_df = train_df.merge(agg_gnn_tr, on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\")\n",
        "\n",
        "# CA baseline + residual targets\n",
        "bx, by = ca_baseline(\n",
        "    train_df[\"x\"].values, train_df[\"y\"].values,\n",
        "    train_df[\"velocity_x\"].values, train_df[\"velocity_y\"].values,\n",
        "    train_df[\"delta_t\"].values,\n",
        "    train_df[\"acceleration_x\"].values, train_df[\"acceleration_y\"].values,\n",
        ")\n",
        "base_rmse = math.sqrt(0.5*(mean_squared_error(train_df[\"target_x\"], bx) + mean_squared_error(train_df[\"target_y\"], by)))\n",
        "print(f\"[Baseline CA] RMSE: {base_rmse:.5f}\")\n",
        "\n",
        "train_df[\"base_x\"] = bx\n",
        "train_df[\"base_y\"] = by\n",
        "train_df[\"res_x\"]  = train_df[\"target_x\"] - train_df[\"base_x\"]\n",
        "train_df[\"res_y\"]  = train_df[\"target_y\"] - train_df[\"base_y\"]\n",
        "\n",
        "# Features\n",
        "feat_cols = build_feature_list(train_df)\n",
        "print(f\"Using {len(feat_cols)} features\")\n",
        "\n",
        "clean = train_df.dropna(subset=feat_cols + [\"res_x\",\"res_y\"]).reset_index(drop=True)\n",
        "clean[feat_cols] = clean[feat_cols].replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "X  = clean[feat_cols].to_numpy(np.float32)\n",
        "yx = clean[\"res_x\"].to_numpy(np.float32)\n",
        "yy = clean[\"res_y\"].to_numpy(np.float32)\n",
        "bxv= clean[\"base_x\"].to_numpy(np.float32)\n",
        "byv= clean[\"base_y\"].to_numpy(np.float32)\n",
        "\n",
        "w = 1.0 + W_H * clean[\"delta_frames\"].clip(lower=1, upper=5).to_numpy(np.float32)\n",
        "groups = (clean[\"game_id\"].astype(str) + \"_\" + clean[\"play_id\"].astype(str) + \"_\" + clean[\"nfl_id\"].astype(str)).values\n",
        "\n",
        "# Train global\n",
        "print(\"\\n[GLOBAL] training…\")\n",
        "glob_x, glob_y, _ = train_folded(X, yx, yy, w, ids_group=groups, base_x=bxv, base_y=byv)\n",
        "\n",
        "# Train TR head (optional)\n",
        "mask_tr = clean[\"role_targeted_receiver\"]==1\n",
        "if mask_tr.sum() > 5000:\n",
        "    print(\"\\n[TR head] training…\")\n",
        "    X_tr, yx_tr, yy_tr = X[mask_tr], yx[mask_tr], yy[mask_tr]\n",
        "    bx_tr, by_tr = bxv[mask_tr], byv[mask_tr]\n",
        "    w_tr  = w[mask_tr]\n",
        "    grp_tr= groups[mask_tr]\n",
        "    tr_x, tr_y, _ = train_folded(X_tr, yx_tr, yy_tr, w_tr, ids_group=grp_tr, base_x=bx_tr, base_y=by_tr)\n",
        "else:\n",
        "    tr_x, tr_y = None, None\n",
        "\n",
        "# Train DC head (optional)\n",
        "mask_dc = clean[\"role_defensive_coverage\"]==1\n",
        "if mask_dc.sum() > 5000:\n",
        "    print(\"\\n[DC head] training…\")\n",
        "    X_dc, yx_dc, yy_dc = X[mask_dc], yx[mask_dc], yy[mask_dc]\n",
        "    bx_dc, by_dc = bxv[mask_dc], byv[mask_dc]\n",
        "    w_dc  = w[mask_dc]\n",
        "    grp_dc= groups[mask_dc]\n",
        "    dc_x, dc_y, _ = train_folded(X_dc, yx_dc, yy_dc, w_dc, ids_group=grp_dc, base_x=bx_dc, base_y=by_dc)\n",
        "else:\n",
        "    dc_x, dc_y = None, None\n",
        "\n",
        "with open(SAVE_DIR/\"catboost_models_5fold_ROLEBLEND.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"global_x\": glob_x, \"global_y\": glob_y,\n",
        "        \"tr_x\": tr_x, \"tr_y\": tr_y,\n",
        "        \"dc_x\": dc_x, \"dc_y\": dc_y,\n",
        "        \"features\": feat_cols\n",
        "    }, f)\n",
        "print(\"Saved models:\", SAVE_DIR/\"catboost_models_5fold_ROLEBLEND.pkl\")\n",
        "\n",
        "# Inference\n",
        "print(\"\\nPreparing test…\")\n",
        "te_in  = pd.read_csv(BASEDIR/\"test_input.csv\")\n",
        "te_tpl = pd.read_csv(BASEDIR/\"test.csv\")\n",
        "\n",
        "te_in  = engineer_advanced_features(te_in)\n",
        "te_in  = add_formation_features(te_in)\n",
        "te_in  = add_sequence_features(te_in)\n",
        "agg_gnn_te = compute_neighbor_embeddings(te_in)\n",
        "\n",
        "agg_te = (\n",
        "    te_in.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"])  \n",
        "         .groupby([\"game_id\",\"play_id\",\"nfl_id\"], as_index=False)  \n",
        "         .tail(1)  \n",
        "         .rename(columns={\"frame_id\":\"last_frame_id\"})\n",
        ")\n",
        "\n",
        "te = te_tpl.merge(agg_te, on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\")\n",
        "te = te.merge(agg_gnn_te, on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\")\n",
        "\n",
        "te[\"delta_frames\"] = (te[\"frame_id\"] - te[\"last_frame_id\"]).clip(lower=0).astype(float)\n",
        "te[\"delta_t\"] = te[\"delta_frames\"] / 10.0\n",
        "\n",
        "# CA baseline test\n",
        "tbx, tby = ca_baseline(\n",
        "    te[\"x\"].values, te[\"y\"].values,\n",
        "    te[\"velocity_x\"].values, te[\"velocity_y\"].values,\n",
        "    te[\"delta_t\"].values,\n",
        "    te[\"acceleration_x\"].values, te[\"acceleration_y\"].values,\n",
        ")\n",
        "\n",
        "# Align features and predict\n",
        "for c in build_feature_list(te):\n",
        "    if c not in te.columns:\n",
        "        te[c] = 0.0\n",
        "with open(SAVE_DIR/\"catboost_models_5fold_ROLEBLEND.pkl\",\"rb\") as f:\n",
        "    pack = pickle.load(f)\n",
        "feat_cols = [c for c in pack[\"features\"] if c in te.columns]\n",
        "\n",
        "te.loc[:, feat_cols] = te[feat_cols].replace([np.inf,-np.inf], np.nan).fillna(0.0).to_numpy()\n",
        "Xtest = te[feat_cols].values.astype(np.float32)\n",
        "\n",
        "glob_x, glob_y = pack[\"global_x\"], pack[\"global_y\"]\n",
        "tr_x, tr_y     = pack[\"tr_x\"], pack[\"tr_y\"]\n",
        "dc_x, dc_y     = pack[\"dc_x\"], pack[\"dc_y\"]\n",
        "\n",
        "avg = lambda ms, X: np.mean([m.predict(X) for m in ms], axis=0).astype(np.float32)\n",
        "prx_global = avg(glob_x, Xtest); pry_global = avg(glob_y, Xtest)\n",
        "\n",
        "prx_tr = prx_global.copy(); pry_tr = pry_global.copy()\n",
        "if tr_x is not None and tr_y is not None:\n",
        "    prx_tr = avg(tr_x, Xtest); pry_tr = avg(tr_y, Xtest)\n",
        "prx_dc = prx_global.copy(); pry_dc = pry_global.copy()\n",
        "if dc_x is not None and dc_y is not None:\n",
        "    prx_dc = avg(dc_x, Xtest); pry_dc = avg(dc_y, Xtest)\n",
        "\n",
        "is_tr = (te[\"player_role\"].astype(str) == \"Targeted Receiver\").values\n",
        "is_dc = (te[\"player_role\"].astype(str) == \"Defensive Coverage\").values\n",
        "\n",
        "pred_rx = prx_global.copy(); pred_ry = pry_global.copy()\n",
        "pred_rx[is_tr] = (1-ALPHA_TR)*prx_global[is_tr] + ALPHA_TR*prx_tr[is_tr]\n",
        "pred_ry[is_tr] = (1-ALPHA_TR)*pry_global[is_tr] + ALPHA_TR*pry_tr[is_tr]\n",
        "pred_rx[is_dc] = (1-ALPHA_DC)*prx_global[is_dc] + ALPHA_DC*prx_dc[is_dc]\n",
        "pred_ry[is_dc] = (1-ALPHA_DC)*pry_global[is_dc] + ALPHA_DC*pry_dc[is_dc]\n",
        "\n",
        "pred_x = np.clip(pred_rx + tbx, 0.0, 120.0)\n",
        "pred_y = np.clip(pred_ry + tby, 0.0, 53.3)\n",
        "\n",
        "sub = pd.DataFrame({\n",
        "    \"id\": (te[\"game_id\"].astype(str) + \"_\" + te[\"play_id\"].astype(str) + \"_\" + te[\"nfl_id\"].astype(str) + \"_\" + te[\"frame_id\"].astype(str)),\n",
        "    \"x\": pred_x,\n",
        "    \"y\": pred_y,\n",
        "})\n",
        "sub.to_csv(SAVE_DIR/\"submission.csv\", index=False)\n",
        "print(\"Saved submission:\", SAVE_DIR/\"submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: submit to Kaggle (only works on Kaggle with API token configured)\n",
        "try:\n",
        "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "    api = KaggleApi(); api.authenticate()\n",
        "    api.competition_submit(file_name=str(SAVE_DIR/\"submission.csv\"), message=\"CatBoost residual + role heads + GNN-lite\", competition=\"nfl-big-data-bowl-2026-prediction\")\n",
        "    print(\"Submitted to Kaggle leaderboard.\")\n",
        "except Exception as e:\n",
        "    print(\"Kaggle submit skipped or failed:\", e)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
