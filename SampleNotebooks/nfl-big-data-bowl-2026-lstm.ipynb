{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "229f501b",
   "metadata": {
    "papermill": {
     "duration": 0.008782,
     "end_time": "2025-10-06T18:09:40.241846",
     "exception": false,
     "start_time": "2025-10-06T18:09:40.233064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "note: lastest version added GRU, switch to version 15 for pure LSTM with LB: 0 .69\n",
    "\n",
    "can change to GPU for faster submission time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95557e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:09:40.258506Z",
     "iopub.status.busy": "2025-10-06T18:09:40.258055Z",
     "iopub.status.idle": "2025-10-06T18:09:50.480725Z",
     "shell.execute_reply": "2025-10-06T18:09:50.479524Z"
    },
    "papermill": {
     "duration": 10.233407,
     "end_time": "2025-10-06T18:09:50.482918",
     "exception": false,
     "start_time": "2025-10-06T18:09:40.249511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# NFL BIG DATA BOWL 2026 - COMPLETE WORKING SOLUTION\n",
    "# Predicting player movement during pass plays with temporal features\n",
    "# ================================================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from tqdm import tqdm\n",
    "# Deep Learning\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ================================================================================\n",
    "# CONFIGURATION\n",
    "# ================================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60d1c60",
   "metadata": {
    "papermill": {
     "duration": 0.007108,
     "end_time": "2025-10-06T18:09:50.497750",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.490642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefded8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:09:50.514950Z",
     "iopub.status.busy": "2025-10-06T18:09:50.514467Z",
     "iopub.status.idle": "2025-10-06T18:09:50.520868Z",
     "shell.execute_reply": "2025-10-06T18:09:50.519876Z"
    },
    "papermill": {
     "duration": 0.016733,
     "end_time": "2025-10-06T18:09:50.522562",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.505829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n",
    "    PRETRAIN_DIR = None\n",
    "    SEED = 42\n",
    "    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n",
    "    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n",
    "    MAX_SPEED = 12.0\n",
    "    N_FOLDS = 5\n",
    "    \n",
    "    # LSTM_DATA_DIR = '/kaggle/input/prepare-lstm'\n",
    "    LSTM_DATA_DIR = None\n",
    "    HIDDEN_DIM = 128\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.3\n",
    "    MAX_FUTURE_HORIZON = 94 #unchangable\n",
    "    \n",
    "    WINDOW_SIZE = 6 # aware of high value. 6,7 are safer for submission\n",
    "    BATCH_SIZE = 256\n",
    "    LEARNING_RATE = 1e-3\n",
    "    PATIENCE = 30\n",
    "    EPOCHS = 200\n",
    "    DEBUG_FRACTION = 1.0\n",
    "    # Set to low value if need to debug\n",
    "    # EPOCHS = 1\n",
    "    # DEBUG_FRACTION = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410dcc36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:09:50.539444Z",
     "iopub.status.busy": "2025-10-06T18:09:50.538402Z",
     "iopub.status.idle": "2025-10-06T18:09:50.551924Z",
     "shell.execute_reply": "2025-10-06T18:09:50.550727Z"
    },
    "papermill": {
     "duration": 0.0238,
     "end_time": "2025-10-06T18:09:50.553750",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.529950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_global_seeds(seed: int = 42):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    import random, os\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_global_seeds(Config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab51ad7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:09:50.570256Z",
     "iopub.status.busy": "2025-10-06T18:09:50.569929Z",
     "iopub.status.idle": "2025-10-06T18:09:50.579747Z",
     "shell.execute_reply": "2025-10-06T18:09:50.578721Z"
    },
    "papermill": {
     "duration": 0.020148,
     "end_time": "2025-10-06T18:09:50.581433",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.561285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ================================================================================\n",
    "# DATA LOADING\n",
    "# ================================================================================\n",
    "\n",
    "def load_data(debug_fraction=1.0):\n",
    "    \"\"\"Load all training and test data with an option to use a fraction for debugging.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Training data\n",
    "    train_input_files = [Config.DATA_DIR / f\"train/input_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
    "    train_output_files = [Config.DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
    "    \n",
    "    # Filter existing files\n",
    "    train_input_files = [f for f in train_input_files if f.exists()]\n",
    "    train_output_files = [f for f in train_output_files if f.exists()]\n",
    "    \n",
    "    print(f\"Found {len(train_input_files)} weeks of data\")\n",
    "    \n",
    "    # Load and concatenate\n",
    "    train_input = pd.concat([pd.read_csv(f) for f in tqdm(train_input_files, desc=\"Input\")], ignore_index=True)\n",
    "    train_output = pd.concat([pd.read_csv(f) for f in tqdm(train_output_files, desc=\"Output\")], ignore_index=True)\n",
    "    \n",
    "    # Test data\n",
    "    test_input = pd.read_csv(Config.DATA_DIR / \"test_input.csv\")\n",
    "    test_template = pd.read_csv(Config.DATA_DIR / \"test.csv\")\n",
    "    \n",
    "    print(f\"Loaded {len(train_input):,} input records, {len(train_output):,} output records\")\n",
    "    \n",
    "    # Use only a fraction of the games for debugging (select entire games)\n",
    "    if debug_fraction < 1.0:\n",
    "        unique_game_ids = train_input['game_id'].unique()\n",
    "        sampled_game_ids = pd.Series(unique_game_ids).sample(frac=debug_fraction, random_state=42).values\n",
    "        train_input = train_input[train_input['game_id'].isin(sampled_game_ids)].reset_index(drop=True)\n",
    "        train_output = train_output[train_output['game_id'].isin(sampled_game_ids)].reset_index(drop=True)\n",
    "        print(f\"Using {len(train_input):,} input records from {len(sampled_game_ids)} games for debugging\")\n",
    "    \n",
    "    return train_input, train_output, test_input, test_template\n",
    "# ================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb100f0c",
   "metadata": {
    "papermill": {
     "duration": 0.007267,
     "end_time": "2025-10-06T18:09:50.596154",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.588887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d3e07e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:09:50.612930Z",
     "iopub.status.busy": "2025-10-06T18:09:50.612586Z",
     "iopub.status.idle": "2025-10-06T18:09:50.623082Z",
     "shell.execute_reply": "2025-10-06T18:09:50.622124Z"
    },
    "papermill": {
     "duration": 0.021484,
     "end_time": "2025-10-06T18:09:50.625017",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.603533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute RMSE for NFL competition.\n",
    "    Expected input:\n",
    "      - solution and submission as pandas.DataFrame\n",
    "      - Column 'id': unique identifier for each (game_id, play_id, nfl_id, frame_id)\n",
    "      - Column 'x'\n",
    "      - Column 'y'\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = 'id'\n",
    "    >>> solution = pd.DataFrame({'id': ['21_12_2_1', '21_12_2_2', '21_12_2_3'], 'x': [1,2,3], 'y':[4,2,3]})\n",
    "    >>> submission  = pd.DataFrame({'id': ['21_12_2_1', '21_12_2_2', '21_12_2_3'], 'x': [1.1,2,3], 'y':[4,2.2,3]})\n",
    "    >>> round(score(solution, submission, row_id_column_name=row_id_column_name), 4)\n",
    "    0.0913\n",
    "    >>> submission  = pd.DataFrame({'id': ['21_12_2_1', '21_12_2_2', '21_12_2_3'], 'x': [0,2,3], 'y':[4,2.2,3]})\n",
    "    >>> round(score(solution, submission, row_id_column_name=row_id_column_name), 4)\n",
    "    0.4163\n",
    "    >>> submission  = pd.DataFrame({'id': ['21_12_2_1', '21_12_2_2', '21_12_2_3'], 'x': [1,2,1], 'y':[4,0,3]})\n",
    "    >>> round(score(solution, submission, row_id_column_name=row_id_column_name), 4)\n",
    "    1.1547\n",
    "    \"\"\"\n",
    "\n",
    "    TARGET = ['x', 'y']\n",
    "    if row_id_column_name not in solution.columns:\n",
    "        raise ParticipantVisibleError(f\"Solution file missing required column: '{row_id_column_name}'\")\n",
    "    if row_id_column_name not in submission.columns:\n",
    "        raise ParticipantVisibleError(f\"Submission file missing required column: '{row_id_column_name}'\")\n",
    "\n",
    "    missing_in_solution = set(TARGET) - set(solution.columns)\n",
    "    missing_in_submission = set(TARGET) - set(submission.columns)\n",
    "\n",
    "    if missing_in_solution:\n",
    "        raise ParticipantVisibleError(f'Solution file missing required columns: {missing_in_solution}')\n",
    "    if missing_in_submission:\n",
    "        raise ParticipantVisibleError(f'Submission file missing required columns: {missing_in_submission}')\n",
    "\n",
    "    submission = submission[['id'] + TARGET]\n",
    "    merged_df = pd.merge(solution, submission, on=row_id_column_name, suffixes=('_true', '_pred'))\n",
    "    #log NaN\n",
    "    nanx_in_pred = merged_df['x_pred'].isna().sum()\n",
    "    nany_in_pred = merged_df['y_pred'].isna().sum()\n",
    "    if nanx_in_pred > 0:\n",
    "        print(f\"WARNING: Found {nanx_in_pred} NaN predictions in merged results\")\n",
    "    if nany_in_pred > 0:\n",
    "        print(f\"WARNING: Found {nany_in_pred} NaN predictions in merged results\")\n",
    "    nanx_in_true = merged_df[merged_df['x_pred'].isna() | merged_df['y_pred'].isna()]['x_true'].isna().sum()\n",
    "    nany_in_true = merged_df[merged_df['x_pred'].isna() | merged_df['y_pred'].isna()]['y_true'].isna().sum()\n",
    "    if nanx_in_true > 0:\n",
    "        print(f\"WARNING: Found {nanx_in_true} NaN true values corresponding to NaN predictions\")\n",
    "    if nany_in_true > 0:\n",
    "        print(f\"WARNING: Found {nany_in_true} NaN true values corresponding to NaN predictions\")\n",
    "    rmse = np.sqrt(\n",
    "        0.5 * (mean_squared_error(merged_df['x_true'], merged_df['x_pred']) + mean_squared_error(merged_df['y_true'], merged_df['y_pred']))\n",
    "    )\n",
    "    return float(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395a2b1",
   "metadata": {
    "papermill": {
     "duration": 0.00702,
     "end_time": "2025-10-06T18:09:50.639333",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.632313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare features for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770b5a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:09:50.655486Z",
     "iopub.status.busy": "2025-10-06T18:09:50.655121Z",
     "iopub.status.idle": "2025-10-06T18:09:50.660670Z",
     "shell.execute_reply": "2025-10-06T18:09:50.659572Z"
    },
    "papermill": {
     "duration": 0.015604,
     "end_time": "2025-10-06T18:09:50.662236",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.646632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def height_to_feet(height_str):\n",
    "    \"\"\"Convert height from 'ft-in' format to feet\"\"\"\n",
    "    try:\n",
    "        ft, inches = map(int, height_str.split('-'))\n",
    "        return ft + inches/12\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f15e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:09:50.678996Z",
     "iopub.status.busy": "2025-10-06T18:09:50.678694Z",
     "iopub.status.idle": "2025-10-06T18:09:50.700143Z",
     "shell.execute_reply": "2025-10-06T18:09:50.699345Z"
    },
    "papermill": {
     "duration": 0.031811,
     "end_time": "2025-10-06T18:09:50.701738",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.669927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_sequences_for_lstm(input_df, output_df=None, test_template=None, is_training=True,\n",
    "                               window_size=Config.WINDOW_SIZE, cache_dir=\"cache\", save_to_disk=True):\n",
    "    \"\"\"(UPDATED) Prepare sequences; now always records last observed frame_id.\"\"\"\n",
    "    print(\"Preparing sequences for LSTM...\")\n",
    "    print('Using window size = ',window_size)\n",
    "    input_df = input_df.copy()\n",
    "    input_df['player_height_feet'] = input_df['player_height'].map(height_to_feet)\n",
    "    dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n",
    "    delta_t = 0.1\n",
    "    input_df['velocity_x'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.sin(dir_rad)\n",
    "    input_df['velocity_y'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.cos(dir_rad)\n",
    "    input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n",
    "    input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n",
    "    input_df['is_receiver'] = (input_df['player_role'] == 'Receiver').astype(int)\n",
    "    input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n",
    "    input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n",
    "    mass_kg = input_df['player_weight'].fillna(200.0) / 2.20462\n",
    "    input_df['momentum_x'] = input_df['velocity_x'] * mass_kg\n",
    "    input_df['momentum_y'] = input_df['velocity_y'] * mass_kg\n",
    "    # add age\n",
    "    current_date = datetime.now()\n",
    "    input_df['age'] = input_df['player_birth_date'].apply(\n",
    "        lambda x: (current_date - datetime.strptime(x, '%Y-%m-%d')).days // 365 if pd.notnull(x) else None\n",
    "    )\n",
    "    # add kenetic energy and force\n",
    "    input_df['kinetic_energy'] = 0.5 * mass_kg * (input_df['s'] ** 2)\n",
    "    input_df['force'] = mass_kg * input_df['a']\n",
    "    # Add rolling statistics\n",
    "    input_df['rolling_mean_velocity_x'] = input_df.groupby(['game_id', 'play_id', 'nfl_id'])['velocity_x'].transform(\n",
    "        lambda x: x.rolling(window=window_size, min_periods=1).mean()\n",
    "    )\n",
    "    input_df['rolling_std_acceleration'] = input_df.groupby(['game_id', 'play_id', 'nfl_id'])['a'].transform(\n",
    "        lambda x: x.rolling(window=window_size, min_periods=1).std()\n",
    "    )\n",
    "    # Ball related features\n",
    "    if all(col in input_df.columns for col in ['ball_land_x', 'ball_land_y']):\n",
    "        ball_dx = input_df['ball_land_x'] - input_df['x']\n",
    "        ball_dy = input_df['ball_land_y'] - input_df['y']\n",
    "        input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n",
    "        input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n",
    "        input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['closing_speed'] = (input_df['velocity_x'] * input_df['ball_direction_x'] +\n",
    "                                     input_df['velocity_y'] * input_df['ball_direction_y'])\n",
    "        input_df['estimated_time_to_ball'] = input_df['distance_to_ball'] / 20.0\n",
    "        input_df['projected_time_to_ball'] = input_df['distance_to_ball'] / (np.abs(input_df['closing_speed']) + 0.1)\n",
    "    input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n",
    "    input_df['is_right'] = (input_df['play_direction'] == 'right').astype(int)\n",
    "    input_df['is_left']  = (input_df['play_direction'] == 'left').astype(int)\n",
    "\n",
    "    target_rows = output_df if is_training else test_template\n",
    "    grouped_input = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n",
    "    target_groups = target_rows[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n",
    "\n",
    "    feature_cols = [\n",
    "        'x','y','s','a','o','dir',\n",
    "        'absolute_yardline_number',\n",
    "        'player_height_feet','player_weight',\n",
    "        'is_right','is_left',\n",
    "        'velocity_x','velocity_y',\n",
    "        'momentum_x','momentum_y',\n",
    "        'is_offense','is_defense','is_receiver','is_coverage','is_passer',\n",
    "        # New features\n",
    "        'age',\n",
    "        'kinetic_energy','force',\n",
    "        'rolling_mean_velocity_x','rolling_std_acceleration'\n",
    "    ]\n",
    "    if 'distance_to_ball' in input_df.columns:\n",
    "        feature_cols += [\n",
    "            'distance_to_ball','angle_to_ball','ball_direction_x','ball_direction_y',\n",
    "            'closing_speed','estimated_time_to_ball','projected_time_to_ball'\n",
    "        ]\n",
    "\n",
    "    sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = [], [], [], [], []\n",
    "    for _, row in tqdm(target_groups.iterrows(), total=len(target_groups)):\n",
    "        key = (row['game_id'], row['play_id'], row['nfl_id'])\n",
    "        try:\n",
    "            group_df = grouped_input.get_group(key)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        input_window = group_df.tail(window_size)\n",
    "        if len(input_window) < window_size:\n",
    "            # Option: pad instead of skip\n",
    "            # pad for test\n",
    "            if is_training:\n",
    "                continue\n",
    "            # pad for test\n",
    "            pad_length = window_size - len(input_window)\n",
    "            pad_df = pd.DataFrame(np.nan, index=range(pad_length), columns=input_window.columns)\n",
    "            input_window = pd.concat([pad_df, input_window], ignore_index=True).reset_index(drop=True)\n",
    "        seq = input_window[feature_cols].values\n",
    "        if np.isnan(seq.astype(np.float32)).any():\n",
    "            if is_training:\n",
    "                print(f\"Skipping sequence with NaNs for key {key}\")\n",
    "                continue\n",
    "            else:\n",
    "            # For test, we can pad NaNs with zeros (or mean values)\n",
    "                print(f\"Found NaNs in test sequence for key {key}, padding with mean values\")\n",
    "                seq = np.nan_to_num(seq, nan=0.0)\n",
    "                seq = np.where(seq == 0, np.mean(seq), seq)\n",
    "        sequences.append(seq)\n",
    "\n",
    "        last_frame_id = input_window['frame_id'].iloc[-1]\n",
    "        if is_training:\n",
    "            output_group = output_df[\n",
    "                (output_df['game_id']==row['game_id']) &\n",
    "                (output_df['play_id']==row['play_id']) &\n",
    "                (output_df['nfl_id']==row['nfl_id'])\n",
    "            ].sort_values('frame_id')\n",
    "            last_input_x = input_window.iloc[-1]['x']\n",
    "            last_input_y = input_window.iloc[-1]['y']\n",
    "            dx = output_group['x'].values - last_input_x  # cumulative displacement\n",
    "            dy = output_group['y'].values - last_input_y\n",
    "            future_frame_ids = output_group['frame_id'].values\n",
    "            targets_dx.append(dx)\n",
    "            targets_dy.append(dy)\n",
    "            targets_frame_ids.append(future_frame_ids)\n",
    "        sequence_ids.append({\n",
    "            'game_id': key[0],\n",
    "            'play_id': key[1],\n",
    "            'nfl_id': key[2],\n",
    "            'frame_id': last_frame_id  # now included\n",
    "        })\n",
    "    if is_training:\n",
    "        return sequences, targets_dx, targets_dy, targets_frame_ids,sequence_ids\n",
    "    return sequences, sequence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b8b4fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:09:50.717858Z",
     "iopub.status.busy": "2025-10-06T18:09:50.717513Z",
     "iopub.status.idle": "2025-10-06T18:10:18.376312Z",
     "shell.execute_reply": "2025-10-06T18:10:18.375242Z"
    },
    "papermill": {
     "duration": 27.668886,
     "end_time": "2025-10-06T18:10:18.378060",
     "exception": false,
     "start_time": "2025-10-06T18:09:50.709174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Loading data...\n",
      "Found 18 weeks of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input: 100%|██████████| 18/18 [00:25<00:00,  1.42s/it]\n",
      "Output: 100%|██████████| 18/18 [00:00<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4,880,579 input records, 562,936 output records\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preparing data...\")\n",
    "train_input, train_output, test_input, test_template = load_data(debug_fraction=Config.DEBUG_FRACTION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beed6210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:10:18.398937Z",
     "iopub.status.busy": "2025-10-06T18:10:18.398610Z",
     "iopub.status.idle": "2025-10-06T18:17:14.901829Z",
     "shell.execute_reply": "2025-10-06T18:17:14.900484Z"
    },
    "papermill": {
     "duration": 416.515676,
     "end_time": "2025-10-06T18:17:14.903528",
     "exception": false,
     "start_time": "2025-10-06T18:10:18.387852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing sequences for LSTM...\n",
      "Using window size =  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46045/46045 [04:40<00:00, 164.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sequences, targets_dx, targets_dy, targets_frame_ids, ids to lstm_sequences_targets_ids.joblib\n"
     ]
    }
   ],
   "source": [
    "sequences, targets_dx, targets_dy,targets_frame_ids,ids = prepare_sequences_for_lstm(\n",
    "    input_df=train_input,\n",
    "    output_df=train_output,\n",
    "    is_training=True,\n",
    "    window_size=Config.WINDOW_SIZE,\n",
    ")\n",
    "# save to /kaggle/working\n",
    "joblib.dump({\n",
    "    'sequences': sequences,\n",
    "    'targets_dx': targets_dx,\n",
    "    'targets_dy': targets_dy,\n",
    "    'targets_frame_ids': targets_frame_ids,\n",
    "    'ids': ids\n",
    "}, 'lstm_sequences_targets_ids.joblib')\n",
    "\n",
    "print(\"Saved sequences, targets_dx, targets_dy, targets_frame_ids, ids to lstm_sequences_targets_ids.joblib\")\n",
    "\n",
    "# Prepare 3D sequences for LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee1eef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:15.176698Z",
     "iopub.status.busy": "2025-10-06T18:17:15.176293Z",
     "iopub.status.idle": "2025-10-06T18:17:15.186503Z",
     "shell.execute_reply": "2025-10-06T18:17:15.184819Z"
    },
    "papermill": {
     "duration": 0.150073,
     "end_time": "2025-10-06T18:17:15.188619",
     "exception": false,
     "start_time": "2025-10-06T18:17:15.038546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46045, (6, 32), 46045, (21,), (21,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences),sequences[0].shape,len(targets_dx),targets_dx[0].shape,targets_dy[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "739889ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:15.460822Z",
     "iopub.status.busy": "2025-10-06T18:17:15.460469Z",
     "iopub.status.idle": "2025-10-06T18:17:15.468022Z",
     "shell.execute_reply": "2025-10-06T18:17:15.466887Z"
    },
    "papermill": {
     "duration": 0.144921,
     "end_time": "2025-10-06T18:17:15.469860",
     "exception": false,
     "start_time": "2025-10-06T18:17:15.324939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4 , 0.81, 1.24, 1.66, 2.09, 2.52, 2.93, 3.32, 3.69, 4.04, 4.37,\n",
       "       4.68, 4.96, 5.23, 5.5 , 5.77, 6.02, 6.28, 6.54, 6.79, 7.05])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_dx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d8dbe83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:15.739303Z",
     "iopub.status.busy": "2025-10-06T18:17:15.738993Z",
     "iopub.status.idle": "2025-10-06T18:17:15.749705Z",
     "shell.execute_reply": "2025-10-06T18:17:15.748766Z"
    },
    "papermill": {
     "duration": 0.148517,
     "end_time": "2025-10-06T18:17:15.751178",
     "exception": false,
     "start_time": "2025-10-06T18:17:15.602661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_oof_predictions(model, scaler, X_val_unscaled, val_ids, y_val_dx, y_val_dy, y_val_frame_ids, val_data):\n",
    "    \"\"\"\n",
    "    Build per-frame OOF predictions using ALL models (no exclusion).\n",
    "    Returns pred_df, true_df with real frame_ids.\n",
    "    \"\"\"\n",
    "    pred_rows, true_rows = [], []\n",
    "    for i, seq_info in enumerate(val_ids):\n",
    "        game_id = seq_info['game_id']\n",
    "        play_id = seq_info['play_id']\n",
    "        nfl_id = seq_info['nfl_id']\n",
    "        x_last = val_data.iloc[i]['x_last']\n",
    "        y_last = val_data.iloc[i]['y_last']\n",
    "        dx_true = y_val_dx[i]\n",
    "        dy_true = y_val_dy[i]\n",
    "        frame_ids_future = y_val_frame_ids[i]  # real future frame_ids\n",
    "        # True rows\n",
    "        for t in range(len(dx_true)):\n",
    "            true_rows.append({\n",
    "                'id': f\"{game_id}_{play_id}_{nfl_id}_{frame_ids_future[t]}\",\n",
    "                'x': x_last + dx_true[t],\n",
    "                'y': y_last + dy_true[t]\n",
    "            })\n",
    "        # Ensemble predictions\n",
    "        per_model_dx, per_model_dy = [], []\n",
    "        \n",
    "            \n",
    "        scaled_seq = scaler.transform(X_val_unscaled[i]).astype(np.float32)\n",
    "        inp = torch.tensor(scaled_seq).unsqueeze(0).to(next(model.parameters()).device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(inp).cpu().numpy()[0]  # (H,2) cumulative dx,dy\n",
    "        per_model_dx.append(out[:,0])\n",
    "        per_model_dy.append(out[:,1])\n",
    "        ens_dx = np.mean(per_model_dx, axis=0)\n",
    "        ens_dy = np.mean(per_model_dy, axis=0)\n",
    "        # Use only required length\n",
    "        for t in range(len(dx_true)):\n",
    "            pred_rows.append({\n",
    "                'id': f\"{game_id}_{play_id}_{nfl_id}_{frame_ids_future[t]}\",\n",
    "                'x': np.clip(x_last + ens_dx[t], Config.FIELD_X_MIN, Config.FIELD_X_MAX),\n",
    "                'y': np.clip(y_last + ens_dy[t], Config.FIELD_Y_MIN, Config.FIELD_Y_MAX),\n",
    "            })\n",
    "    return pd.DataFrame(pred_rows), pd.DataFrame(true_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "222ab90d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:16.094815Z",
     "iopub.status.busy": "2025-10-06T18:17:16.094523Z",
     "iopub.status.idle": "2025-10-06T18:17:16.102994Z",
     "shell.execute_reply": "2025-10-06T18:17:16.101962Z"
    },
    "papermill": {
     "duration": 0.144989,
     "end_time": "2025-10-06T18:17:16.104473",
     "exception": false,
     "start_time": "2025-10-06T18:17:15.959484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# PREDICTION UTILITIES\n",
    "# ================================================================================\n",
    "\n",
    "def displacement_to_position(displacement_dx, displacement_dy, x_last, y_last):\n",
    "    \"\"\"\n",
    "    Convert displacement predictions to absolute positions.\n",
    "    \n",
    "    Args:\n",
    "        displacement_dx: Predicted displacement in x direction\n",
    "        displacement_dy: Predicted displacement in y direction  \n",
    "        x_last: Last known x position\n",
    "        y_last: Last known y position\n",
    "        \n",
    "    Returns:\n",
    "        pred_x, pred_y: Absolute predicted positions\n",
    "    \"\"\"\n",
    "    pred_x = x_last + displacement_dx\n",
    "    pred_y = y_last + displacement_dy\n",
    "    \n",
    "    # Apply field constraints\n",
    "    pred_x = np.clip(pred_x, Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n",
    "    pred_y = np.clip(pred_y, Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n",
    "    \n",
    "    return pred_x, pred_y\n",
    "\n",
    "\n",
    "def predict_with_lstm(model, X_test, test_data):\n",
    "    \"\"\"\n",
    "    Make predictions with trained LSTM model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LSTM model\n",
    "        X_test: Test sequences (batch, sequence_length, features)\n",
    "        test_data: Test dataframe for position conversion\n",
    "        \n",
    "    Returns:\n",
    "        pred_x, pred_y: Absolute predicted positions\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    \n",
    "    predictions_dx = []\n",
    "    predictions_dy = []\n",
    "    \n",
    "    # Predict in batches\n",
    "    batch_size = 1024\n",
    "    test_dataset = TensorDataset(torch.FloatTensor(X_test))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            \n",
    "            predictions_dx.extend(outputs[:, 0].cpu().numpy())\n",
    "            predictions_dy.extend(outputs[:, 1].cpu().numpy())\n",
    "    \n",
    "    # Convert to absolute positions\n",
    "    pred_x, pred_y = displacement_to_position(\n",
    "        np.array(predictions_dx), \n",
    "        np.array(predictions_dy),\n",
    "        test_data['x_last'].values,\n",
    "        test_data['y_last'].values\n",
    "    )\n",
    "    \n",
    "    return pred_x, pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1592081",
   "metadata": {
    "papermill": {
     "duration": 0.133944,
     "end_time": "2025-10-06T18:17:16.371426",
     "exception": false,
     "start_time": "2025-10-06T18:17:16.237482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b394711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:16.637935Z",
     "iopub.status.busy": "2025-10-06T18:17:16.637618Z",
     "iopub.status.idle": "2025-10-06T18:17:16.653211Z",
     "shell.execute_reply": "2025-10-06T18:17:16.652002Z"
    },
    "papermill": {
     "duration": 0.151715,
     "end_time": "2025-10-06T18:17:16.655050",
     "exception": false,
     "start_time": "2025-10-06T18:17:16.503335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_test_predictions_lstm(models, X_test, test_seq_ids, test_input):\n",
    "    \"\"\"\n",
    "    Make predictions on test data using ensemble of trained LSTM models.\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained LSTM models\n",
    "        X_test: Test sequences (batch, sequence_length, features)\n",
    "        test_seq_ids: Mapping info for test sequences\n",
    "        test_input: Original test input dataframe\n",
    "        \n",
    "    Returns:\n",
    "        submission: DataFrame with id, x, y columns\n",
    "    \"\"\"\n",
    "    print(\"Making test predictions...\")\n",
    "    \n",
    "    if len(X_test) == 0:\n",
    "        print(\"WARNING: No test sequences provided. Using fallback predictions.\")\n",
    "        # Fallback: use last known positions\n",
    "        submission = pd.DataFrame({\n",
    "            'id': (test_input['game_id'].astype(str) + '_' + \n",
    "                  test_input['play_id'].astype(str) + '_' + \n",
    "                  test_input['nfl_id'].astype(str) + '_' + \n",
    "                  test_input['frame_id'].astype(str)),\n",
    "            'x': test_input['x'].values,\n",
    "            'y': test_input['y'].values\n",
    "        })\n",
    "        return submission\n",
    "    \n",
    "    print(f\"Test sequences shape: {X_test.shape}\")\n",
    "    \n",
    "    # Get ensemble predictions\n",
    "    all_predictions_dx = []\n",
    "    all_predictions_dy = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Predicting with model {i+1}/{len(models)}...\")\n",
    "        \n",
    "        device = next(model.parameters()).device\n",
    "        model.eval()\n",
    "        \n",
    "        predictions_dx = []\n",
    "        predictions_dy = []\n",
    "        \n",
    "        # Predict in batches\n",
    "        batch_size = 512\n",
    "        test_dataset = TensorDataset(torch.FloatTensor(X_test))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, in test_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                \n",
    "                predictions_dx.extend(outputs[:, 0].cpu().numpy())\n",
    "                predictions_dy.extend(outputs[:, 1].cpu().numpy())\n",
    "        \n",
    "        all_predictions_dx.append(np.array(predictions_dx))\n",
    "        all_predictions_dy.append(np.array(predictions_dy))\n",
    "    \n",
    "    # Ensemble average\n",
    "    ensemble_dx = np.mean(all_predictions_dx, axis=0)\n",
    "    ensemble_dy = np.mean(all_predictions_dy, axis=0)\n",
    "    \n",
    "    # Initialize output arrays with NaN\n",
    "    final_pred_x = np.full(len(test_input), np.nan)\n",
    "    final_pred_y = np.full(len(test_input), np.nan)\n",
    "    \n",
    "    # Map predictions back to original test rows\n",
    "    for i, seq_info in enumerate(test_seq_ids):\n",
    "        # Find corresponding row in test_input\n",
    "        mask = ((test_input['game_id'] == seq_info['game_id']) &\n",
    "               (test_input['play_id'] == seq_info['play_id']) &\n",
    "               (test_input['nfl_id'] == seq_info['nfl_id']) &\n",
    "               (test_input['frame_id'] == seq_info['frame_id']))\n",
    "        \n",
    "        if mask.any():\n",
    "            # Get reference position\n",
    "            ref_x = test_input.loc[mask, 'x'].iloc[0]\n",
    "            ref_y = test_input.loc[mask, 'y'].iloc[0]\n",
    "            \n",
    "            # Convert displacement to absolute position\n",
    "            pred_x = ref_x + ensemble_dx[i]\n",
    "            pred_y = ref_y + ensemble_dy[i]\n",
    "            \n",
    "            # Store predictions\n",
    "            final_pred_x[mask] = pred_x\n",
    "            final_pred_y[mask] = pred_y\n",
    "    \n",
    "    # Fill any remaining NaN with original positions\n",
    "    nan_mask = np.isnan(final_pred_x)\n",
    "    final_pred_x[nan_mask] = test_input.loc[nan_mask, 'x'].values\n",
    "    final_pred_y[nan_mask] = test_input.loc[nan_mask, 'y'].values\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission = pd.DataFrame({\n",
    "        'id': (test_input['game_id'].astype(str) + '_' + \n",
    "              test_input['play_id'].astype(str) + '_' + \n",
    "              test_input['nfl_id'].astype(str) + '_' + \n",
    "              test_input['frame_id'].astype(str)),\n",
    "        'x': final_pred_x,\n",
    "        'y': final_pred_y\n",
    "    })\n",
    "    \n",
    "    # Final validation\n",
    "    submission['x'] = np.clip(submission['x'], Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n",
    "    submission['y'] = np.clip(submission['y'], Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n",
    "    \n",
    "    print(f\"Created submission with {len(submission)} predictions\")\n",
    "    print(f\"X range: [{submission['x'].min():.2f}, {submission['x'].max():.2f}]\")\n",
    "    print(f\"Y range: [{submission['y'].min():.2f}, {submission['y'].max():.2f}]\")\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c696c",
   "metadata": {
    "papermill": {
     "duration": 0.133349,
     "end_time": "2025-10-06T18:17:16.923925",
     "exception": false,
     "start_time": "2025-10-06T18:17:16.790576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e92b265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:17.196083Z",
     "iopub.status.busy": "2025-10-06T18:17:17.195730Z",
     "iopub.status.idle": "2025-10-06T18:17:17.204821Z",
     "shell.execute_reply": "2025-10-06T18:17:17.203952Z"
    },
    "papermill": {
     "duration": 0.150285,
     "end_time": "2025-10-06T18:17:17.206446",
     "exception": false,
     "start_time": "2025-10-06T18:17:17.056161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CombinedLSTMGRURegressor(nn.Module):\n",
    "    \"\"\"Parallel LSTM+GRU encoders on same input; concatenate last states.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.3, max_frames_output=10):\n",
    "        super().__init__()\n",
    "        self.max_frames_output = max_frames_output\n",
    "        branch_h = max(16, hidden_dim // 2)  # keep total ~hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim, hidden_size=branch_h,\n",
    "            num_layers=num_layers, batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_dim, hidden_size=branch_h,\n",
    "            num_layers=num_layers, batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * branch_h, 128),\n",
    "            nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, 2 * max_frames_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        gru_out, _ = self.gru(x)\n",
    "        last_lstm = lstm_out[:, -1, :]\n",
    "        last_gru  = gru_out[:, -1, :]\n",
    "        combined = torch.cat([last_lstm, last_gru], dim=-1)\n",
    "        all_outputs = self.fc(combined)\n",
    "        B = all_outputs.shape[0]\n",
    "        return all_outputs.view(B, self.max_frames_output, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a63bf5",
   "metadata": {
    "papermill": {
     "duration": 0.166633,
     "end_time": "2025-10-06T18:17:17.508153",
     "exception": false,
     "start_time": "2025-10-06T18:17:17.341520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b78be504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:17.872333Z",
     "iopub.status.busy": "2025-10-06T18:17:17.871997Z",
     "iopub.status.idle": "2025-10-06T18:17:17.900388Z",
     "shell.execute_reply": "2025-10-06T18:17:17.898963Z"
    },
    "papermill": {
     "duration": 0.25213,
     "end_time": "2025-10-06T18:17:17.902245",
     "exception": false,
     "start_time": "2025-10-06T18:17:17.650115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add these imports if needed\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_improved_lstm_model(\n",
    "    X_train, y_train_dx, y_train_dy,\n",
    "    X_val, y_val_dx, y_val_dy,\n",
    "    val_data, input_dim,\n",
    "    epochs=50, batch_size=512, learning_rate=0.001,patience = 10,\n",
    "    eval_all_frames=True,print_score_every=10  # set False to score only first frame\n",
    "):\n",
    "    X_train = np.array(X_train, dtype=np.float32)\n",
    "    X_val   = np.array(X_val, dtype=np.float32)\n",
    "\n",
    "    # Max future horizon\n",
    "    max_frames_output = Config.MAX_FUTURE_HORIZON\n",
    "    print(f\"Maximum output frames: {max_frames_output}\")\n",
    "\n",
    "    def prepare_targets_batch(batch_dx, batch_dy):\n",
    "        output_lengths = [len(dx) for dx in batch_dx]\n",
    "        tensors_dx, tensors_dy, masks = [], [], []\n",
    "        for i in range(len(batch_dx)):\n",
    "            dx_padded = np.pad(batch_dx[i], (0, max_frames_output - len(batch_dx[i])), constant_values=0)\n",
    "            dy_padded = np.pad(batch_dy[i], (0, max_frames_output - len(batch_dy[i])), constant_values=0)\n",
    "            tensors_dx.append(torch.tensor(dx_padded, dtype=torch.float32))\n",
    "            tensors_dy.append(torch.tensor(dy_padded, dtype=torch.float32))\n",
    "            mask = torch.zeros(max_frames_output)\n",
    "            mask[:len(batch_dx[i])] = 1\n",
    "            masks.append(mask)\n",
    "        batch_dx_tensor = torch.stack(tensors_dx).unsqueeze(-1)  # (B, L, 1)\n",
    "        batch_dy_tensor = torch.stack(tensors_dy).unsqueeze(-1)  # (B, L, 1)\n",
    "        batch_targets = torch.cat([batch_dx_tensor, batch_dy_tensor], dim=-1)  # (B, L, 2)\n",
    "        batch_mask = torch.stack(masks)  # (B, L)\n",
    "        return batch_targets, batch_mask, output_lengths\n",
    "\n",
    "    # Pre-batch (kept same style as original)\n",
    "    train_batches = []\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        end = min(i + batch_size, len(X_train))\n",
    "        batch_y, batch_mask, lengths = prepare_targets_batch(\n",
    "            [y_train_dx[j] for j in range(i, end)],\n",
    "            [y_train_dy[j] for j in range(i, end)]\n",
    "        )\n",
    "        train_batches.append((torch.tensor(X_train[i:end]), batch_y, batch_mask, lengths))\n",
    "\n",
    "    val_batches = []\n",
    "    for i in range(0, len(X_val), batch_size):\n",
    "        end = min(i + batch_size, len(X_val))\n",
    "        batch_y, batch_mask, lengths = prepare_targets_batch(\n",
    "            [y_val_dx[j] for j in range(i, end)],\n",
    "            [y_val_dy[j] for j in range(i, end)]\n",
    "        )\n",
    "        val_batches.append((torch.tensor(X_val[i:end]), batch_y, batch_mask, lengths))\n",
    "\n",
    "    model = CombinedLSTMGRURegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=Config.HIDDEN_DIM,\n",
    "        num_layers=Config.NUM_LAYERS,\n",
    "        dropout=Config.DROPOUT,\n",
    "        max_frames_output=Config.MAX_FUTURE_HORIZON\n",
    "    )\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Using device:\", device)\n",
    "    model.to(device)\n",
    "    print('sucessfully moved model to device')\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', patience=5, factor=0.5, verbose=True\n",
    "    )\n",
    "\n",
    "    best_score = float('inf')\n",
    "    best_competition_score = float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    patience_ctr = 0\n",
    "\n",
    "    # Sequence-level metadata (one row per sequence) from val_data\n",
    "    # Ensure order matches X_val / y_val arrays\n",
    "    val_meta = val_data.reset_index(drop=True)\n",
    "    assert len(val_meta) == len(X_val), \"val_data length mismatch with validation sequences\"\n",
    "\n",
    "    x_last = val_meta['x_last'].values\n",
    "    y_last = val_meta['y_last'].values\n",
    "    seq_game = val_meta['game_id'].values\n",
    "    seq_play = val_meta['play_id'].values\n",
    "    seq_nfl  = val_meta['nfl_id'].values\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # -------- Train --------\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_X, batch_y, batch_mask, lengths in train_batches:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_mask = batch_mask.to(device).unsqueeze(-1)  # (B,L,1)\n",
    "\n",
    "            outputs = model(batch_X)  # (B, max_frames_output, 2)\n",
    "\n",
    "            loss_all = criterion(outputs, batch_y)  # (B,L,2)\n",
    "            mask_expanded = batch_mask.expand_as(loss_all)\n",
    "            masked_loss = (loss_all * mask_expanded).sum() / mask_expanded.sum()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            masked_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_losses.append(masked_loss.item())\n",
    "\n",
    "        # -------- Validate (build flattened per-frame DataFrames) --------\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "\n",
    "        pred_rows = []\n",
    "        true_rows = []\n",
    "\n",
    "        seq_cursor = 0  # global sequence index across val batches\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y, batch_mask, lengths in val_batches:\n",
    "                B = batch_X.size(0)\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_mask_device = batch_mask.to(device).unsqueeze(-1)\n",
    "\n",
    "                outputs = model(batch_X)\n",
    "                loss_all = criterion(outputs, batch_y)\n",
    "                mask_expanded = batch_mask_device.expand_as(loss_all)\n",
    "                masked_loss = (loss_all * mask_expanded).sum() / mask_expanded.sum()\n",
    "                val_losses.append(masked_loss.item())\n",
    "\n",
    "                outputs_cpu = outputs.cpu()\n",
    "                targets_cpu = batch_y.cpu()\n",
    "\n",
    "                for b in range(B):\n",
    "                    L = lengths[b]  # valid future frames\n",
    "                    game_id = seq_game[seq_cursor]\n",
    "                    play_id = seq_play[seq_cursor]\n",
    "                    nfl_id  = seq_nfl[seq_cursor]\n",
    "                    base_x  = x_last[seq_cursor]\n",
    "                    base_y  = y_last[seq_cursor]\n",
    "\n",
    "                    valid_pred = outputs_cpu[b, :L, :]   # (L,2) dx,dy\n",
    "                    valid_true = targets_cpu[b, :L, :]   # (L,2)\n",
    "\n",
    "                    for t in range(L):\n",
    "                        frame_rel = t + 1  # start at 1\n",
    "                        dx_pred, dy_pred = valid_pred[t].tolist()\n",
    "                        dx_true, dy_true = valid_true[t].tolist()\n",
    "\n",
    "                        pred_rows.append({\n",
    "                            'id': f\"{game_id}_{play_id}_{nfl_id}_{frame_rel}\",\n",
    "                            'x': base_x + dx_pred,\n",
    "                            'y': base_y + dy_pred\n",
    "                        })\n",
    "                        true_rows.append({\n",
    "                            'id': f\"{game_id}_{play_id}_{nfl_id}_{frame_rel}\",\n",
    "                            'x': base_x + dx_true,\n",
    "                            'y': base_y + dy_true\n",
    "                        })\n",
    "\n",
    "                    seq_cursor += 1\n",
    "        mean_vloss = np.mean(val_losses)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - TrainLoss {np.mean(train_losses):.4f} ValLoss {mean_vloss:.4f}\")\n",
    "        # Build DataFrames\n",
    "        val_submission_full = pd.DataFrame(pred_rows)\n",
    "        val_truth_full = pd.DataFrame(true_rows)\n",
    "        \n",
    "        if not eval_all_frames:\n",
    "            # Keep only first-frame per id group (frame_id_rel==1)\n",
    "            val_submission_eval = val_submission_full[val_submission_full['id'].str.endswith('_1')].copy()\n",
    "            val_truth_eval = val_truth_full[val_truth_full['id'].str.endswith('_1')].copy()\n",
    "        else:\n",
    "            val_submission_eval = val_submission_full\n",
    "            val_truth_eval = val_truth_full\n",
    "        competition_score = score(val_truth_eval, val_submission_eval, 'id')\n",
    "        print(f\"Val RMSE ({'all' if eval_all_frames else 'first'} frames): {competition_score:.5f}\")\n",
    "            \n",
    "        if competition_score < best_competition_score:\n",
    "            best_competition_score = competition_score\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if mean_vloss < best_score:\n",
    "            best_score = mean_vloss\n",
    "            best_state = model.state_dict()\n",
    "            patience_ctr = 0\n",
    "            print(f\" New best model found at epoch {epoch+1} with ValLoss {best_score:.4f}\")\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "\n",
    "        scheduler.step(np.mean(val_losses))\n",
    "        if patience_ctr >= patience:\n",
    "            print(f\"Early stopping epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, best_score, best_competition_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd66ce",
   "metadata": {
    "papermill": {
     "duration": 0.13151,
     "end_time": "2025-10-06T18:17:18.167408",
     "exception": false,
     "start_time": "2025-10-06T18:17:18.035898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train 1 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b98749c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:18.436510Z",
     "iopub.status.busy": "2025-10-06T18:17:18.436152Z",
     "iopub.status.idle": "2025-10-06T18:17:18.878867Z",
     "shell.execute_reply": "2025-10-06T18:17:18.877462Z"
    },
    "papermill": {
     "duration": 0.578593,
     "end_time": "2025-10-06T18:17:18.881000",
     "exception": false,
     "start_time": "2025-10-06T18:17:18.302407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences shape: 46045\n",
      "Targets_dx: 46045 sequences, lengths: [21, 21, 21, 9, 9]...\n",
      "Targets_dy: 46045 sequences, lengths: [21, 21, 21, 9, 9]...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train 1 fold using GroupKFold\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f\"Sequences shape: {len(sequences)}\")  # Already an object array\n",
    "print(f\"Targets_dx: {len(targets_dx)} sequences, lengths: {[len(dx) for dx in targets_dx[:5]]}...\")  # Show first 5 lengths\n",
    "print(f\"Targets_dy: {len(targets_dy)} sequences, lengths: {[len(dy) for dy in targets_dy[:5]]}...\")\n",
    "\n",
    "# Convert lists to numpy arrays for consistent handling\n",
    "sequences = np.array(sequences, dtype=object) \n",
    "targets_dx = np.array(targets_dx, dtype=object)\n",
    "targets_dy = np.array(targets_dy, dtype=object)\n",
    "\n",
    "# Get number of output frames from the targets\n",
    "num_frames_output = [targets_dx[i].shape for i in range(len(targets_dx))]\n",
    "# print(f\"Number of output frames to predict: {num_frames_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a82e3d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:19.144903Z",
     "iopub.status.busy": "2025-10-06T18:17:19.144552Z",
     "iopub.status.idle": "2025-10-06T18:17:19.149944Z",
     "shell.execute_reply": "2025-10-06T18:17:19.148927Z"
    },
    "papermill": {
     "duration": 0.139369,
     "end_time": "2025-10-06T18:17:19.151423",
     "exception": false,
     "start_time": "2025-10-06T18:17:19.012054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Prepare the data for training using GroupKFold\n",
    "# groups = [d['play_id'] for d in ids]\n",
    "# gkf = GroupKFold(n_splits=5)\n",
    "# folds = list(gkf.split(sequences, groups=groups))\n",
    "\n",
    "# # Use the first fold\n",
    "# train_idx, val_idx = folds[0]\n",
    "\n",
    "# X_train_unscaled = sequences[train_idx]\n",
    "# X_val_unscaled = sequences[val_idx]\n",
    "# y_train_dx_fold = targets_dx[train_idx]\n",
    "# y_train_dy_fold = targets_dy[train_idx]\n",
    "# y_val_dx_fold = targets_dx[val_idx]\n",
    "# y_val_dy_fold = targets_dy[val_idx]\n",
    "\n",
    "# # Validation metadata (use unscaled last positions)\n",
    "# val_ids = [ids[i] for i in val_idx]\n",
    "# val_data = pd.DataFrame(val_ids)\n",
    "# val_data['x_last'] = np.array([s[-1, 0] for s in X_val_unscaled])\n",
    "# val_data['y_last'] = np.array([s[-1, 1] for s in X_val_unscaled])\n",
    "\n",
    "# # Fit scaler on training-fold frames only (no leakage)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# train_frames = np.vstack([s for s in X_train_unscaled])  # (n_train*window, feat)\n",
    "# scaler.fit(train_frames)\n",
    "\n",
    "# # Helper to apply scaler to each sequence\n",
    "# def apply_scaler_to_sequences(seq_array, scaler):\n",
    "#     scaled = []\n",
    "#     for s in seq_array:\n",
    "#         scaled.append(scaler.transform(s))\n",
    "#     return np.array(scaled, dtype=object)\n",
    "\n",
    "# # Produce scaled arrays used for training\n",
    "# X_train_fold = apply_scaler_to_sequences(X_train_unscaled, scaler)\n",
    "# X_val_fold = apply_scaler_to_sequences(X_val_unscaled, scaler)\n",
    "\n",
    "# # Optionally persist scaler for inference\n",
    "# joblib.dump(scaler, 'lstm_feature_scaler.joblib')\n",
    "\n",
    "# # REMOVE the block that overwrote game_id/play_id/nfl_id using train_output:\n",
    "# # (Delete these lines if present)\n",
    "# # val_data['x'] = train_output.iloc[val_idx]['x'].values\n",
    "# # val_data['y'] = train_output.iloc[val_idx]['y'].values\n",
    "# # val_data['game_id'] = train_output.iloc[val_idx]['game_id'].values\n",
    "# # val_data['play_id'] = train_output.iloc[val_idx]['play_id'].values\n",
    "# # val_data['nfl_id'] = train_output.iloc[val_idx]['nfl_id'].values\n",
    "# # val_data['frame_id'] = train_output.iloc[val_idx]['frame_id'].values\n",
    "# # val_data['id'] = ...\n",
    "\n",
    "# # Alignment sanity check (optional)\n",
    "# # print(\"Alignment check (first 3):\")\n",
    "# # for k in range(min(3, len(X_val_fold))):\n",
    "# #     seq_id = val_ids[k]\n",
    "# #     dx_seq = y_val_dx_fold[k]\n",
    "# #     if len(dx_seq) == 0: \n",
    "# #         continue\n",
    "# #     approx_first_abs = val_data.loc[k, 'x_last'] + dx_seq[0]\n",
    "# #     print(seq_id, \"first_pred_abs_x_example:\", approx_first_abs)\n",
    "# # Train the model - no need to provide num_frames_output\n",
    "# input_dim = X_train_fold[0].shape[-1]\n",
    "# model, best_score = train_improved_lstm_model(\n",
    "#     X_train_fold, y_train_dx_fold, y_train_dy_fold,\n",
    "#     X_val_fold, y_val_dx_fold, y_val_dy_fold,\n",
    "#     val_data, input_dim=input_dim,\n",
    "#     epochs=200, batch_size=512, learning_rate=0.001,eval_all_frames=True\n",
    "# )\n",
    "\n",
    "# print(f\"Best validation RMSE (1st fold): {best_score:.5f}\")\n",
    "\n",
    "# # Save the model\n",
    "# torch.save(model.state_dict(), 'lstm_model.pt')\n",
    "# print(\"Model saved to 'lstm_model.pt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7b26c",
   "metadata": {
    "papermill": {
     "duration": 0.134552,
     "end_time": "2025-10-06T18:17:19.419301",
     "exception": false,
     "start_time": "2025-10-06T18:17:19.284749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c2d58ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:19.686879Z",
     "iopub.status.busy": "2025-10-06T18:17:19.686502Z",
     "iopub.status.idle": "2025-10-06T18:17:19.696191Z",
     "shell.execute_reply": "2025-10-06T18:17:19.695136Z"
    },
    "papermill": {
     "duration": 0.144812,
     "end_time": "2025-10-06T18:17:19.698064",
     "exception": false,
     "start_time": "2025-10-06T18:17:19.553252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_with_improved_lstm(model, X_test, test_data,test_template=None, return_all=True):\n",
    "    \"\"\"\n",
    "    Predict cumulative displacements for each horizon.\n",
    "    Returns:\n",
    "      pred_first_x, pred_first_y, dx_cum, dy_cum, (optional) abs_all_x, abs_all_y\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    X = np.array(X_test, dtype=np.float32)\n",
    "    test_dataset = TensorDataset(torch.from_numpy(X))\n",
    "    loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "    dx_list, dy_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for (batch,) in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)  # (B, H, 2) cumulative displacements\n",
    "            # print(f\"Predicted batch shape: {out.shape}\")\n",
    "            dx_list.append(out[:, :, 0].cpu().numpy())\n",
    "            dy_list.append(out[:, :, 1].cpu().numpy())\n",
    "    # print(f\"Predicted {len(dx_list)} batches\")\n",
    "    if not dx_list:\n",
    "        print(\"WARNING: No predictions made. Using fallback.\")\n",
    "        empty = np.zeros((0, getattr(model, \"max_frames_output\", 1)))\n",
    "        return empty, empty, empty, empty, empty, empty\n",
    "    dx_cum = np.vstack(dx_list)\n",
    "    dy_cum = np.vstack(dy_list)\n",
    "    x_last = test_data['x_last'].values\n",
    "    y_last = test_data['y_last'].values\n",
    "    abs_all_x = x_last[:, None] + dx_cum\n",
    "    abs_all_y = y_last[:, None] + dy_cum\n",
    "    abs_all_x = np.clip(abs_all_x, Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n",
    "    abs_all_y = np.clip(abs_all_y, Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n",
    "    pred_first_x = abs_all_x[:, 0]\n",
    "    pred_first_y = abs_all_y[:, 0]\n",
    "    # print(pred_first_x.shape, pred_first_y.shape, dx_cum.shape, dy_cum.shape, abs_all_x.shape, abs_all_y.shape)\n",
    "    # print(abs_all_x[0])\n",
    "    if return_all:\n",
    "        return pred_first_x, pred_first_y, dx_cum, dy_cum, abs_all_x, abs_all_y\n",
    "    # print(pred_first_x.shape, pred_first_y.shape, dx_cum.shape, dy_cum.shape)\n",
    "    return pred_first_x, pred_first_y, dx_cum, dy_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35d78131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:20.041152Z",
     "iopub.status.busy": "2025-10-06T18:17:20.040798Z",
     "iopub.status.idle": "2025-10-06T18:17:20.055220Z",
     "shell.execute_reply": "2025-10-06T18:17:20.053888Z"
    },
    "papermill": {
     "duration": 0.222167,
     "end_time": "2025-10-06T18:17:20.057095",
     "exception": false,
     "start_time": "2025-10-06T18:17:19.834928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ensemble_predictions(models, scalers, X_test_unscaled, test_seq_ids, test_template):\n",
    "    \"\"\"\n",
    "    Ensemble cumulative displacement predictions across models/folds.\n",
    "    Produces one row per (game_id, play_id, nfl_id, frame_id) present in test_template.\n",
    "    \n",
    "    Args:\n",
    "        models: list[ImprovedLSTMRegressor]\n",
    "        scalers: list[StandardScaler] (same length as models) or None\n",
    "        X_test_unscaled: list/array of shape (N, seq_len, feats)\n",
    "        test_seq_ids: list of dicts including metadata for each sequence\n",
    "        test_template: DataFrame with required submission rows\n",
    "    \n",
    "    Returns:\n",
    "        submission: DataFrame with id, x, y columns for all frames in test_template.\n",
    "    \"\"\"\n",
    "    if len(models) == 0:\n",
    "        print(\"No models supplied.\")\n",
    "        return None\n",
    "    if scalers is not None and len(scalers) != len(models):\n",
    "        raise ValueError(\"Length of scalers must match models or be None.\")\n",
    "\n",
    "    # Convert test sequences to numpy array\n",
    "    X_test_unscaled = np.array(X_test_unscaled, dtype=object)\n",
    "    test_meta = pd.DataFrame(test_seq_ids)\n",
    "\n",
    "    # Prepare last observed positions\n",
    "    x_last = np.array([seq[-1, 0] for seq in X_test_unscaled], dtype=np.float32)\n",
    "    y_last = np.array([seq[-1, 1] for seq in X_test_unscaled], dtype=np.float32)\n",
    "    test_meta['x_last'] = x_last\n",
    "    test_meta['y_last'] = y_last\n",
    "\n",
    "    # Ensemble predictions\n",
    "    per_model_abs = []\n",
    "    max_h = 0\n",
    "    for i, model in enumerate(models):\n",
    "        scaler = scalers[i] if scalers is not None else None\n",
    "        if scaler is not None:\n",
    "            scaled = np.array([scaler.transform(s) for s in X_test_unscaled], dtype=object)\n",
    "        else:\n",
    "            scaled = np.array(X_test_unscaled, dtype=object)\n",
    "        # Convert object -> stacked float tensor\n",
    "        stacked = np.stack(scaled.astype(np.float32))\n",
    "        _, _, _, _, abs_all_x, abs_all_y = predict_with_improved_lstm(\n",
    "            model, stacked, test_meta, return_all=True\n",
    "        )\n",
    "        per_model_abs.append((abs_all_x, abs_all_y))\n",
    "        max_h = max(max_h, abs_all_x.shape[1])\n",
    "\n",
    "    # Pad & average predictions across models\n",
    "    M = len(per_model_abs)\n",
    "    N = len(test_meta)\n",
    "    pad_x = np.full((M, N, max_h), np.nan, dtype=np.float32)\n",
    "    pad_y = np.full((M, N, max_h), np.nan, dtype=np.float32)\n",
    "    for m, (ax, ay) in enumerate(per_model_abs):\n",
    "        h = ax.shape[1]\n",
    "        pad_x[m, :, :h] = ax\n",
    "        pad_y[m, :, :h] = ay\n",
    "    ens_x = np.nanmean(pad_x, axis=0)\n",
    "    ens_y = np.nanmean(pad_y, axis=0)\n",
    "\n",
    "    # Create submission DataFrame\n",
    "    out_rows = []\n",
    "    for i, seq_info in test_meta.iterrows():\n",
    "        # game_id, play_id, nfl_id = seq_info['game_id'], seq_info['play_id'], seq_info['nfl_id']\n",
    "        game_id = int(seq_info['game_id'])\n",
    "        play_id = int(seq_info['play_id'])\n",
    "        nfl_id = int(seq_info['nfl_id'])\n",
    "        frame_ids = test_template[\n",
    "            (test_template['game_id'] == game_id) &\n",
    "            (test_template['play_id'] == play_id) &\n",
    "            (test_template['nfl_id'] == nfl_id)\n",
    "        ]['frame_id'].sort_values().tolist()\n",
    "\n",
    "        for t, frame_id in enumerate(frame_ids):\n",
    "            if t < ens_x.shape[1]:  # Ensure we don't exceed the predicted horizon\n",
    "                px = ens_x[i, t]\n",
    "                py = ens_y[i, t]\n",
    "            else:\n",
    "                # If predictions are shorter than required frames, use the last prediction\n",
    "                px = ens_x[i, -1]\n",
    "                py = ens_y[i, -1]\n",
    "\n",
    "            out_rows.append({\n",
    "                'id': f\"{game_id}_{play_id}_{nfl_id}_{frame_id}\",\n",
    "                'x': np.clip(px, Config.FIELD_X_MIN, Config.FIELD_X_MAX),\n",
    "                'y': np.clip(py, Config.FIELD_Y_MIN, Config.FIELD_Y_MAX),\n",
    "            })\n",
    "\n",
    "    submission = pd.DataFrame(out_rows)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b45b139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:20.327117Z",
     "iopub.status.busy": "2025-10-06T18:17:20.326784Z",
     "iopub.status.idle": "2025-10-06T18:17:20.338848Z",
     "shell.execute_reply": "2025-10-06T18:17:20.337608Z"
    },
    "papermill": {
     "duration": 0.149086,
     "end_time": "2025-10-06T18:17:20.340588",
     "exception": false,
     "start_time": "2025-10-06T18:17:20.191502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ensemble_val_predictions(models, scalers, X_val_unscaled, val_ids, y_val_dx_fold, y_val_dy_fold, val_data, exclude_fold=None):\n",
    "    \"\"\"\n",
    "    Generate ensemble predictions for validation data and prepare for scoring.\n",
    "    Excludes the model from the same fold to prevent potential overfitting/leakage.\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained models\n",
    "        scalers: List of scalers (one per model)\n",
    "        X_val_unscaled: Validation sequences (unscaled)\n",
    "        val_ids: List of dicts with sequence metadata\n",
    "        y_val_dx_fold, y_val_dy_fold: Ground truth displacements\n",
    "        val_data: DataFrame with x_last, y_last\n",
    "        exclude_fold: Index of the fold to exclude (0-based)\n",
    "    \n",
    "    Returns:\n",
    "        ensemble_pred_df, ensemble_true_df: DataFrames for scoring\n",
    "    \"\"\"\n",
    "    pred_rows = []\n",
    "    true_rows = []\n",
    "    \n",
    "    for i, seq_info in enumerate(val_ids):\n",
    "        game_id = seq_info['game_id']\n",
    "        play_id = seq_info['play_id']\n",
    "        nfl_id = seq_info['nfl_id']\n",
    "        x_last = val_data.iloc[i]['x_last']\n",
    "        y_last = val_data.iloc[i]['y_last']\n",
    "        \n",
    "        # Ground truth\n",
    "        dx_true = y_val_dx_fold[i]\n",
    "        dy_true = y_val_dy_fold[i]\n",
    "        for t in range(len(dx_true)):\n",
    "            frame_rel = t + 1\n",
    "            true_x = x_last + dx_true[t]\n",
    "            true_y = y_last + dy_true[t]\n",
    "            true_rows.append({\n",
    "                'id': f\"{game_id}_{play_id}_{nfl_id}_{frame_rel}\",\n",
    "                'x': true_x,\n",
    "                'y': true_y\n",
    "            })\n",
    "        \n",
    "        # Ensemble predictions (exclude the model from the same fold)\n",
    "        per_model_dx = []\n",
    "        per_model_dy = []\n",
    "        for j, model in enumerate(models):\n",
    "            if exclude_fold is not None and j == exclude_fold:\n",
    "                continue  # Skip the model trained on this fold\n",
    "            scaler = scalers[j]\n",
    "            scaled_seq = scaler.transform(X_val_unscaled[i]).astype(np.float32)\n",
    "            scaled_seq = torch.tensor(scaled_seq).unsqueeze(0).to(next(model.parameters()).device)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(scaled_seq).cpu().numpy()[0]  # (max_frames_output, 2)\n",
    "            per_model_dx.append(output[:, 0])\n",
    "            per_model_dy.append(output[:, 1])\n",
    "        \n",
    "        # Average across remaining models\n",
    "        if per_model_dx:  # Ensure there are models to average\n",
    "            ens_dx = np.mean(per_model_dx, axis=0)\n",
    "            ens_dy = np.mean(per_model_dy, axis=0)\n",
    "        else:\n",
    "            # Fallback: use the last known position (though this shouldn't happen with n_folds > 1)\n",
    "            ens_dx = np.zeros(len(dx_true))\n",
    "            ens_dy = np.zeros(len(dy_true))\n",
    "        \n",
    "        # Generate predictions for each frame\n",
    "        for t in range(len(dx_true)):\n",
    "            pred_x = x_last + ens_dx[t]\n",
    "            pred_y = y_last + ens_dy[t]\n",
    "            pred_rows.append({\n",
    "                'id': f\"{game_id}_{play_id}_{nfl_id}_{t+1}\",\n",
    "                'x': np.clip(pred_x, Config.FIELD_X_MIN, Config.FIELD_X_MAX),\n",
    "                'y': np.clip(pred_y, Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(pred_rows), pd.DataFrame(true_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846e32c",
   "metadata": {
    "papermill": {
     "duration": 0.131868,
     "end_time": "2025-10-06T18:17:20.607223",
     "exception": false,
     "start_time": "2025-10-06T18:17:20.475355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5folds training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb8f603e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:20.879113Z",
     "iopub.status.busy": "2025-10-06T18:17:20.878797Z",
     "iopub.status.idle": "2025-10-06T18:17:20.895568Z",
     "shell.execute_reply": "2025-10-06T18:17:20.894424Z"
    },
    "papermill": {
     "duration": 0.15641,
     "end_time": "2025-10-06T18:17:20.897038",
     "exception": false,
     "start_time": "2025-10-06T18:17:20.740628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_multi_fold_training(sequences, targets_dx, targets_dy, targets_frame_ids, ids,\n",
    "                            lr=Config.LEARNING_RATE, n_folds=5, epochs=15, patience=5):\n",
    "    # Ensure numpy object arrays for advanced indexing\n",
    "    if not isinstance(sequences, np.ndarray):\n",
    "        sequences = np.array(sequences, dtype=object)\n",
    "    if not isinstance(targets_dx, np.ndarray):\n",
    "        targets_dx = np.array(targets_dx, dtype=object)\n",
    "    if not isinstance(targets_dy, np.ndarray):\n",
    "        targets_dy = np.array(targets_dy, dtype=object)\n",
    "    if not isinstance(targets_frame_ids, np.ndarray):\n",
    "        targets_frame_ids = np.array(targets_frame_ids, dtype=object)\n",
    "    groups = [d['play_id'] for d in ids]\n",
    "    gkf = GroupKFold(n_splits=n_folds)\n",
    "    folds = list(gkf.split(sequences, groups=groups))\n",
    "    input_dim = sequences[0].shape[-1]\n",
    "    print(f\"Input feature dimension: {input_dim}\")\n",
    "    models, scalers, fold_scores = [], [], []\n",
    "    # Store per-fold validation pieces for OOF\n",
    "    oof_pred_parts, oof_true_parts = [], []\n",
    "    for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "        print(f\"\\n--- Training Fold {fold+1}/{n_folds} ---\")\n",
    "        X_train_unscaled = sequences[train_idx]\n",
    "        X_val_unscaled = sequences[val_idx]\n",
    "        y_train_dx_fold = targets_dx[train_idx]\n",
    "        y_train_dy_fold = targets_dy[train_idx]\n",
    "        y_val_dx_fold = targets_dx[val_idx]\n",
    "        y_val_dy_fold = targets_dy[val_idx]\n",
    "        y_val_frame_ids_fold = targets_frame_ids[val_idx]\n",
    "        # Meta\n",
    "        val_ids = [ids[i] for i in val_idx]\n",
    "        val_data = pd.DataFrame(val_ids)\n",
    "        val_data['x_last'] = np.array([s[-1,0] for s in X_val_unscaled])\n",
    "        val_data['y_last'] = np.array([s[-1,1] for s in X_val_unscaled])\n",
    "        # Scaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(np.vstack(X_train_unscaled))\n",
    "        def apply_scaler(arr):\n",
    "            return np.array([scaler.transform(s) for s in arr], dtype=object)\n",
    "        X_train_fold = apply_scaler(X_train_unscaled)\n",
    "        X_val_fold = apply_scaler(X_val_unscaled)\n",
    "        model, best_loss, best_metric = train_improved_lstm_model(\n",
    "            X_train_fold, y_train_dx_fold, y_train_dy_fold,\n",
    "            X_val_fold, y_val_dx_fold, y_val_dy_fold,\n",
    "            val_data, input_dim=input_dim,\n",
    "            epochs=epochs, batch_size=Config.BATCH_SIZE, learning_rate=lr,\n",
    "            eval_all_frames=True, patience=patience\n",
    "        )\n",
    "        fold_scores.append(best_metric)\n",
    "        models.append(model); scalers.append(scaler)\n",
    "        # save scaler for this fold\n",
    "        # make directory if not exists\n",
    "        import os\n",
    "        if not os.path.exists(f'fold_{fold+1}'):\n",
    "            os.makedirs(f'fold_{fold+1}')\n",
    "        joblib.dump(scaler, f'fold_{fold+1}/lstm_feature_scaler_fold.joblib')\n",
    "        print(f\"Scaler for fold {fold+1} saved to 'fold_{fold+1}/lstm_feature_scaler_fold.joblib'\")\n",
    "        # Save model for this fold\n",
    "        torch.save({\n",
    "            'state_dict': model.state_dict(),\n",
    "            'config': {\n",
    "                'input_dim': input_dim,\n",
    "                'hidden_dim': Config.HIDDEN_DIM,\n",
    "                'num_layers': Config.NUM_LAYERS,\n",
    "                'dropout': Config.DROPOUT,\n",
    "                'max_frames_output': Config.MAX_FUTURE_HORIZON\n",
    "            }\n",
    "        }, f'fold_{fold+1}/lstm_model_fold.pt')\n",
    "        print(f\"Model for fold {fold+1} saved to 'fold_{fold+1}/lstm_model_fold.pt'\")\n",
    "        oof_pred_fold, oof_true_fold = create_oof_predictions(\n",
    "            model=model, scaler=scaler,\n",
    "            X_val_unscaled=X_val_unscaled,\n",
    "            val_ids=val_ids,\n",
    "            y_val_dx=y_val_dx_fold,\n",
    "            y_val_dy=y_val_dy_fold,\n",
    "            y_val_frame_ids=y_val_frame_ids_fold,\n",
    "            val_data=val_data\n",
    "        )\n",
    "        print('shape of oof_pred_fold:', oof_pred_fold.shape)\n",
    "        oof_pred_parts.append(oof_pred_fold)\n",
    "        oof_true_parts.append(oof_true_fold)\n",
    "    oof_pred_df = pd.concat(oof_pred_parts, ignore_index=True)\n",
    "    oof_true_df = pd.concat(oof_true_parts, ignore_index=True)\n",
    "    # Deduplicate if any (shouldn't but safe)\n",
    "    oof_pred_df = oof_pred_df.drop_duplicates('id')\n",
    "    oof_true_df = oof_true_df.drop_duplicates('id')\n",
    "    print(f\"OOF predictions example:\\n{oof_pred_df.head()}\")\n",
    "    print(f\"OOF truth example:\\n{oof_true_df.head()}\")\n",
    "    print(f\"\\nOOF predictions shape: {oof_pred_df.shape}, OOF truth shape: {oof_true_df.shape}\")\n",
    "    cv_score = score(oof_true_df, oof_pred_df, 'id')\n",
    "    print(\"\\n--- Multi-Fold Training Summary ---\")\n",
    "    for i, fs in enumerate(fold_scores):\n",
    "        print(f\"Fold {i+1}: {fs:.5f}\")\n",
    "    print(f\"Mean Single-Model Fold Score: {np.mean(fold_scores):.5f} ± {np.std(fold_scores):.5f}\")\n",
    "    print(f\"OOF CV Score: {cv_score:.5f}\")\n",
    "    return models, fold_scores, scalers, cv_score, oof_pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a2732b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:21.165011Z",
     "iopub.status.busy": "2025-10-06T18:17:21.164699Z",
     "iopub.status.idle": "2025-10-06T18:17:21.176398Z",
     "shell.execute_reply": "2025-10-06T18:17:21.175349Z"
    },
    "papermill": {
     "duration": 0.147926,
     "end_time": "2025-10-06T18:17:21.178213",
     "exception": false,
     "start_time": "2025-10-06T18:17:21.030287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_trained_models(num_models, input_dim=None, max_frames_output=None, models_dir=None,\n",
    "                        default_hidden=Config.HIDDEN_DIM, default_layers=Config.NUM_LAYERS, default_dropout=Config.DROPOUT):\n",
    "    \"\"\"\n",
    "    Robust loader: handles (a) new checkpoints with config dict, (b) old state_dict-only files.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    scalers = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    for fold in range(num_models):\n",
    "\n",
    "        model_path = f'fold_{fold+1}/lstm_model_fold.pt'\n",
    "        scaler_path = f'fold_{fold+1}/lstm_feature_scaler_fold.joblib'\n",
    "        if models_dir is not None:\n",
    "            model_path  = f\"{models_dir}/fold_{fold+1}/lstm_model_fold.pt\"\n",
    "            scaler_path = f\"{models_dir}/fold_{fold+1}/lstm_feature_scaler_fold.joblib\"\n",
    "        try:\n",
    "            ckpt = torch.load(model_path, map_location=device)\n",
    "            if isinstance(ckpt, dict) and 'state_dict' in ckpt:\n",
    "                print(f\"Loading fold {fold+1} from checkpoint with config...\")\n",
    "                state_dict = ckpt['state_dict']\n",
    "                cfg = ckpt.get('config', {})\n",
    "                _input_dim = cfg.get('input_dim', input_dim)\n",
    "                _hidden = cfg.get('hidden_dim', default_hidden)\n",
    "                _layers = cfg.get('num_layers', default_layers)\n",
    "                _dropout = cfg.get('dropout', default_dropout)\n",
    "                _max_out = cfg.get('max_frames_output', max_frames_output)\n",
    "            else:\n",
    "                # Old format: only state_dict\n",
    "                state_dict = ckpt\n",
    "                _input_dim = input_dim\n",
    "                _hidden = default_hidden\n",
    "                _layers = default_layers\n",
    "                _dropout = default_dropout\n",
    "                _max_out = max_frames_output\n",
    "            if _input_dim is None or _max_out is None:\n",
    "                print(f\"[Fold {fold+1}] Missing input_dim or max_frames_output; cannot load.\")\n",
    "                continue\n",
    "            model = CombinedLSTMGRURegressor(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=Config.HIDDEN_DIM,           # will be split across branches\n",
    "                num_layers=Config.NUM_LAYERS,\n",
    "                dropout=Config.DROPOUT,\n",
    "                max_frames_output=Config.MAX_FUTURE_HORIZON\n",
    "            )\n",
    "            model.load_state_dict(state_dict, strict=True)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            models.append(model)\n",
    "            print(f\"Loaded fold {fold+1} (hidden={_hidden}, layers={_layers}, max_out={_max_out})\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Checkpoint not found: {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {model_path}: {e}\")\n",
    "        # Load scaler\n",
    "        try:\n",
    "            scaler = joblib.load(scaler_path)\n",
    "            scalers.append(scaler)\n",
    "            print(f\"Loaded scaler for fold {fold+1}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Scaler not found: {scaler_path}\")\n",
    "            scalers.append(None)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading scaler {scaler_path}: {e}\")\n",
    "            scalers.append(None)\n",
    "    return models, scalers\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f42fa",
   "metadata": {
    "papermill": {
     "duration": 0.135425,
     "end_time": "2025-10-06T18:17:21.447250",
     "exception": false,
     "start_time": "2025-10-06T18:17:21.311825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c80fcda8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:21.787694Z",
     "iopub.status.busy": "2025-10-06T18:17:21.787402Z",
     "iopub.status.idle": "2025-10-06T18:17:22.268785Z",
     "shell.execute_reply": "2025-10-06T18:17:22.267735Z"
    },
    "papermill": {
     "duration": 0.688102,
     "end_time": "2025-10-06T18:17:22.270211",
     "exception": false,
     "start_time": "2025-10-06T18:17:21.582109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences with NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# Check NaN in sequences robustly\n",
    "nan_count = 0\n",
    "for i, seq in enumerate(sequences):\n",
    "    try:\n",
    "        arr = np.array(seq, dtype=np.float32)\n",
    "        if np.isnan(arr).any():\n",
    "            nan_mask = np.isnan(arr)\n",
    "            nan_features = np.where(nan_mask.any(axis=0))[0]\n",
    "            print(f\"WARNING: NaN values found in sequence index {i}, feature columns: {nan_features}\")\n",
    "            nan_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Could not check sequence {i}: {e}\")\n",
    "print(f\"Total sequences with NaN: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57d83e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T18:17:22.537238Z",
     "iopub.status.busy": "2025-10-06T18:17:22.536951Z",
     "iopub.status.idle": "2025-10-06T20:14:13.547202Z",
     "shell.execute_reply": "2025-10-06T20:14:13.544946Z"
    },
    "papermill": {
     "duration": 7011.147258,
     "end_time": "2025-10-06T20:14:13.549981",
     "exception": false,
     "start_time": "2025-10-06T18:17:22.402723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature dimension: 32\n",
      "\n",
      "--- Training Fold 1/5 ---\n",
      "Maximum output frames: 94\n",
      "Using device: cpu\n",
      "sucessfully moved model to device\n",
      "Epoch 1/200 - TrainLoss 7.6568 ValLoss 2.2547\n",
      "Val RMSE (all frames): 1.51143\n",
      " New best model found at epoch 1 with ValLoss 2.2547\n",
      "Epoch 2/200 - TrainLoss 2.6174 ValLoss 1.5405\n",
      "Val RMSE (all frames): 1.24967\n",
      " New best model found at epoch 2 with ValLoss 1.5405\n",
      "Epoch 3/200 - TrainLoss 2.0265 ValLoss 1.3255\n",
      "Val RMSE (all frames): 1.15942\n",
      " New best model found at epoch 3 with ValLoss 1.3255\n",
      "Epoch 4/200 - TrainLoss 1.7317 ValLoss 1.1490\n",
      "Val RMSE (all frames): 1.07930\n",
      " New best model found at epoch 4 with ValLoss 1.1490\n",
      "Epoch 5/200 - TrainLoss 1.5987 ValLoss 1.0723\n",
      "Val RMSE (all frames): 1.04299\n",
      " New best model found at epoch 5 with ValLoss 1.0723\n",
      "Epoch 6/200 - TrainLoss 1.4962 ValLoss 0.9951\n",
      "Val RMSE (all frames): 1.00455\n",
      " New best model found at epoch 6 with ValLoss 0.9951\n",
      "Epoch 7/200 - TrainLoss 1.4262 ValLoss 0.9988\n",
      "Val RMSE (all frames): 1.00624\n",
      "Epoch 8/200 - TrainLoss 1.3742 ValLoss 0.9701\n",
      "Val RMSE (all frames): 0.99151\n",
      " New best model found at epoch 8 with ValLoss 0.9701\n",
      "Epoch 9/200 - TrainLoss 1.3596 ValLoss 0.9918\n",
      "Val RMSE (all frames): 1.00227\n",
      "Epoch 10/200 - TrainLoss 1.2922 ValLoss 0.9313\n",
      "Val RMSE (all frames): 0.97176\n",
      " New best model found at epoch 10 with ValLoss 0.9313\n",
      "Epoch 11/200 - TrainLoss 1.2601 ValLoss 0.9145\n",
      "Val RMSE (all frames): 0.96274\n",
      " New best model found at epoch 11 with ValLoss 0.9145\n",
      "Epoch 12/200 - TrainLoss 1.2367 ValLoss 0.9510\n",
      "Val RMSE (all frames): 0.98207\n",
      "Epoch 13/200 - TrainLoss 1.2213 ValLoss 0.8989\n",
      "Val RMSE (all frames): 0.95409\n",
      " New best model found at epoch 13 with ValLoss 0.8989\n",
      "Epoch 14/200 - TrainLoss 1.2182 ValLoss 0.9169\n",
      "Val RMSE (all frames): 0.96420\n",
      "Epoch 15/200 - TrainLoss 1.1884 ValLoss 0.8820\n",
      "Val RMSE (all frames): 0.94548\n",
      " New best model found at epoch 15 with ValLoss 0.8820\n",
      "Epoch 16/200 - TrainLoss 1.1363 ValLoss 0.8667\n",
      "Val RMSE (all frames): 0.93707\n",
      " New best model found at epoch 16 with ValLoss 0.8667\n",
      "Epoch 17/200 - TrainLoss 1.1195 ValLoss 0.8632\n",
      "Val RMSE (all frames): 0.93529\n",
      " New best model found at epoch 17 with ValLoss 0.8632\n",
      "Epoch 18/200 - TrainLoss 1.1329 ValLoss 0.8640\n",
      "Val RMSE (all frames): 0.93527\n",
      "Epoch 19/200 - TrainLoss 1.1233 ValLoss 0.8518\n",
      "Val RMSE (all frames): 0.92931\n",
      " New best model found at epoch 19 with ValLoss 0.8518\n",
      "Epoch 20/200 - TrainLoss 1.0922 ValLoss 0.8340\n",
      "Val RMSE (all frames): 0.91978\n",
      " New best model found at epoch 20 with ValLoss 0.8340\n",
      "Epoch 21/200 - TrainLoss 1.0818 ValLoss 0.8389\n",
      "Val RMSE (all frames): 0.92220\n",
      "Epoch 22/200 - TrainLoss 1.0750 ValLoss 0.8258\n",
      "Val RMSE (all frames): 0.91511\n",
      " New best model found at epoch 22 with ValLoss 0.8258\n",
      "Epoch 23/200 - TrainLoss 1.0627 ValLoss 0.8045\n",
      "Val RMSE (all frames): 0.90312\n",
      " New best model found at epoch 23 with ValLoss 0.8045\n",
      "Epoch 24/200 - TrainLoss 1.0400 ValLoss 0.7828\n",
      "Val RMSE (all frames): 0.89116\n",
      " New best model found at epoch 24 with ValLoss 0.7828\n",
      "Epoch 25/200 - TrainLoss 1.0317 ValLoss 0.7789\n",
      "Val RMSE (all frames): 0.88825\n",
      " New best model found at epoch 25 with ValLoss 0.7789\n",
      "Epoch 26/200 - TrainLoss 1.0182 ValLoss 0.7790\n",
      "Val RMSE (all frames): 0.88855\n",
      "Epoch 27/200 - TrainLoss 1.0154 ValLoss 0.7720\n",
      "Val RMSE (all frames): 0.88471\n",
      " New best model found at epoch 27 with ValLoss 0.7720\n",
      "Epoch 28/200 - TrainLoss 1.0090 ValLoss 0.8005\n",
      "Val RMSE (all frames): 0.90122\n",
      "Epoch 29/200 - TrainLoss 0.9787 ValLoss 0.7635\n",
      "Val RMSE (all frames): 0.87984\n",
      " New best model found at epoch 29 with ValLoss 0.7635\n",
      "Epoch 30/200 - TrainLoss 0.9678 ValLoss 0.7770\n",
      "Val RMSE (all frames): 0.88799\n",
      "Epoch 31/200 - TrainLoss 0.9568 ValLoss 0.7755\n",
      "Val RMSE (all frames): 0.88659\n",
      "Epoch 32/200 - TrainLoss 0.9559 ValLoss 0.7636\n",
      "Val RMSE (all frames): 0.88004\n",
      "Epoch 33/200 - TrainLoss 0.9421 ValLoss 0.7289\n",
      "Val RMSE (all frames): 0.85955\n",
      " New best model found at epoch 33 with ValLoss 0.7289\n",
      "Epoch 34/200 - TrainLoss 0.9554 ValLoss 0.7855\n",
      "Val RMSE (all frames): 0.89224\n",
      "Epoch 35/200 - TrainLoss 0.9438 ValLoss 0.7244\n",
      "Val RMSE (all frames): 0.85735\n",
      " New best model found at epoch 35 with ValLoss 0.7244\n",
      "Epoch 36/200 - TrainLoss 0.9196 ValLoss 0.7476\n",
      "Val RMSE (all frames): 0.87123\n",
      "Epoch 37/200 - TrainLoss 0.9343 ValLoss 0.7535\n",
      "Val RMSE (all frames): 0.87473\n",
      "Epoch 38/200 - TrainLoss 0.9126 ValLoss 0.7419\n",
      "Val RMSE (all frames): 0.86756\n",
      "Epoch 39/200 - TrainLoss 0.9100 ValLoss 0.7140\n",
      "Val RMSE (all frames): 0.85112\n",
      " New best model found at epoch 39 with ValLoss 0.7140\n",
      "Epoch 40/200 - TrainLoss 0.8847 ValLoss 0.7172\n",
      "Val RMSE (all frames): 0.85250\n",
      "Epoch 41/200 - TrainLoss 0.8905 ValLoss 0.7494\n",
      "Val RMSE (all frames): 0.87170\n",
      "Epoch 42/200 - TrainLoss 0.8979 ValLoss 0.7121\n",
      "Val RMSE (all frames): 0.84942\n",
      " New best model found at epoch 42 with ValLoss 0.7121\n",
      "Epoch 43/200 - TrainLoss 0.9041 ValLoss 0.7224\n",
      "Val RMSE (all frames): 0.85541\n",
      "Epoch 44/200 - TrainLoss 0.8719 ValLoss 0.6846\n",
      "Val RMSE (all frames): 0.83312\n",
      " New best model found at epoch 44 with ValLoss 0.6846\n",
      "Epoch 45/200 - TrainLoss 0.8569 ValLoss 0.6792\n",
      "Val RMSE (all frames): 0.82964\n",
      " New best model found at epoch 45 with ValLoss 0.6792\n",
      "Epoch 46/200 - TrainLoss 0.8622 ValLoss 0.7008\n",
      "Val RMSE (all frames): 0.84262\n",
      "Epoch 47/200 - TrainLoss 0.8562 ValLoss 0.6807\n",
      "Val RMSE (all frames): 0.83058\n",
      "Epoch 48/200 - TrainLoss 0.8464 ValLoss 0.6844\n",
      "Val RMSE (all frames): 0.83293\n",
      "Epoch 49/200 - TrainLoss 0.8495 ValLoss 0.6923\n",
      "Val RMSE (all frames): 0.83836\n",
      "Epoch 50/200 - TrainLoss 0.8529 ValLoss 0.6925\n",
      "Val RMSE (all frames): 0.83807\n",
      "Epoch 51/200 - TrainLoss 0.8458 ValLoss 0.6938\n",
      "Val RMSE (all frames): 0.83873\n",
      "Epoch 52/200 - TrainLoss 0.8115 ValLoss 0.6521\n",
      "Val RMSE (all frames): 0.81297\n",
      " New best model found at epoch 52 with ValLoss 0.6521\n",
      "Epoch 53/200 - TrainLoss 0.7952 ValLoss 0.6523\n",
      "Val RMSE (all frames): 0.81290\n",
      "Epoch 54/200 - TrainLoss 0.7789 ValLoss 0.6596\n",
      "Val RMSE (all frames): 0.81770\n",
      "Epoch 55/200 - TrainLoss 0.7804 ValLoss 0.6470\n",
      "Val RMSE (all frames): 0.80987\n",
      " New best model found at epoch 55 with ValLoss 0.6470\n",
      "Epoch 56/200 - TrainLoss 0.7776 ValLoss 0.6613\n",
      "Val RMSE (all frames): 0.81931\n",
      "Epoch 57/200 - TrainLoss 0.7822 ValLoss 0.6397\n",
      "Val RMSE (all frames): 0.80533\n",
      " New best model found at epoch 57 with ValLoss 0.6397\n",
      "Epoch 58/200 - TrainLoss 0.7688 ValLoss 0.6397\n",
      "Val RMSE (all frames): 0.80568\n",
      " New best model found at epoch 58 with ValLoss 0.6397\n",
      "Epoch 59/200 - TrainLoss 0.7654 ValLoss 0.6556\n",
      "Val RMSE (all frames): 0.81584\n",
      "Epoch 60/200 - TrainLoss 0.7624 ValLoss 0.6548\n",
      "Val RMSE (all frames): 0.81531\n",
      "Epoch 61/200 - TrainLoss 0.7665 ValLoss 0.6323\n",
      "Val RMSE (all frames): 0.80065\n",
      " New best model found at epoch 61 with ValLoss 0.6323\n",
      "Epoch 62/200 - TrainLoss 0.7629 ValLoss 0.6409\n",
      "Val RMSE (all frames): 0.80580\n",
      "Epoch 63/200 - TrainLoss 0.7490 ValLoss 0.6397\n",
      "Val RMSE (all frames): 0.80558\n",
      "Epoch 64/200 - TrainLoss 0.7492 ValLoss 0.6326\n",
      "Val RMSE (all frames): 0.80118\n",
      "Epoch 65/200 - TrainLoss 0.7469 ValLoss 0.6292\n",
      "Val RMSE (all frames): 0.79917\n",
      " New best model found at epoch 65 with ValLoss 0.6292\n",
      "Epoch 66/200 - TrainLoss 0.7399 ValLoss 0.6292\n",
      "Val RMSE (all frames): 0.79899\n",
      "Epoch 67/200 - TrainLoss 0.7446 ValLoss 0.6308\n",
      "Val RMSE (all frames): 0.80024\n",
      "Epoch 68/200 - TrainLoss 0.7364 ValLoss 0.6204\n",
      "Val RMSE (all frames): 0.79375\n",
      " New best model found at epoch 68 with ValLoss 0.6204\n",
      "Epoch 69/200 - TrainLoss 0.7522 ValLoss 0.6299\n",
      "Val RMSE (all frames): 0.79941\n",
      "Epoch 70/200 - TrainLoss 0.7302 ValLoss 0.6415\n",
      "Val RMSE (all frames): 0.80662\n",
      "Epoch 71/200 - TrainLoss 0.7392 ValLoss 0.6339\n",
      "Val RMSE (all frames): 0.80212\n",
      "Epoch 72/200 - TrainLoss 0.7419 ValLoss 0.6267\n",
      "Val RMSE (all frames): 0.79761\n",
      "Epoch 73/200 - TrainLoss 0.7286 ValLoss 0.6251\n",
      "Val RMSE (all frames): 0.79651\n",
      "Epoch 74/200 - TrainLoss 0.7141 ValLoss 0.6319\n",
      "Val RMSE (all frames): 0.80133\n",
      "Epoch 75/200 - TrainLoss 0.7165 ValLoss 0.6147\n",
      "Val RMSE (all frames): 0.78972\n",
      " New best model found at epoch 75 with ValLoss 0.6147\n",
      "Epoch 76/200 - TrainLoss 0.7070 ValLoss 0.6087\n",
      "Val RMSE (all frames): 0.78531\n",
      " New best model found at epoch 76 with ValLoss 0.6087\n",
      "Epoch 77/200 - TrainLoss 0.7032 ValLoss 0.6090\n",
      "Val RMSE (all frames): 0.78601\n",
      "Epoch 78/200 - TrainLoss 0.7090 ValLoss 0.6100\n",
      "Val RMSE (all frames): 0.78655\n",
      "Epoch 79/200 - TrainLoss 0.7066 ValLoss 0.6010\n",
      "Val RMSE (all frames): 0.78063\n",
      " New best model found at epoch 79 with ValLoss 0.6010\n",
      "Epoch 80/200 - TrainLoss 0.7081 ValLoss 0.6023\n",
      "Val RMSE (all frames): 0.78112\n",
      "Epoch 81/200 - TrainLoss 0.7024 ValLoss 0.6038\n",
      "Val RMSE (all frames): 0.78254\n",
      "Epoch 82/200 - TrainLoss 0.6920 ValLoss 0.5923\n",
      "Val RMSE (all frames): 0.77489\n",
      " New best model found at epoch 82 with ValLoss 0.5923\n",
      "Epoch 83/200 - TrainLoss 0.6884 ValLoss 0.6061\n",
      "Val RMSE (all frames): 0.78372\n",
      "Epoch 84/200 - TrainLoss 0.6911 ValLoss 0.5948\n",
      "Val RMSE (all frames): 0.77634\n",
      "Epoch 85/200 - TrainLoss 0.6951 ValLoss 0.6079\n",
      "Val RMSE (all frames): 0.78513\n",
      "Epoch 86/200 - TrainLoss 0.6931 ValLoss 0.6077\n",
      "Val RMSE (all frames): 0.78504\n",
      "Epoch 87/200 - TrainLoss 0.6899 ValLoss 0.6006\n",
      "Val RMSE (all frames): 0.78015\n",
      "Epoch 88/200 - TrainLoss 0.6906 ValLoss 0.5973\n",
      "Val RMSE (all frames): 0.77823\n",
      "Epoch 89/200 - TrainLoss 0.6781 ValLoss 0.5949\n",
      "Val RMSE (all frames): 0.77662\n",
      "Epoch 90/200 - TrainLoss 0.6639 ValLoss 0.5994\n",
      "Val RMSE (all frames): 0.77969\n",
      "Epoch 91/200 - TrainLoss 0.6666 ValLoss 0.5947\n",
      "Val RMSE (all frames): 0.77633\n",
      "Epoch 92/200 - TrainLoss 0.6728 ValLoss 0.5914\n",
      "Val RMSE (all frames): 0.77421\n",
      " New best model found at epoch 92 with ValLoss 0.5914\n",
      "Epoch 93/200 - TrainLoss 0.6858 ValLoss 0.5904\n",
      "Val RMSE (all frames): 0.77361\n",
      " New best model found at epoch 93 with ValLoss 0.5904\n",
      "Epoch 94/200 - TrainLoss 0.6733 ValLoss 0.5915\n",
      "Val RMSE (all frames): 0.77456\n",
      "Epoch 95/200 - TrainLoss 0.6760 ValLoss 0.5930\n",
      "Val RMSE (all frames): 0.77521\n",
      "Epoch 96/200 - TrainLoss 0.6647 ValLoss 0.5896\n",
      "Val RMSE (all frames): 0.77300\n",
      " New best model found at epoch 96 with ValLoss 0.5896\n",
      "Epoch 97/200 - TrainLoss 0.6615 ValLoss 0.5943\n",
      "Val RMSE (all frames): 0.77616\n",
      "Epoch 98/200 - TrainLoss 0.6770 ValLoss 0.5866\n",
      "Val RMSE (all frames): 0.77115\n",
      " New best model found at epoch 98 with ValLoss 0.5866\n",
      "Epoch 99/200 - TrainLoss 0.6725 ValLoss 0.5924\n",
      "Val RMSE (all frames): 0.77500\n",
      "Epoch 100/200 - TrainLoss 0.6724 ValLoss 0.5943\n",
      "Val RMSE (all frames): 0.77626\n",
      "Epoch 101/200 - TrainLoss 0.6779 ValLoss 0.5905\n",
      "Val RMSE (all frames): 0.77357\n",
      "Epoch 102/200 - TrainLoss 0.6614 ValLoss 0.5872\n",
      "Val RMSE (all frames): 0.77119\n",
      "Epoch 103/200 - TrainLoss 0.6624 ValLoss 0.5914\n",
      "Val RMSE (all frames): 0.77409\n",
      "Epoch 104/200 - TrainLoss 0.6760 ValLoss 0.5912\n",
      "Val RMSE (all frames): 0.77372\n",
      "Epoch 105/200 - TrainLoss 0.6563 ValLoss 0.5871\n",
      "Val RMSE (all frames): 0.77113\n",
      "Epoch 106/200 - TrainLoss 0.6566 ValLoss 0.5906\n",
      "Val RMSE (all frames): 0.77351\n",
      "Epoch 107/200 - TrainLoss 0.6596 ValLoss 0.5912\n",
      "Val RMSE (all frames): 0.77392\n",
      "Epoch 108/200 - TrainLoss 0.6536 ValLoss 0.5852\n",
      "Val RMSE (all frames): 0.77011\n",
      " New best model found at epoch 108 with ValLoss 0.5852\n",
      "Epoch 109/200 - TrainLoss 0.6600 ValLoss 0.5869\n",
      "Val RMSE (all frames): 0.77118\n",
      "Epoch 110/200 - TrainLoss 0.6635 ValLoss 0.5839\n",
      "Val RMSE (all frames): 0.76928\n",
      " New best model found at epoch 110 with ValLoss 0.5839\n",
      "Epoch 111/200 - TrainLoss 0.6447 ValLoss 0.5904\n",
      "Val RMSE (all frames): 0.77358\n",
      "Epoch 112/200 - TrainLoss 0.6584 ValLoss 0.5901\n",
      "Val RMSE (all frames): 0.77336\n",
      "Epoch 113/200 - TrainLoss 0.6546 ValLoss 0.5831\n",
      "Val RMSE (all frames): 0.76867\n",
      " New best model found at epoch 113 with ValLoss 0.5831\n",
      "Epoch 114/200 - TrainLoss 0.6561 ValLoss 0.5833\n",
      "Val RMSE (all frames): 0.76886\n",
      "Epoch 115/200 - TrainLoss 0.6497 ValLoss 0.5876\n",
      "Val RMSE (all frames): 0.77168\n",
      "Epoch 116/200 - TrainLoss 0.6510 ValLoss 0.5834\n",
      "Val RMSE (all frames): 0.76873\n",
      "Epoch 117/200 - TrainLoss 0.6434 ValLoss 0.5870\n",
      "Val RMSE (all frames): 0.77134\n",
      "Epoch 118/200 - TrainLoss 0.6512 ValLoss 0.5874\n",
      "Val RMSE (all frames): 0.77150\n",
      "Epoch 119/200 - TrainLoss 0.6544 ValLoss 0.5897\n",
      "Val RMSE (all frames): 0.77303\n",
      "Epoch 120/200 - TrainLoss 0.6524 ValLoss 0.5822\n",
      "Val RMSE (all frames): 0.76812\n",
      " New best model found at epoch 120 with ValLoss 0.5822\n",
      "Epoch 121/200 - TrainLoss 0.6540 ValLoss 0.5823\n",
      "Val RMSE (all frames): 0.76816\n",
      "Epoch 122/200 - TrainLoss 0.6488 ValLoss 0.5818\n",
      "Val RMSE (all frames): 0.76781\n",
      " New best model found at epoch 122 with ValLoss 0.5818\n",
      "Epoch 123/200 - TrainLoss 0.6607 ValLoss 0.5819\n",
      "Val RMSE (all frames): 0.76784\n",
      "Epoch 124/200 - TrainLoss 0.6468 ValLoss 0.5833\n",
      "Val RMSE (all frames): 0.76882\n",
      "Epoch 125/200 - TrainLoss 0.6468 ValLoss 0.5869\n",
      "Val RMSE (all frames): 0.77127\n",
      "Epoch 126/200 - TrainLoss 0.6414 ValLoss 0.5831\n",
      "Val RMSE (all frames): 0.76869\n",
      "Epoch 127/200 - TrainLoss 0.6459 ValLoss 0.5830\n",
      "Val RMSE (all frames): 0.76862\n",
      "Epoch 128/200 - TrainLoss 0.6494 ValLoss 0.5835\n",
      "Val RMSE (all frames): 0.76901\n",
      "Epoch 129/200 - TrainLoss 0.6471 ValLoss 0.5822\n",
      "Val RMSE (all frames): 0.76813\n",
      "Epoch 130/200 - TrainLoss 0.6388 ValLoss 0.5829\n",
      "Val RMSE (all frames): 0.76864\n",
      "Epoch 131/200 - TrainLoss 0.6445 ValLoss 0.5805\n",
      "Val RMSE (all frames): 0.76698\n",
      " New best model found at epoch 131 with ValLoss 0.5805\n",
      "Epoch 132/200 - TrainLoss 0.6428 ValLoss 0.5816\n",
      "Val RMSE (all frames): 0.76772\n",
      "Epoch 133/200 - TrainLoss 0.6457 ValLoss 0.5806\n",
      "Val RMSE (all frames): 0.76710\n",
      "Epoch 134/200 - TrainLoss 0.6435 ValLoss 0.5801\n",
      "Val RMSE (all frames): 0.76682\n",
      " New best model found at epoch 134 with ValLoss 0.5801\n",
      "Epoch 135/200 - TrainLoss 0.6440 ValLoss 0.5807\n",
      "Val RMSE (all frames): 0.76721\n",
      "Epoch 136/200 - TrainLoss 0.6461 ValLoss 0.5828\n",
      "Val RMSE (all frames): 0.76864\n",
      "Epoch 137/200 - TrainLoss 0.6430 ValLoss 0.5817\n",
      "Val RMSE (all frames): 0.76778\n",
      "Epoch 138/200 - TrainLoss 0.6499 ValLoss 0.5819\n",
      "Val RMSE (all frames): 0.76800\n",
      "Epoch 139/200 - TrainLoss 0.6503 ValLoss 0.5813\n",
      "Val RMSE (all frames): 0.76754\n",
      "Epoch 140/200 - TrainLoss 0.6434 ValLoss 0.5799\n",
      "Val RMSE (all frames): 0.76667\n",
      " New best model found at epoch 140 with ValLoss 0.5799\n",
      "Epoch 141/200 - TrainLoss 0.6354 ValLoss 0.5788\n",
      "Val RMSE (all frames): 0.76586\n",
      " New best model found at epoch 141 with ValLoss 0.5788\n",
      "Epoch 142/200 - TrainLoss 0.6409 ValLoss 0.5796\n",
      "Val RMSE (all frames): 0.76639\n",
      "Epoch 143/200 - TrainLoss 0.6438 ValLoss 0.5797\n",
      "Val RMSE (all frames): 0.76647\n",
      "Epoch 144/200 - TrainLoss 0.6435 ValLoss 0.5793\n",
      "Val RMSE (all frames): 0.76627\n",
      "Epoch 145/200 - TrainLoss 0.6424 ValLoss 0.5784\n",
      "Val RMSE (all frames): 0.76560\n",
      " New best model found at epoch 145 with ValLoss 0.5784\n",
      "Epoch 146/200 - TrainLoss 0.6430 ValLoss 0.5805\n",
      "Val RMSE (all frames): 0.76703\n",
      "Epoch 147/200 - TrainLoss 0.6506 ValLoss 0.5803\n",
      "Val RMSE (all frames): 0.76688\n",
      "Epoch 148/200 - TrainLoss 0.6425 ValLoss 0.5799\n",
      "Val RMSE (all frames): 0.76670\n",
      "Epoch 149/200 - TrainLoss 0.6474 ValLoss 0.5802\n",
      "Val RMSE (all frames): 0.76685\n",
      "Epoch 150/200 - TrainLoss 0.6428 ValLoss 0.5812\n",
      "Val RMSE (all frames): 0.76749\n",
      "Epoch 151/200 - TrainLoss 0.6438 ValLoss 0.5808\n",
      "Val RMSE (all frames): 0.76729\n",
      "Epoch 152/200 - TrainLoss 0.6369 ValLoss 0.5810\n",
      "Val RMSE (all frames): 0.76739\n",
      "Epoch 153/200 - TrainLoss 0.6293 ValLoss 0.5813\n",
      "Val RMSE (all frames): 0.76757\n",
      "Epoch 154/200 - TrainLoss 0.6364 ValLoss 0.5814\n",
      "Val RMSE (all frames): 0.76765\n",
      "Epoch 155/200 - TrainLoss 0.6372 ValLoss 0.5832\n",
      "Val RMSE (all frames): 0.76886\n",
      "Epoch 156/200 - TrainLoss 0.6422 ValLoss 0.5800\n",
      "Val RMSE (all frames): 0.76667\n",
      "Epoch 157/200 - TrainLoss 0.6428 ValLoss 0.5808\n",
      "Val RMSE (all frames): 0.76725\n",
      "Epoch 158/200 - TrainLoss 0.6414 ValLoss 0.5805\n",
      "Val RMSE (all frames): 0.76704\n",
      "Epoch 159/200 - TrainLoss 0.6491 ValLoss 0.5806\n",
      "Val RMSE (all frames): 0.76709\n",
      "Epoch 160/200 - TrainLoss 0.6365 ValLoss 0.5805\n",
      "Val RMSE (all frames): 0.76705\n",
      "Epoch 161/200 - TrainLoss 0.6403 ValLoss 0.5798\n",
      "Val RMSE (all frames): 0.76656\n",
      "Epoch 162/200 - TrainLoss 0.6419 ValLoss 0.5801\n",
      "Val RMSE (all frames): 0.76673\n",
      "Epoch 163/200 - TrainLoss 0.6348 ValLoss 0.5790\n",
      "Val RMSE (all frames): 0.76601\n",
      "Epoch 164/200 - TrainLoss 0.6364 ValLoss 0.5798\n",
      "Val RMSE (all frames): 0.76657\n",
      "Epoch 165/200 - TrainLoss 0.6349 ValLoss 0.5798\n",
      "Val RMSE (all frames): 0.76660\n",
      "Epoch 166/200 - TrainLoss 0.6381 ValLoss 0.5800\n",
      "Val RMSE (all frames): 0.76673\n",
      "Epoch 167/200 - TrainLoss 0.6375 ValLoss 0.5797\n",
      "Val RMSE (all frames): 0.76651\n",
      "Epoch 168/200 - TrainLoss 0.6445 ValLoss 0.5800\n",
      "Val RMSE (all frames): 0.76673\n",
      "Epoch 169/200 - TrainLoss 0.6469 ValLoss 0.5798\n",
      "Val RMSE (all frames): 0.76658\n",
      "Epoch 170/200 - TrainLoss 0.6486 ValLoss 0.5799\n",
      "Val RMSE (all frames): 0.76663\n",
      "Epoch 171/200 - TrainLoss 0.6446 ValLoss 0.5799\n",
      "Val RMSE (all frames): 0.76665\n",
      "Epoch 172/200 - TrainLoss 0.6352 ValLoss 0.5799\n",
      "Val RMSE (all frames): 0.76666\n",
      "Epoch 173/200 - TrainLoss 0.6393 ValLoss 0.5799\n",
      "Val RMSE (all frames): 0.76666\n",
      "Epoch 174/200 - TrainLoss 0.6463 ValLoss 0.5801\n",
      "Val RMSE (all frames): 0.76675\n",
      "Epoch 175/200 - TrainLoss 0.6472 ValLoss 0.5800\n",
      "Val RMSE (all frames): 0.76669\n",
      "Early stopping epoch 175\n",
      "Scaler for fold 1 saved to 'fold_1/lstm_feature_scaler_fold.joblib'\n",
      "Model for fold 1 saved to 'fold_1/lstm_model_fold.pt'\n",
      "shape of oof_pred_fold: (114109, 3)\n",
      "\n",
      "--- Training Fold 2/5 ---\n",
      "Maximum output frames: 94\n",
      "Using device: cpu\n",
      "sucessfully moved model to device\n",
      "Epoch 1/200 - TrainLoss 7.8391 ValLoss 2.0618\n",
      "Val RMSE (all frames): 1.44141\n",
      " New best model found at epoch 1 with ValLoss 2.0618\n",
      "Epoch 2/200 - TrainLoss 2.6038 ValLoss 1.3951\n",
      "Val RMSE (all frames): 1.18485\n",
      " New best model found at epoch 2 with ValLoss 1.3951\n",
      "Epoch 3/200 - TrainLoss 2.0198 ValLoss 1.0513\n",
      "Val RMSE (all frames): 1.02834\n",
      " New best model found at epoch 3 with ValLoss 1.0513\n",
      "Epoch 4/200 - TrainLoss 1.7627 ValLoss 0.9205\n",
      "Val RMSE (all frames): 0.96198\n",
      " New best model found at epoch 4 with ValLoss 0.9205\n",
      "Epoch 5/200 - TrainLoss 1.6155 ValLoss 0.8858\n",
      "Val RMSE (all frames): 0.94396\n",
      " New best model found at epoch 5 with ValLoss 0.8858\n",
      "Epoch 6/200 - TrainLoss 1.5582 ValLoss 0.8357\n",
      "Val RMSE (all frames): 0.91707\n",
      " New best model found at epoch 6 with ValLoss 0.8357\n",
      "Epoch 7/200 - TrainLoss 1.4410 ValLoss 0.8146\n",
      "Val RMSE (all frames): 0.90544\n",
      " New best model found at epoch 7 with ValLoss 0.8146\n",
      "Epoch 8/200 - TrainLoss 1.3846 ValLoss 0.8398\n",
      "Val RMSE (all frames): 0.91954\n",
      "Epoch 9/200 - TrainLoss 1.3548 ValLoss 0.7661\n",
      "Val RMSE (all frames): 0.87800\n",
      " New best model found at epoch 9 with ValLoss 0.7661\n",
      "Epoch 10/200 - TrainLoss 1.3259 ValLoss 0.7891\n",
      "Val RMSE (all frames): 0.89142\n",
      "Epoch 11/200 - TrainLoss 1.2778 ValLoss 0.7253\n",
      "Val RMSE (all frames): 0.85453\n",
      " New best model found at epoch 11 with ValLoss 0.7253\n",
      "Epoch 12/200 - TrainLoss 1.2445 ValLoss 0.7337\n",
      "Val RMSE (all frames): 0.85940\n",
      "Epoch 13/200 - TrainLoss 1.2495 ValLoss 0.7111\n",
      "Val RMSE (all frames): 0.84610\n",
      " New best model found at epoch 13 with ValLoss 0.7111\n",
      "Epoch 14/200 - TrainLoss 1.2088 ValLoss 0.6960\n",
      "Val RMSE (all frames): 0.83712\n",
      " New best model found at epoch 14 with ValLoss 0.6960\n",
      "Epoch 15/200 - TrainLoss 1.1910 ValLoss 0.7098\n",
      "Val RMSE (all frames): 0.84560\n",
      "Epoch 16/200 - TrainLoss 1.1747 ValLoss 0.7068\n",
      "Val RMSE (all frames): 0.84365\n",
      "Epoch 17/200 - TrainLoss 1.1667 ValLoss 0.7313\n",
      "Val RMSE (all frames): 0.85843\n",
      "Epoch 18/200 - TrainLoss 1.1406 ValLoss 0.7088\n",
      "Val RMSE (all frames): 0.84513\n",
      "Epoch 19/200 - TrainLoss 1.1457 ValLoss 0.7115\n",
      "Val RMSE (all frames): 0.84689\n",
      "Epoch 20/200 - TrainLoss 1.1116 ValLoss 0.6857\n",
      "Val RMSE (all frames): 0.83114\n",
      " New best model found at epoch 20 with ValLoss 0.6857\n",
      "Epoch 21/200 - TrainLoss 1.0914 ValLoss 0.6863\n",
      "Val RMSE (all frames): 0.83170\n",
      "Epoch 22/200 - TrainLoss 1.0924 ValLoss 0.6445\n",
      "Val RMSE (all frames): 0.80574\n",
      " New best model found at epoch 22 with ValLoss 0.6445\n",
      "Epoch 23/200 - TrainLoss 1.0797 ValLoss 0.6567\n",
      "Val RMSE (all frames): 0.81341\n",
      "Epoch 24/200 - TrainLoss 1.0784 ValLoss 0.6573\n",
      "Val RMSE (all frames): 0.81408\n",
      "Epoch 25/200 - TrainLoss 1.0602 ValLoss 0.6282\n",
      "Val RMSE (all frames): 0.79571\n",
      " New best model found at epoch 25 with ValLoss 0.6282\n",
      "Epoch 26/200 - TrainLoss 1.0351 ValLoss 0.6538\n",
      "Val RMSE (all frames): 0.81193\n",
      "Epoch 27/200 - TrainLoss 1.0272 ValLoss 0.6466\n",
      "Val RMSE (all frames): 0.80755\n",
      "Epoch 28/200 - TrainLoss 1.0254 ValLoss 0.6256\n",
      "Val RMSE (all frames): 0.79451\n",
      " New best model found at epoch 28 with ValLoss 0.6256\n",
      "Epoch 29/200 - TrainLoss 1.0163 ValLoss 0.6196\n",
      "Val RMSE (all frames): 0.79064\n",
      " New best model found at epoch 29 with ValLoss 0.6196\n",
      "Epoch 30/200 - TrainLoss 1.0104 ValLoss 0.6184\n",
      "Val RMSE (all frames): 0.78968\n",
      " New best model found at epoch 30 with ValLoss 0.6184\n",
      "Epoch 31/200 - TrainLoss 0.9968 ValLoss 0.6151\n",
      "Val RMSE (all frames): 0.78760\n",
      " New best model found at epoch 31 with ValLoss 0.6151\n",
      "Epoch 32/200 - TrainLoss 0.9918 ValLoss 0.6134\n",
      "Val RMSE (all frames): 0.78627\n",
      " New best model found at epoch 32 with ValLoss 0.6134\n",
      "Epoch 33/200 - TrainLoss 0.9861 ValLoss 0.6261\n",
      "Val RMSE (all frames): 0.79482\n",
      "Epoch 34/200 - TrainLoss 0.9898 ValLoss 0.6255\n",
      "Val RMSE (all frames): 0.79441\n",
      "Epoch 35/200 - TrainLoss 0.9652 ValLoss 0.6237\n",
      "Val RMSE (all frames): 0.79382\n",
      "Epoch 36/200 - TrainLoss 0.9484 ValLoss 0.6317\n",
      "Val RMSE (all frames): 0.79847\n",
      "Epoch 37/200 - TrainLoss 0.9530 ValLoss 0.6066\n",
      "Val RMSE (all frames): 0.78253\n",
      " New best model found at epoch 37 with ValLoss 0.6066\n",
      "Epoch 38/200 - TrainLoss 0.9342 ValLoss 0.5928\n",
      "Val RMSE (all frames): 0.77330\n",
      " New best model found at epoch 38 with ValLoss 0.5928\n",
      "Epoch 39/200 - TrainLoss 0.9259 ValLoss 0.5894\n",
      "Val RMSE (all frames): 0.77135\n",
      " New best model found at epoch 39 with ValLoss 0.5894\n",
      "Epoch 40/200 - TrainLoss 0.9281 ValLoss 0.5861\n",
      "Val RMSE (all frames): 0.76917\n",
      " New best model found at epoch 40 with ValLoss 0.5861\n",
      "Epoch 41/200 - TrainLoss 0.9223 ValLoss 0.5701\n",
      "Val RMSE (all frames): 0.75844\n",
      " New best model found at epoch 41 with ValLoss 0.5701\n",
      "Epoch 42/200 - TrainLoss 0.9110 ValLoss 0.5637\n",
      "Val RMSE (all frames): 0.75427\n",
      " New best model found at epoch 42 with ValLoss 0.5637\n",
      "Epoch 43/200 - TrainLoss 0.9027 ValLoss 0.5742\n",
      "Val RMSE (all frames): 0.76122\n",
      "Epoch 44/200 - TrainLoss 0.8908 ValLoss 0.5864\n",
      "Val RMSE (all frames): 0.76920\n",
      "Epoch 45/200 - TrainLoss 0.8839 ValLoss 0.5585\n",
      "Val RMSE (all frames): 0.75102\n",
      " New best model found at epoch 45 with ValLoss 0.5585\n",
      "Epoch 46/200 - TrainLoss 0.8716 ValLoss 0.5635\n",
      "Val RMSE (all frames): 0.75429\n",
      "Epoch 47/200 - TrainLoss 0.8713 ValLoss 0.5402\n",
      "Val RMSE (all frames): 0.73819\n",
      " New best model found at epoch 47 with ValLoss 0.5402\n",
      "Epoch 48/200 - TrainLoss 0.8545 ValLoss 0.5507\n",
      "Val RMSE (all frames): 0.74584\n",
      "Epoch 49/200 - TrainLoss 0.8512 ValLoss 0.5650\n",
      "Val RMSE (all frames): 0.75530\n",
      "Epoch 50/200 - TrainLoss 0.8656 ValLoss 0.5633\n",
      "Val RMSE (all frames): 0.75413\n",
      "Epoch 51/200 - TrainLoss 0.8488 ValLoss 0.5456\n",
      "Val RMSE (all frames): 0.74205\n",
      "Epoch 52/200 - TrainLoss 0.8418 ValLoss 0.5856\n",
      "Val RMSE (all frames): 0.76855\n",
      "Epoch 53/200 - TrainLoss 0.8520 ValLoss 0.5274\n",
      "Val RMSE (all frames): 0.72972\n",
      " New best model found at epoch 53 with ValLoss 0.5274\n",
      "Epoch 54/200 - TrainLoss 0.8473 ValLoss 0.5407\n",
      "Val RMSE (all frames): 0.73840\n",
      "Epoch 55/200 - TrainLoss 0.8302 ValLoss 0.5516\n",
      "Val RMSE (all frames): 0.74622\n",
      "Epoch 56/200 - TrainLoss 0.8276 ValLoss 0.5494\n",
      "Val RMSE (all frames): 0.74500\n",
      "Epoch 57/200 - TrainLoss 0.8205 ValLoss 0.5543\n",
      "Val RMSE (all frames): 0.74825\n",
      "Epoch 58/200 - TrainLoss 0.8215 ValLoss 0.5384\n",
      "Val RMSE (all frames): 0.73716\n",
      "Epoch 59/200 - TrainLoss 0.8168 ValLoss 0.5555\n",
      "Val RMSE (all frames): 0.74891\n",
      "Epoch 60/200 - TrainLoss 0.7987 ValLoss 0.5064\n",
      "Val RMSE (all frames): 0.71465\n",
      " New best model found at epoch 60 with ValLoss 0.5064\n",
      "Epoch 61/200 - TrainLoss 0.7684 ValLoss 0.4945\n",
      "Val RMSE (all frames): 0.70637\n",
      " New best model found at epoch 61 with ValLoss 0.4945\n",
      "Epoch 62/200 - TrainLoss 0.7570 ValLoss 0.5145\n",
      "Val RMSE (all frames): 0.72062\n",
      "Epoch 63/200 - TrainLoss 0.7521 ValLoss 0.5075\n",
      "Val RMSE (all frames): 0.71558\n",
      "Epoch 64/200 - TrainLoss 0.7572 ValLoss 0.5076\n",
      "Val RMSE (all frames): 0.71556\n",
      "Epoch 65/200 - TrainLoss 0.7443 ValLoss 0.5033\n",
      "Val RMSE (all frames): 0.71240\n",
      "Epoch 66/200 - TrainLoss 0.7496 ValLoss 0.4920\n",
      "Val RMSE (all frames): 0.70462\n",
      " New best model found at epoch 66 with ValLoss 0.4920\n",
      "Epoch 67/200 - TrainLoss 0.7513 ValLoss 0.4963\n",
      "Val RMSE (all frames): 0.70772\n",
      "Epoch 68/200 - TrainLoss 0.7393 ValLoss 0.5028\n",
      "Val RMSE (all frames): 0.71220\n",
      "Epoch 69/200 - TrainLoss 0.7392 ValLoss 0.5003\n",
      "Val RMSE (all frames): 0.71057\n",
      "Epoch 70/200 - TrainLoss 0.7402 ValLoss 0.5114\n",
      "Val RMSE (all frames): 0.71829\n",
      "Epoch 71/200 - TrainLoss 0.7413 ValLoss 0.4934\n",
      "Val RMSE (all frames): 0.70563\n",
      "Epoch 72/200 - TrainLoss 0.7254 ValLoss 0.5057\n",
      "Val RMSE (all frames): 0.71447\n",
      "Epoch 73/200 - TrainLoss 0.7125 ValLoss 0.4857\n",
      "Val RMSE (all frames): 0.70030\n",
      " New best model found at epoch 73 with ValLoss 0.4857\n",
      "Epoch 74/200 - TrainLoss 0.7009 ValLoss 0.4756\n",
      "Val RMSE (all frames): 0.69271\n",
      " New best model found at epoch 74 with ValLoss 0.4756\n",
      "Epoch 75/200 - TrainLoss 0.7141 ValLoss 0.4851\n",
      "Val RMSE (all frames): 0.69971\n",
      "Epoch 76/200 - TrainLoss 0.6935 ValLoss 0.4838\n",
      "Val RMSE (all frames): 0.69876\n",
      "Epoch 77/200 - TrainLoss 0.7077 ValLoss 0.4809\n",
      "Val RMSE (all frames): 0.69664\n",
      "Epoch 78/200 - TrainLoss 0.6952 ValLoss 0.4896\n",
      "Val RMSE (all frames): 0.70299\n",
      "Epoch 79/200 - TrainLoss 0.7037 ValLoss 0.4832\n",
      "Val RMSE (all frames): 0.69815\n",
      "Epoch 80/200 - TrainLoss 0.7071 ValLoss 0.4831\n",
      "Val RMSE (all frames): 0.69842\n",
      "Epoch 81/200 - TrainLoss 0.6851 ValLoss 0.4738\n",
      "Val RMSE (all frames): 0.69150\n",
      " New best model found at epoch 81 with ValLoss 0.4738\n",
      "Epoch 82/200 - TrainLoss 0.6872 ValLoss 0.4740\n",
      "Val RMSE (all frames): 0.69162\n",
      "Epoch 83/200 - TrainLoss 0.6929 ValLoss 0.4727\n",
      "Val RMSE (all frames): 0.69065\n",
      " New best model found at epoch 83 with ValLoss 0.4727\n",
      "Epoch 84/200 - TrainLoss 0.6907 ValLoss 0.4707\n",
      "Val RMSE (all frames): 0.68917\n",
      " New best model found at epoch 84 with ValLoss 0.4707\n",
      "Epoch 85/200 - TrainLoss 0.6807 ValLoss 0.4786\n",
      "Val RMSE (all frames): 0.69509\n",
      "Epoch 86/200 - TrainLoss 0.6840 ValLoss 0.4737\n",
      "Val RMSE (all frames): 0.69124\n",
      "Epoch 87/200 - TrainLoss 0.6737 ValLoss 0.4688\n",
      "Val RMSE (all frames): 0.68770\n",
      " New best model found at epoch 87 with ValLoss 0.4688\n",
      "Epoch 88/200 - TrainLoss 0.6876 ValLoss 0.4700\n",
      "Val RMSE (all frames): 0.68865\n",
      "Epoch 89/200 - TrainLoss 0.6849 ValLoss 0.4812\n",
      "Val RMSE (all frames): 0.69689\n",
      "Epoch 90/200 - TrainLoss 0.6789 ValLoss 0.4729\n",
      "Val RMSE (all frames): 0.69079\n",
      "Epoch 91/200 - TrainLoss 0.6743 ValLoss 0.4748\n",
      "Val RMSE (all frames): 0.69209\n",
      "Epoch 92/200 - TrainLoss 0.6752 ValLoss 0.4788\n",
      "Val RMSE (all frames): 0.69502\n",
      "Epoch 93/200 - TrainLoss 0.6793 ValLoss 0.4684\n",
      "Val RMSE (all frames): 0.68757\n",
      " New best model found at epoch 93 with ValLoss 0.4684\n",
      "Epoch 94/200 - TrainLoss 0.6790 ValLoss 0.4713\n",
      "Val RMSE (all frames): 0.68979\n",
      "Epoch 95/200 - TrainLoss 0.6780 ValLoss 0.4711\n",
      "Val RMSE (all frames): 0.68958\n",
      "Epoch 96/200 - TrainLoss 0.6804 ValLoss 0.4765\n",
      "Val RMSE (all frames): 0.69344\n",
      "Epoch 97/200 - TrainLoss 0.6809 ValLoss 0.4733\n",
      "Val RMSE (all frames): 0.69117\n",
      "Epoch 98/200 - TrainLoss 0.6834 ValLoss 0.4765\n",
      "Val RMSE (all frames): 0.69340\n",
      "Epoch 99/200 - TrainLoss 0.6692 ValLoss 0.4699\n",
      "Val RMSE (all frames): 0.68850\n",
      "Epoch 100/200 - TrainLoss 0.6777 ValLoss 0.4699\n",
      "Val RMSE (all frames): 0.68850\n",
      "Epoch 101/200 - TrainLoss 0.6595 ValLoss 0.4719\n",
      "Val RMSE (all frames): 0.69001\n",
      "Epoch 102/200 - TrainLoss 0.6776 ValLoss 0.4711\n",
      "Val RMSE (all frames): 0.68942\n",
      "Epoch 103/200 - TrainLoss 0.6700 ValLoss 0.4716\n",
      "Val RMSE (all frames): 0.68978\n",
      "Epoch 104/200 - TrainLoss 0.6668 ValLoss 0.4676\n",
      "Val RMSE (all frames): 0.68684\n",
      " New best model found at epoch 104 with ValLoss 0.4676\n",
      "Epoch 105/200 - TrainLoss 0.6600 ValLoss 0.4710\n",
      "Val RMSE (all frames): 0.68939\n",
      "Epoch 106/200 - TrainLoss 0.6568 ValLoss 0.4750\n",
      "Val RMSE (all frames): 0.69230\n",
      "Epoch 107/200 - TrainLoss 0.6696 ValLoss 0.4695\n",
      "Val RMSE (all frames): 0.68835\n",
      "Epoch 108/200 - TrainLoss 0.6583 ValLoss 0.4708\n",
      "Val RMSE (all frames): 0.68929\n",
      "Epoch 109/200 - TrainLoss 0.6645 ValLoss 0.4731\n",
      "Val RMSE (all frames): 0.69099\n",
      "Epoch 110/200 - TrainLoss 0.6703 ValLoss 0.4669\n",
      "Val RMSE (all frames): 0.68630\n",
      " New best model found at epoch 110 with ValLoss 0.4669\n",
      "Epoch 111/200 - TrainLoss 0.6596 ValLoss 0.4672\n",
      "Val RMSE (all frames): 0.68651\n",
      "Epoch 112/200 - TrainLoss 0.6631 ValLoss 0.4681\n",
      "Val RMSE (all frames): 0.68728\n",
      "Epoch 113/200 - TrainLoss 0.6577 ValLoss 0.4678\n",
      "Val RMSE (all frames): 0.68705\n",
      "Epoch 114/200 - TrainLoss 0.6626 ValLoss 0.4671\n",
      "Val RMSE (all frames): 0.68654\n",
      "Epoch 115/200 - TrainLoss 0.6716 ValLoss 0.4668\n",
      "Val RMSE (all frames): 0.68626\n",
      " New best model found at epoch 115 with ValLoss 0.4668\n",
      "Epoch 116/200 - TrainLoss 0.6608 ValLoss 0.4694\n",
      "Val RMSE (all frames): 0.68828\n",
      "Epoch 117/200 - TrainLoss 0.6680 ValLoss 0.4671\n",
      "Val RMSE (all frames): 0.68653\n",
      "Epoch 118/200 - TrainLoss 0.6613 ValLoss 0.4686\n",
      "Val RMSE (all frames): 0.68769\n",
      "Epoch 119/200 - TrainLoss 0.6609 ValLoss 0.4681\n",
      "Val RMSE (all frames): 0.68725\n",
      "Epoch 120/200 - TrainLoss 0.6738 ValLoss 0.4642\n",
      "Val RMSE (all frames): 0.68442\n",
      " New best model found at epoch 120 with ValLoss 0.4642\n",
      "Epoch 121/200 - TrainLoss 0.6613 ValLoss 0.4657\n",
      "Val RMSE (all frames): 0.68555\n",
      "Epoch 122/200 - TrainLoss 0.6676 ValLoss 0.4666\n",
      "Val RMSE (all frames): 0.68615\n",
      "Epoch 123/200 - TrainLoss 0.6503 ValLoss 0.4683\n",
      "Val RMSE (all frames): 0.68741\n",
      "Epoch 124/200 - TrainLoss 0.6550 ValLoss 0.4691\n",
      "Val RMSE (all frames): 0.68806\n",
      "Epoch 125/200 - TrainLoss 0.6617 ValLoss 0.4690\n",
      "Val RMSE (all frames): 0.68795\n",
      "Epoch 126/200 - TrainLoss 0.6457 ValLoss 0.4676\n",
      "Val RMSE (all frames): 0.68698\n",
      "Epoch 127/200 - TrainLoss 0.6610 ValLoss 0.4689\n",
      "Val RMSE (all frames): 0.68790\n",
      "Epoch 128/200 - TrainLoss 0.6561 ValLoss 0.4677\n",
      "Val RMSE (all frames): 0.68700\n",
      "Epoch 129/200 - TrainLoss 0.6549 ValLoss 0.4689\n",
      "Val RMSE (all frames): 0.68785\n",
      "Epoch 130/200 - TrainLoss 0.6574 ValLoss 0.4689\n",
      "Val RMSE (all frames): 0.68783\n",
      "Epoch 131/200 - TrainLoss 0.6620 ValLoss 0.4682\n",
      "Val RMSE (all frames): 0.68734\n",
      "Epoch 132/200 - TrainLoss 0.6602 ValLoss 0.4670\n",
      "Val RMSE (all frames): 0.68645\n",
      "Epoch 133/200 - TrainLoss 0.6704 ValLoss 0.4679\n",
      "Val RMSE (all frames): 0.68710\n",
      "Epoch 134/200 - TrainLoss 0.6595 ValLoss 0.4684\n",
      "Val RMSE (all frames): 0.68747\n",
      "Epoch 135/200 - TrainLoss 0.6624 ValLoss 0.4672\n",
      "Val RMSE (all frames): 0.68664\n",
      "Epoch 136/200 - TrainLoss 0.6716 ValLoss 0.4684\n",
      "Val RMSE (all frames): 0.68747\n",
      "Epoch 137/200 - TrainLoss 0.6493 ValLoss 0.4681\n",
      "Val RMSE (all frames): 0.68722\n",
      "Epoch 138/200 - TrainLoss 0.6724 ValLoss 0.4678\n",
      "Val RMSE (all frames): 0.68700\n",
      "Epoch 139/200 - TrainLoss 0.6664 ValLoss 0.4681\n",
      "Val RMSE (all frames): 0.68727\n",
      "Epoch 140/200 - TrainLoss 0.6446 ValLoss 0.4683\n",
      "Val RMSE (all frames): 0.68741\n",
      "Epoch 141/200 - TrainLoss 0.6522 ValLoss 0.4674\n",
      "Val RMSE (all frames): 0.68673\n",
      "Epoch 142/200 - TrainLoss 0.6527 ValLoss 0.4676\n",
      "Val RMSE (all frames): 0.68689\n",
      "Epoch 143/200 - TrainLoss 0.6698 ValLoss 0.4679\n",
      "Val RMSE (all frames): 0.68710\n",
      "Epoch 144/200 - TrainLoss 0.6606 ValLoss 0.4678\n",
      "Val RMSE (all frames): 0.68701\n",
      "Epoch 145/200 - TrainLoss 0.6595 ValLoss 0.4676\n",
      "Val RMSE (all frames): 0.68687\n",
      "Epoch 146/200 - TrainLoss 0.6515 ValLoss 0.4679\n",
      "Val RMSE (all frames): 0.68710\n",
      "Epoch 147/200 - TrainLoss 0.6499 ValLoss 0.4680\n",
      "Val RMSE (all frames): 0.68715\n",
      "Epoch 148/200 - TrainLoss 0.6611 ValLoss 0.4685\n",
      "Val RMSE (all frames): 0.68749\n",
      "Epoch 149/200 - TrainLoss 0.6623 ValLoss 0.4685\n",
      "Val RMSE (all frames): 0.68751\n",
      "Epoch 150/200 - TrainLoss 0.6547 ValLoss 0.4684\n",
      "Val RMSE (all frames): 0.68747\n",
      "Early stopping epoch 150\n",
      "Scaler for fold 2 saved to 'fold_2/lstm_feature_scaler_fold.joblib'\n",
      "Model for fold 2 saved to 'fold_2/lstm_model_fold.pt'\n",
      "shape of oof_pred_fold: (111606, 3)\n",
      "\n",
      "--- Training Fold 3/5 ---\n",
      "Maximum output frames: 94\n",
      "Using device: cpu\n",
      "sucessfully moved model to device\n",
      "Epoch 1/200 - TrainLoss 7.5612 ValLoss 1.9980\n",
      "Val RMSE (all frames): 1.41890\n",
      " New best model found at epoch 1 with ValLoss 1.9980\n",
      "Epoch 2/200 - TrainLoss 2.5566 ValLoss 1.3679\n",
      "Val RMSE (all frames): 1.17394\n",
      " New best model found at epoch 2 with ValLoss 1.3679\n",
      "Epoch 3/200 - TrainLoss 1.9575 ValLoss 1.0573\n",
      "Val RMSE (all frames): 1.03204\n",
      " New best model found at epoch 3 with ValLoss 1.0573\n",
      "Epoch 4/200 - TrainLoss 1.7010 ValLoss 0.9902\n",
      "Val RMSE (all frames): 0.99883\n",
      " New best model found at epoch 4 with ValLoss 0.9902\n",
      "Epoch 5/200 - TrainLoss 1.5608 ValLoss 0.9129\n",
      "Val RMSE (all frames): 0.95901\n",
      " New best model found at epoch 5 with ValLoss 0.9129\n",
      "Epoch 6/200 - TrainLoss 1.4890 ValLoss 0.9154\n",
      "Val RMSE (all frames): 0.96068\n",
      "Epoch 7/200 - TrainLoss 1.4364 ValLoss 0.9124\n",
      "Val RMSE (all frames): 0.95973\n",
      " New best model found at epoch 7 with ValLoss 0.9124\n",
      "Epoch 8/200 - TrainLoss 1.3793 ValLoss 0.8351\n",
      "Val RMSE (all frames): 0.91820\n",
      " New best model found at epoch 8 with ValLoss 0.8351\n",
      "Epoch 9/200 - TrainLoss 1.3085 ValLoss 0.8367\n",
      "Val RMSE (all frames): 0.91932\n",
      "Epoch 10/200 - TrainLoss 1.2793 ValLoss 0.7645\n",
      "Val RMSE (all frames): 0.87832\n",
      " New best model found at epoch 10 with ValLoss 0.7645\n",
      "Epoch 11/200 - TrainLoss 1.2393 ValLoss 0.7937\n",
      "Val RMSE (all frames): 0.89520\n",
      "Epoch 12/200 - TrainLoss 1.2252 ValLoss 0.7863\n",
      "Val RMSE (all frames): 0.89123\n",
      "Epoch 13/200 - TrainLoss 1.2233 ValLoss 0.7633\n",
      "Val RMSE (all frames): 0.87819\n",
      " New best model found at epoch 13 with ValLoss 0.7633\n",
      "Epoch 14/200 - TrainLoss 1.2075 ValLoss 0.7878\n",
      "Val RMSE (all frames): 0.89200\n",
      "Epoch 15/200 - TrainLoss 1.1645 ValLoss 0.7275\n",
      "Val RMSE (all frames): 0.85717\n",
      " New best model found at epoch 15 with ValLoss 0.7275\n",
      "Epoch 16/200 - TrainLoss 1.1529 ValLoss 0.7405\n",
      "Val RMSE (all frames): 0.86463\n",
      "Epoch 17/200 - TrainLoss 1.1393 ValLoss 0.6800\n",
      "Val RMSE (all frames): 0.82878\n",
      " New best model found at epoch 17 with ValLoss 0.6800\n",
      "Epoch 18/200 - TrainLoss 1.1130 ValLoss 0.7299\n",
      "Val RMSE (all frames): 0.85915\n",
      "Epoch 19/200 - TrainLoss 1.1362 ValLoss 0.7790\n",
      "Val RMSE (all frames): 0.88725\n",
      "Epoch 20/200 - TrainLoss 1.0999 ValLoss 0.6823\n",
      "Val RMSE (all frames): 0.82976\n",
      "Epoch 21/200 - TrainLoss 1.0978 ValLoss 0.7043\n",
      "Val RMSE (all frames): 0.84347\n",
      "Epoch 22/200 - TrainLoss 1.0528 ValLoss 0.6842\n",
      "Val RMSE (all frames): 0.83183\n",
      "Epoch 23/200 - TrainLoss 1.0619 ValLoss 0.6662\n",
      "Val RMSE (all frames): 0.82026\n",
      " New best model found at epoch 23 with ValLoss 0.6662\n",
      "Epoch 24/200 - TrainLoss 1.0523 ValLoss 0.6776\n",
      "Val RMSE (all frames): 0.82740\n",
      "Epoch 25/200 - TrainLoss 1.0365 ValLoss 0.6741\n",
      "Val RMSE (all frames): 0.82526\n",
      "Epoch 26/200 - TrainLoss 1.0104 ValLoss 0.6333\n",
      "Val RMSE (all frames): 0.79965\n",
      " New best model found at epoch 26 with ValLoss 0.6333\n",
      "Epoch 27/200 - TrainLoss 1.0119 ValLoss 0.6416\n",
      "Val RMSE (all frames): 0.80502\n",
      "Epoch 28/200 - TrainLoss 1.0099 ValLoss 0.6608\n",
      "Val RMSE (all frames): 0.81702\n",
      "Epoch 29/200 - TrainLoss 0.9981 ValLoss 0.6175\n",
      "Val RMSE (all frames): 0.78958\n",
      " New best model found at epoch 29 with ValLoss 0.6175\n",
      "Epoch 30/200 - TrainLoss 0.9799 ValLoss 0.6445\n",
      "Val RMSE (all frames): 0.80731\n",
      "Epoch 31/200 - TrainLoss 0.9850 ValLoss 0.6313\n",
      "Val RMSE (all frames): 0.79892\n",
      "Epoch 32/200 - TrainLoss 0.9571 ValLoss 0.6139\n",
      "Val RMSE (all frames): 0.78755\n",
      " New best model found at epoch 32 with ValLoss 0.6139\n",
      "Epoch 33/200 - TrainLoss 0.9580 ValLoss 0.6049\n",
      "Val RMSE (all frames): 0.78129\n",
      " New best model found at epoch 33 with ValLoss 0.6049\n",
      "Epoch 34/200 - TrainLoss 0.9542 ValLoss 0.5892\n",
      "Val RMSE (all frames): 0.77116\n",
      " New best model found at epoch 34 with ValLoss 0.5892\n",
      "Epoch 35/200 - TrainLoss 0.9352 ValLoss 0.5962\n",
      "Val RMSE (all frames): 0.77617\n",
      "Epoch 36/200 - TrainLoss 0.9367 ValLoss 0.6145\n",
      "Val RMSE (all frames): 0.78805\n",
      "Epoch 37/200 - TrainLoss 0.9336 ValLoss 0.6213\n",
      "Val RMSE (all frames): 0.79230\n",
      "Epoch 38/200 - TrainLoss 0.9247 ValLoss 0.6465\n",
      "Val RMSE (all frames): 0.80795\n",
      "Epoch 39/200 - TrainLoss 0.9132 ValLoss 0.5969\n",
      "Val RMSE (all frames): 0.77662\n",
      "Epoch 40/200 - TrainLoss 0.9144 ValLoss 0.6310\n",
      "Val RMSE (all frames): 0.79836\n",
      "Epoch 41/200 - TrainLoss 0.8570 ValLoss 0.5654\n",
      "Val RMSE (all frames): 0.75547\n",
      " New best model found at epoch 41 with ValLoss 0.5654\n",
      "Epoch 42/200 - TrainLoss 0.8568 ValLoss 0.5625\n",
      "Val RMSE (all frames): 0.75365\n",
      " New best model found at epoch 42 with ValLoss 0.5625\n",
      "Epoch 43/200 - TrainLoss 0.8404 ValLoss 0.5587\n",
      "Val RMSE (all frames): 0.75132\n",
      " New best model found at epoch 43 with ValLoss 0.5587\n",
      "Epoch 44/200 - TrainLoss 0.8392 ValLoss 0.5788\n",
      "Val RMSE (all frames): 0.76434\n",
      "Epoch 45/200 - TrainLoss 0.8344 ValLoss 0.5682\n",
      "Val RMSE (all frames): 0.75722\n",
      "Epoch 46/200 - TrainLoss 0.8345 ValLoss 0.5627\n",
      "Val RMSE (all frames): 0.75374\n",
      "Epoch 47/200 - TrainLoss 0.8147 ValLoss 0.5816\n",
      "Val RMSE (all frames): 0.76659\n",
      "Epoch 48/200 - TrainLoss 0.8194 ValLoss 0.5486\n",
      "Val RMSE (all frames): 0.74434\n",
      " New best model found at epoch 48 with ValLoss 0.5486\n",
      "Epoch 49/200 - TrainLoss 0.8253 ValLoss 0.5814\n",
      "Val RMSE (all frames): 0.76638\n",
      "Epoch 50/200 - TrainLoss 0.8116 ValLoss 0.5506\n",
      "Val RMSE (all frames): 0.74584\n",
      "Epoch 51/200 - TrainLoss 0.8214 ValLoss 0.5645\n",
      "Val RMSE (all frames): 0.75513\n",
      "Epoch 52/200 - TrainLoss 0.8033 ValLoss 0.5830\n",
      "Val RMSE (all frames): 0.76761\n",
      "Epoch 53/200 - TrainLoss 0.7999 ValLoss 0.5611\n",
      "Val RMSE (all frames): 0.75284\n",
      "Epoch 54/200 - TrainLoss 0.8001 ValLoss 0.5605\n",
      "Val RMSE (all frames): 0.75233\n",
      "Epoch 55/200 - TrainLoss 0.7875 ValLoss 0.5349\n",
      "Val RMSE (all frames): 0.73500\n",
      " New best model found at epoch 55 with ValLoss 0.5349\n",
      "Epoch 56/200 - TrainLoss 0.7766 ValLoss 0.5347\n",
      "Val RMSE (all frames): 0.73482\n",
      " New best model found at epoch 56 with ValLoss 0.5347\n",
      "Epoch 57/200 - TrainLoss 0.7685 ValLoss 0.5447\n",
      "Val RMSE (all frames): 0.74150\n",
      "Epoch 58/200 - TrainLoss 0.7761 ValLoss 0.5395\n",
      "Val RMSE (all frames): 0.73799\n",
      "Epoch 59/200 - TrainLoss 0.7641 ValLoss 0.5461\n",
      "Val RMSE (all frames): 0.74270\n",
      "Epoch 60/200 - TrainLoss 0.7643 ValLoss 0.5272\n",
      "Val RMSE (all frames): 0.72944\n",
      " New best model found at epoch 60 with ValLoss 0.5272\n",
      "Epoch 61/200 - TrainLoss 0.7717 ValLoss 0.5297\n",
      "Val RMSE (all frames): 0.73110\n",
      "Epoch 62/200 - TrainLoss 0.7517 ValLoss 0.5423\n",
      "Val RMSE (all frames): 0.74003\n",
      "Epoch 63/200 - TrainLoss 0.7650 ValLoss 0.5403\n",
      "Val RMSE (all frames): 0.73869\n",
      "Epoch 64/200 - TrainLoss 0.7573 ValLoss 0.5361\n",
      "Val RMSE (all frames): 0.73586\n",
      "Epoch 65/200 - TrainLoss 0.7561 ValLoss 0.5424\n",
      "Val RMSE (all frames): 0.74007\n",
      "Epoch 66/200 - TrainLoss 0.7506 ValLoss 0.5239\n",
      "Val RMSE (all frames): 0.72733\n",
      " New best model found at epoch 66 with ValLoss 0.5239\n",
      "Epoch 67/200 - TrainLoss 0.7542 ValLoss 0.5431\n",
      "Val RMSE (all frames): 0.74054\n",
      "Epoch 68/200 - TrainLoss 0.7458 ValLoss 0.5374\n",
      "Val RMSE (all frames): 0.73659\n",
      "Epoch 69/200 - TrainLoss 0.7390 ValLoss 0.5356\n",
      "Val RMSE (all frames): 0.73545\n",
      "Epoch 70/200 - TrainLoss 0.7372 ValLoss 0.5444\n",
      "Val RMSE (all frames): 0.74156\n",
      "Epoch 71/200 - TrainLoss 0.7499 ValLoss 0.5405\n",
      "Val RMSE (all frames): 0.73887\n",
      "Epoch 72/200 - TrainLoss 0.7351 ValLoss 0.5386\n",
      "Val RMSE (all frames): 0.73765\n",
      "Epoch 73/200 - TrainLoss 0.7273 ValLoss 0.5282\n",
      "Val RMSE (all frames): 0.73025\n",
      "Epoch 74/200 - TrainLoss 0.7431 ValLoss 0.5189\n",
      "Val RMSE (all frames): 0.72377\n",
      " New best model found at epoch 74 with ValLoss 0.5189\n",
      "Epoch 75/200 - TrainLoss 0.7217 ValLoss 0.5195\n",
      "Val RMSE (all frames): 0.72415\n",
      "Epoch 76/200 - TrainLoss 0.7226 ValLoss 0.5212\n",
      "Val RMSE (all frames): 0.72533\n",
      "Epoch 77/200 - TrainLoss 0.7356 ValLoss 0.5236\n",
      "Val RMSE (all frames): 0.72710\n",
      "Epoch 78/200 - TrainLoss 0.7365 ValLoss 0.5252\n",
      "Val RMSE (all frames): 0.72810\n",
      "Epoch 79/200 - TrainLoss 0.7377 ValLoss 0.5197\n",
      "Val RMSE (all frames): 0.72446\n",
      "Epoch 80/200 - TrainLoss 0.7312 ValLoss 0.5226\n",
      "Val RMSE (all frames): 0.72648\n",
      "Epoch 81/200 - TrainLoss 0.7115 ValLoss 0.5148\n",
      "Val RMSE (all frames): 0.72088\n",
      " New best model found at epoch 81 with ValLoss 0.5148\n",
      "Epoch 82/200 - TrainLoss 0.7220 ValLoss 0.5152\n",
      "Val RMSE (all frames): 0.72122\n",
      "Epoch 83/200 - TrainLoss 0.7264 ValLoss 0.5139\n",
      "Val RMSE (all frames): 0.72030\n",
      " New best model found at epoch 83 with ValLoss 0.5139\n",
      "Epoch 84/200 - TrainLoss 0.7277 ValLoss 0.5129\n",
      "Val RMSE (all frames): 0.71958\n",
      " New best model found at epoch 84 with ValLoss 0.5129\n",
      "Epoch 85/200 - TrainLoss 0.7285 ValLoss 0.5131\n",
      "Val RMSE (all frames): 0.71971\n",
      "Epoch 86/200 - TrainLoss 0.7112 ValLoss 0.5134\n",
      "Val RMSE (all frames): 0.71997\n",
      "Epoch 87/200 - TrainLoss 0.7186 ValLoss 0.5185\n",
      "Val RMSE (all frames): 0.72364\n",
      "Epoch 88/200 - TrainLoss 0.7168 ValLoss 0.5150\n",
      "Val RMSE (all frames): 0.72116\n",
      "Epoch 89/200 - TrainLoss 0.7154 ValLoss 0.5134\n",
      "Val RMSE (all frames): 0.72013\n",
      "Epoch 90/200 - TrainLoss 0.7183 ValLoss 0.5132\n",
      "Val RMSE (all frames): 0.71994\n",
      "Epoch 91/200 - TrainLoss 0.7129 ValLoss 0.5126\n",
      "Val RMSE (all frames): 0.71942\n",
      " New best model found at epoch 91 with ValLoss 0.5126\n",
      "Epoch 92/200 - TrainLoss 0.7214 ValLoss 0.5149\n",
      "Val RMSE (all frames): 0.72112\n",
      "Epoch 93/200 - TrainLoss 0.7081 ValLoss 0.5101\n",
      "Val RMSE (all frames): 0.71762\n",
      " New best model found at epoch 93 with ValLoss 0.5101\n",
      "Epoch 94/200 - TrainLoss 0.7112 ValLoss 0.5126\n",
      "Val RMSE (all frames): 0.71946\n",
      "Epoch 95/200 - TrainLoss 0.7022 ValLoss 0.5118\n",
      "Val RMSE (all frames): 0.71888\n",
      "Epoch 96/200 - TrainLoss 0.7148 ValLoss 0.5113\n",
      "Val RMSE (all frames): 0.71854\n",
      "Epoch 97/200 - TrainLoss 0.7103 ValLoss 0.5144\n",
      "Val RMSE (all frames): 0.72072\n",
      "Epoch 98/200 - TrainLoss 0.7103 ValLoss 0.5137\n",
      "Val RMSE (all frames): 0.72018\n",
      "Epoch 99/200 - TrainLoss 0.7033 ValLoss 0.5120\n",
      "Val RMSE (all frames): 0.71891\n",
      "Epoch 100/200 - TrainLoss 0.7054 ValLoss 0.5118\n",
      "Val RMSE (all frames): 0.71885\n",
      "Epoch 101/200 - TrainLoss 0.7042 ValLoss 0.5108\n",
      "Val RMSE (all frames): 0.71809\n",
      "Epoch 102/200 - TrainLoss 0.7043 ValLoss 0.5124\n",
      "Val RMSE (all frames): 0.71921\n",
      "Epoch 103/200 - TrainLoss 0.6962 ValLoss 0.5128\n",
      "Val RMSE (all frames): 0.71950\n",
      "Epoch 104/200 - TrainLoss 0.7080 ValLoss 0.5100\n",
      "Val RMSE (all frames): 0.71755\n",
      " New best model found at epoch 104 with ValLoss 0.5100\n",
      "Epoch 105/200 - TrainLoss 0.7041 ValLoss 0.5121\n",
      "Val RMSE (all frames): 0.71904\n",
      "Epoch 106/200 - TrainLoss 0.7139 ValLoss 0.5119\n",
      "Val RMSE (all frames): 0.71892\n",
      "Epoch 107/200 - TrainLoss 0.6981 ValLoss 0.5107\n",
      "Val RMSE (all frames): 0.71795\n",
      "Epoch 108/200 - TrainLoss 0.7064 ValLoss 0.5110\n",
      "Val RMSE (all frames): 0.71825\n",
      "Epoch 109/200 - TrainLoss 0.7008 ValLoss 0.5099\n",
      "Val RMSE (all frames): 0.71741\n",
      " New best model found at epoch 109 with ValLoss 0.5099\n",
      "Epoch 110/200 - TrainLoss 0.7015 ValLoss 0.5115\n",
      "Val RMSE (all frames): 0.71856\n",
      "Epoch 111/200 - TrainLoss 0.7077 ValLoss 0.5109\n",
      "Val RMSE (all frames): 0.71821\n",
      "Epoch 112/200 - TrainLoss 0.6911 ValLoss 0.5098\n",
      "Val RMSE (all frames): 0.71735\n",
      " New best model found at epoch 112 with ValLoss 0.5098\n",
      "Epoch 113/200 - TrainLoss 0.7041 ValLoss 0.5108\n",
      "Val RMSE (all frames): 0.71808\n",
      "Epoch 114/200 - TrainLoss 0.7164 ValLoss 0.5112\n",
      "Val RMSE (all frames): 0.71835\n",
      "Epoch 115/200 - TrainLoss 0.6995 ValLoss 0.5102\n",
      "Val RMSE (all frames): 0.71770\n",
      "Epoch 116/200 - TrainLoss 0.7079 ValLoss 0.5110\n",
      "Val RMSE (all frames): 0.71823\n",
      "Epoch 117/200 - TrainLoss 0.7022 ValLoss 0.5093\n",
      "Val RMSE (all frames): 0.71706\n",
      " New best model found at epoch 117 with ValLoss 0.5093\n",
      "Epoch 118/200 - TrainLoss 0.6961 ValLoss 0.5103\n",
      "Val RMSE (all frames): 0.71780\n",
      "Epoch 119/200 - TrainLoss 0.6944 ValLoss 0.5100\n",
      "Val RMSE (all frames): 0.71755\n",
      "Epoch 120/200 - TrainLoss 0.7039 ValLoss 0.5094\n",
      "Val RMSE (all frames): 0.71717\n",
      "Epoch 121/200 - TrainLoss 0.6990 ValLoss 0.5103\n",
      "Val RMSE (all frames): 0.71779\n",
      "Epoch 122/200 - TrainLoss 0.6955 ValLoss 0.5105\n",
      "Val RMSE (all frames): 0.71792\n",
      "Epoch 123/200 - TrainLoss 0.7001 ValLoss 0.5106\n",
      "Val RMSE (all frames): 0.71797\n",
      "Epoch 124/200 - TrainLoss 0.7101 ValLoss 0.5101\n",
      "Val RMSE (all frames): 0.71763\n",
      "Epoch 125/200 - TrainLoss 0.7090 ValLoss 0.5094\n",
      "Val RMSE (all frames): 0.71713\n",
      "Epoch 126/200 - TrainLoss 0.6855 ValLoss 0.5088\n",
      "Val RMSE (all frames): 0.71675\n",
      " New best model found at epoch 126 with ValLoss 0.5088\n",
      "Epoch 127/200 - TrainLoss 0.6991 ValLoss 0.5102\n",
      "Val RMSE (all frames): 0.71772\n",
      "Epoch 128/200 - TrainLoss 0.7021 ValLoss 0.5094\n",
      "Val RMSE (all frames): 0.71716\n",
      "Epoch 129/200 - TrainLoss 0.6948 ValLoss 0.5107\n",
      "Val RMSE (all frames): 0.71811\n",
      "Epoch 130/200 - TrainLoss 0.7006 ValLoss 0.5100\n",
      "Val RMSE (all frames): 0.71759\n",
      "Epoch 131/200 - TrainLoss 0.6968 ValLoss 0.5098\n",
      "Val RMSE (all frames): 0.71745\n",
      "Epoch 132/200 - TrainLoss 0.6987 ValLoss 0.5109\n",
      "Val RMSE (all frames): 0.71820\n",
      "Epoch 133/200 - TrainLoss 0.7008 ValLoss 0.5097\n",
      "Val RMSE (all frames): 0.71738\n",
      "Epoch 134/200 - TrainLoss 0.7143 ValLoss 0.5097\n",
      "Val RMSE (all frames): 0.71736\n",
      "Epoch 135/200 - TrainLoss 0.6908 ValLoss 0.5103\n",
      "Val RMSE (all frames): 0.71773\n",
      "Epoch 136/200 - TrainLoss 0.6988 ValLoss 0.5100\n",
      "Val RMSE (all frames): 0.71752\n",
      "Epoch 137/200 - TrainLoss 0.7072 ValLoss 0.5092\n",
      "Val RMSE (all frames): 0.71695\n",
      "Epoch 138/200 - TrainLoss 0.7048 ValLoss 0.5095\n",
      "Val RMSE (all frames): 0.71723\n",
      "Epoch 139/200 - TrainLoss 0.7118 ValLoss 0.5097\n",
      "Val RMSE (all frames): 0.71736\n",
      "Epoch 140/200 - TrainLoss 0.7035 ValLoss 0.5098\n",
      "Val RMSE (all frames): 0.71740\n",
      "Epoch 141/200 - TrainLoss 0.7063 ValLoss 0.5096\n",
      "Val RMSE (all frames): 0.71726\n",
      "Epoch 142/200 - TrainLoss 0.6977 ValLoss 0.5093\n",
      "Val RMSE (all frames): 0.71705\n",
      "Epoch 143/200 - TrainLoss 0.7038 ValLoss 0.5097\n",
      "Val RMSE (all frames): 0.71732\n",
      "Epoch 144/200 - TrainLoss 0.6975 ValLoss 0.5094\n",
      "Val RMSE (all frames): 0.71713\n",
      "Epoch 145/200 - TrainLoss 0.6878 ValLoss 0.5095\n",
      "Val RMSE (all frames): 0.71719\n",
      "Epoch 146/200 - TrainLoss 0.6995 ValLoss 0.5095\n",
      "Val RMSE (all frames): 0.71720\n",
      "Epoch 147/200 - TrainLoss 0.7038 ValLoss 0.5096\n",
      "Val RMSE (all frames): 0.71729\n",
      "Epoch 148/200 - TrainLoss 0.7168 ValLoss 0.5098\n",
      "Val RMSE (all frames): 0.71739\n",
      "Epoch 149/200 - TrainLoss 0.7046 ValLoss 0.5097\n",
      "Val RMSE (all frames): 0.71733\n",
      "Epoch 150/200 - TrainLoss 0.7048 ValLoss 0.5095\n",
      "Val RMSE (all frames): 0.71723\n",
      "Epoch 151/200 - TrainLoss 0.7045 ValLoss 0.5096\n",
      "Val RMSE (all frames): 0.71726\n",
      "Epoch 152/200 - TrainLoss 0.6897 ValLoss 0.5096\n",
      "Val RMSE (all frames): 0.71729\n",
      "Epoch 153/200 - TrainLoss 0.7094 ValLoss 0.5097\n",
      "Val RMSE (all frames): 0.71737\n",
      "Epoch 154/200 - TrainLoss 0.7098 ValLoss 0.5097\n",
      "Val RMSE (all frames): 0.71737\n",
      "Epoch 155/200 - TrainLoss 0.6966 ValLoss 0.5096\n",
      "Val RMSE (all frames): 0.71729\n",
      "Epoch 156/200 - TrainLoss 0.6927 ValLoss 0.5095\n",
      "Val RMSE (all frames): 0.71722\n",
      "Early stopping epoch 156\n",
      "Scaler for fold 3 saved to 'fold_3/lstm_feature_scaler_fold.joblib'\n",
      "Model for fold 3 saved to 'fold_3/lstm_model_fold.pt'\n",
      "shape of oof_pred_fold: (111428, 3)\n",
      "\n",
      "--- Training Fold 4/5 ---\n",
      "Maximum output frames: 94\n",
      "Using device: cpu\n",
      "sucessfully moved model to device\n",
      "Epoch 1/200 - TrainLoss 7.5342 ValLoss 2.5876\n",
      "Val RMSE (all frames): 1.63017\n",
      " New best model found at epoch 1 with ValLoss 2.5876\n",
      "Epoch 2/200 - TrainLoss 2.4967 ValLoss 1.8020\n",
      "Val RMSE (all frames): 1.36563\n",
      " New best model found at epoch 2 with ValLoss 1.8020\n",
      "Epoch 3/200 - TrainLoss 1.9306 ValLoss 1.5494\n",
      "Val RMSE (all frames): 1.26832\n",
      " New best model found at epoch 3 with ValLoss 1.5494\n",
      "Epoch 4/200 - TrainLoss 1.6825 ValLoss 1.4051\n",
      "Val RMSE (all frames): 1.20989\n",
      " New best model found at epoch 4 with ValLoss 1.4051\n",
      "Epoch 5/200 - TrainLoss 1.5171 ValLoss 1.3414\n",
      "Val RMSE (all frames): 1.18269\n",
      " New best model found at epoch 5 with ValLoss 1.3414\n",
      "Epoch 6/200 - TrainLoss 1.4399 ValLoss 1.3027\n",
      "Val RMSE (all frames): 1.16668\n",
      " New best model found at epoch 6 with ValLoss 1.3027\n",
      "Epoch 7/200 - TrainLoss 1.3926 ValLoss 1.2558\n",
      "Val RMSE (all frames): 1.14533\n",
      " New best model found at epoch 7 with ValLoss 1.2558\n",
      "Epoch 8/200 - TrainLoss 1.3542 ValLoss 1.1850\n",
      "Val RMSE (all frames): 1.11392\n",
      " New best model found at epoch 8 with ValLoss 1.1850\n",
      "Epoch 9/200 - TrainLoss 1.2960 ValLoss 1.2114\n",
      "Val RMSE (all frames): 1.12521\n",
      "Epoch 10/200 - TrainLoss 1.2718 ValLoss 1.1622\n",
      "Val RMSE (all frames): 1.10308\n",
      " New best model found at epoch 10 with ValLoss 1.1622\n",
      "Epoch 11/200 - TrainLoss 1.2288 ValLoss 1.1472\n",
      "Val RMSE (all frames): 1.09636\n",
      " New best model found at epoch 11 with ValLoss 1.1472\n",
      "Epoch 12/200 - TrainLoss 1.2040 ValLoss 1.1943\n",
      "Val RMSE (all frames): 1.11772\n",
      "Epoch 13/200 - TrainLoss 1.1936 ValLoss 1.1473\n",
      "Val RMSE (all frames): 1.09683\n",
      "Epoch 14/200 - TrainLoss 1.1521 ValLoss 1.0778\n",
      "Val RMSE (all frames): 1.06356\n",
      " New best model found at epoch 14 with ValLoss 1.0778\n",
      "Epoch 15/200 - TrainLoss 1.1280 ValLoss 1.0806\n",
      "Val RMSE (all frames): 1.06531\n",
      "Epoch 16/200 - TrainLoss 1.1291 ValLoss 1.0743\n",
      "Val RMSE (all frames): 1.06239\n",
      " New best model found at epoch 16 with ValLoss 1.0743\n",
      "Epoch 17/200 - TrainLoss 1.1001 ValLoss 1.0527\n",
      "Val RMSE (all frames): 1.05129\n",
      " New best model found at epoch 17 with ValLoss 1.0527\n",
      "Epoch 18/200 - TrainLoss 1.1038 ValLoss 1.0651\n",
      "Val RMSE (all frames): 1.05793\n",
      "Epoch 19/200 - TrainLoss 1.0668 ValLoss 1.0913\n",
      "Val RMSE (all frames): 1.06987\n",
      "Epoch 20/200 - TrainLoss 1.0526 ValLoss 1.0343\n",
      "Val RMSE (all frames): 1.04245\n",
      " New best model found at epoch 20 with ValLoss 1.0343\n",
      "Epoch 21/200 - TrainLoss 1.0423 ValLoss 1.0152\n",
      "Val RMSE (all frames): 1.03308\n",
      " New best model found at epoch 21 with ValLoss 1.0152\n",
      "Epoch 22/200 - TrainLoss 1.0386 ValLoss 1.0195\n",
      "Val RMSE (all frames): 1.03560\n",
      "Epoch 23/200 - TrainLoss 1.0191 ValLoss 1.0125\n",
      "Val RMSE (all frames): 1.03166\n",
      " New best model found at epoch 23 with ValLoss 1.0125\n",
      "Epoch 24/200 - TrainLoss 0.9979 ValLoss 1.0011\n",
      "Val RMSE (all frames): 1.02645\n",
      " New best model found at epoch 24 with ValLoss 1.0011\n",
      "Epoch 25/200 - TrainLoss 1.0133 ValLoss 0.9916\n",
      "Val RMSE (all frames): 1.02164\n",
      " New best model found at epoch 25 with ValLoss 0.9916\n",
      "Epoch 26/200 - TrainLoss 0.9953 ValLoss 1.0110\n",
      "Val RMSE (all frames): 1.03120\n",
      "Epoch 27/200 - TrainLoss 0.9783 ValLoss 1.0060\n",
      "Val RMSE (all frames): 1.02881\n",
      "Epoch 28/200 - TrainLoss 0.9841 ValLoss 0.9654\n",
      "Val RMSE (all frames): 1.00891\n",
      " New best model found at epoch 28 with ValLoss 0.9654\n",
      "Epoch 29/200 - TrainLoss 0.9537 ValLoss 0.9872\n",
      "Val RMSE (all frames): 1.01907\n",
      "Epoch 30/200 - TrainLoss 0.9424 ValLoss 0.9770\n",
      "Val RMSE (all frames): 1.01385\n",
      "Epoch 31/200 - TrainLoss 0.9538 ValLoss 0.9775\n",
      "Val RMSE (all frames): 1.01458\n",
      "Epoch 32/200 - TrainLoss 0.9512 ValLoss 0.9887\n",
      "Val RMSE (all frames): 1.01983\n",
      "Epoch 33/200 - TrainLoss 0.9369 ValLoss 0.9658\n",
      "Val RMSE (all frames): 1.00876\n",
      "Epoch 34/200 - TrainLoss 0.9353 ValLoss 0.9706\n",
      "Val RMSE (all frames): 1.01113\n",
      "Epoch 35/200 - TrainLoss 0.8761 ValLoss 0.9119\n",
      "Val RMSE (all frames): 0.98123\n",
      " New best model found at epoch 35 with ValLoss 0.9119\n",
      "Epoch 36/200 - TrainLoss 0.8834 ValLoss 0.9073\n",
      "Val RMSE (all frames): 0.97904\n",
      " New best model found at epoch 36 with ValLoss 0.9073\n",
      "Epoch 37/200 - TrainLoss 0.8485 ValLoss 0.9166\n",
      "Val RMSE (all frames): 0.98382\n",
      "Epoch 38/200 - TrainLoss 0.8505 ValLoss 0.9045\n",
      "Val RMSE (all frames): 0.97747\n",
      " New best model found at epoch 38 with ValLoss 0.9045\n",
      "Epoch 39/200 - TrainLoss 0.8426 ValLoss 0.8985\n",
      "Val RMSE (all frames): 0.97465\n",
      " New best model found at epoch 39 with ValLoss 0.8985\n",
      "Epoch 40/200 - TrainLoss 0.8318 ValLoss 0.9140\n",
      "Val RMSE (all frames): 0.98224\n",
      "Epoch 41/200 - TrainLoss 0.8310 ValLoss 0.9081\n",
      "Val RMSE (all frames): 0.97958\n",
      "Epoch 42/200 - TrainLoss 0.8263 ValLoss 0.9065\n",
      "Val RMSE (all frames): 0.97847\n",
      "Epoch 43/200 - TrainLoss 0.8303 ValLoss 0.8985\n",
      "Val RMSE (all frames): 0.97439\n",
      " New best model found at epoch 43 with ValLoss 0.8985\n",
      "Epoch 44/200 - TrainLoss 0.8125 ValLoss 0.9042\n",
      "Val RMSE (all frames): 0.97745\n",
      "Epoch 45/200 - TrainLoss 0.8105 ValLoss 0.8946\n",
      "Val RMSE (all frames): 0.97220\n",
      " New best model found at epoch 45 with ValLoss 0.8946\n",
      "Epoch 46/200 - TrainLoss 0.8114 ValLoss 0.9025\n",
      "Val RMSE (all frames): 0.97702\n",
      "Epoch 47/200 - TrainLoss 0.8022 ValLoss 0.8971\n",
      "Val RMSE (all frames): 0.97405\n",
      "Epoch 48/200 - TrainLoss 0.8101 ValLoss 0.8978\n",
      "Val RMSE (all frames): 0.97429\n",
      "Epoch 49/200 - TrainLoss 0.8114 ValLoss 0.9086\n",
      "Val RMSE (all frames): 0.97963\n",
      "Epoch 50/200 - TrainLoss 0.8108 ValLoss 0.8944\n",
      "Val RMSE (all frames): 0.97224\n",
      " New best model found at epoch 50 with ValLoss 0.8944\n",
      "Epoch 51/200 - TrainLoss 0.8032 ValLoss 0.8987\n",
      "Val RMSE (all frames): 0.97467\n",
      "Epoch 52/200 - TrainLoss 0.7923 ValLoss 0.8917\n",
      "Val RMSE (all frames): 0.97127\n",
      " New best model found at epoch 52 with ValLoss 0.8917\n",
      "Epoch 53/200 - TrainLoss 0.7949 ValLoss 0.8782\n",
      "Val RMSE (all frames): 0.96418\n",
      " New best model found at epoch 53 with ValLoss 0.8782\n",
      "Epoch 54/200 - TrainLoss 0.7822 ValLoss 0.8834\n",
      "Val RMSE (all frames): 0.96664\n",
      "Epoch 55/200 - TrainLoss 0.7849 ValLoss 0.8960\n",
      "Val RMSE (all frames): 0.97340\n",
      "Epoch 56/200 - TrainLoss 0.7957 ValLoss 0.8875\n",
      "Val RMSE (all frames): 0.96878\n",
      "Epoch 57/200 - TrainLoss 0.7771 ValLoss 0.8857\n",
      "Val RMSE (all frames): 0.96785\n",
      "Epoch 58/200 - TrainLoss 0.7802 ValLoss 0.8875\n",
      "Val RMSE (all frames): 0.96896\n",
      "Epoch 59/200 - TrainLoss 0.7698 ValLoss 0.8851\n",
      "Val RMSE (all frames): 0.96775\n",
      "Epoch 60/200 - TrainLoss 0.7592 ValLoss 0.8751\n",
      "Val RMSE (all frames): 0.96257\n",
      " New best model found at epoch 60 with ValLoss 0.8751\n",
      "Epoch 61/200 - TrainLoss 0.7526 ValLoss 0.8732\n",
      "Val RMSE (all frames): 0.96160\n",
      " New best model found at epoch 61 with ValLoss 0.8732\n",
      "Epoch 62/200 - TrainLoss 0.7425 ValLoss 0.8786\n",
      "Val RMSE (all frames): 0.96425\n",
      "Epoch 63/200 - TrainLoss 0.7307 ValLoss 0.8767\n",
      "Val RMSE (all frames): 0.96317\n",
      "Epoch 64/200 - TrainLoss 0.7423 ValLoss 0.8730\n",
      "Val RMSE (all frames): 0.96158\n",
      " New best model found at epoch 64 with ValLoss 0.8730\n",
      "Epoch 65/200 - TrainLoss 0.7468 ValLoss 0.8688\n",
      "Val RMSE (all frames): 0.95936\n",
      " New best model found at epoch 65 with ValLoss 0.8688\n",
      "Epoch 66/200 - TrainLoss 0.7357 ValLoss 0.8724\n",
      "Val RMSE (all frames): 0.96121\n",
      "Epoch 67/200 - TrainLoss 0.7267 ValLoss 0.8642\n",
      "Val RMSE (all frames): 0.95707\n",
      " New best model found at epoch 67 with ValLoss 0.8642\n",
      "Epoch 68/200 - TrainLoss 0.7344 ValLoss 0.8701\n",
      "Val RMSE (all frames): 0.95987\n",
      "Epoch 69/200 - TrainLoss 0.7277 ValLoss 0.8705\n",
      "Val RMSE (all frames): 0.96019\n",
      "Epoch 70/200 - TrainLoss 0.7359 ValLoss 0.8729\n",
      "Val RMSE (all frames): 0.96110\n",
      "Epoch 71/200 - TrainLoss 0.7346 ValLoss 0.8612\n",
      "Val RMSE (all frames): 0.95504\n",
      " New best model found at epoch 71 with ValLoss 0.8612\n",
      "Epoch 72/200 - TrainLoss 0.7251 ValLoss 0.8663\n",
      "Val RMSE (all frames): 0.95776\n",
      "Epoch 73/200 - TrainLoss 0.7192 ValLoss 0.8742\n",
      "Val RMSE (all frames): 0.96200\n",
      "Epoch 74/200 - TrainLoss 0.7264 ValLoss 0.8591\n",
      "Val RMSE (all frames): 0.95410\n",
      " New best model found at epoch 74 with ValLoss 0.8591\n",
      "Epoch 75/200 - TrainLoss 0.7216 ValLoss 0.8751\n",
      "Val RMSE (all frames): 0.96255\n",
      "Epoch 76/200 - TrainLoss 0.7105 ValLoss 0.8665\n",
      "Val RMSE (all frames): 0.95821\n",
      "Epoch 77/200 - TrainLoss 0.7264 ValLoss 0.8697\n",
      "Val RMSE (all frames): 0.96002\n",
      "Epoch 78/200 - TrainLoss 0.7258 ValLoss 0.8643\n",
      "Val RMSE (all frames): 0.95714\n",
      "Epoch 79/200 - TrainLoss 0.7086 ValLoss 0.8747\n",
      "Val RMSE (all frames): 0.96215\n",
      "Epoch 80/200 - TrainLoss 0.7244 ValLoss 0.8732\n",
      "Val RMSE (all frames): 0.96150\n",
      "Epoch 81/200 - TrainLoss 0.7048 ValLoss 0.8655\n",
      "Val RMSE (all frames): 0.95765\n",
      "Epoch 82/200 - TrainLoss 0.7073 ValLoss 0.8637\n",
      "Val RMSE (all frames): 0.95667\n",
      "Epoch 83/200 - TrainLoss 0.7039 ValLoss 0.8647\n",
      "Val RMSE (all frames): 0.95712\n",
      "Epoch 84/200 - TrainLoss 0.6984 ValLoss 0.8604\n",
      "Val RMSE (all frames): 0.95494\n",
      "Epoch 85/200 - TrainLoss 0.7095 ValLoss 0.8663\n",
      "Val RMSE (all frames): 0.95795\n",
      "Epoch 86/200 - TrainLoss 0.7224 ValLoss 0.8691\n",
      "Val RMSE (all frames): 0.95927\n",
      "Epoch 87/200 - TrainLoss 0.6918 ValLoss 0.8646\n",
      "Val RMSE (all frames): 0.95698\n",
      "Epoch 88/200 - TrainLoss 0.6953 ValLoss 0.8629\n",
      "Val RMSE (all frames): 0.95618\n",
      "Epoch 89/200 - TrainLoss 0.6983 ValLoss 0.8605\n",
      "Val RMSE (all frames): 0.95499\n",
      "Epoch 90/200 - TrainLoss 0.7071 ValLoss 0.8569\n",
      "Val RMSE (all frames): 0.95306\n",
      " New best model found at epoch 90 with ValLoss 0.8569\n",
      "Epoch 91/200 - TrainLoss 0.6933 ValLoss 0.8597\n",
      "Val RMSE (all frames): 0.95445\n",
      "Epoch 92/200 - TrainLoss 0.6830 ValLoss 0.8588\n",
      "Val RMSE (all frames): 0.95395\n",
      "Epoch 93/200 - TrainLoss 0.7021 ValLoss 0.8586\n",
      "Val RMSE (all frames): 0.95409\n",
      "Epoch 94/200 - TrainLoss 0.6816 ValLoss 0.8594\n",
      "Val RMSE (all frames): 0.95451\n",
      "Epoch 95/200 - TrainLoss 0.6929 ValLoss 0.8589\n",
      "Val RMSE (all frames): 0.95418\n",
      "Epoch 96/200 - TrainLoss 0.6988 ValLoss 0.8622\n",
      "Val RMSE (all frames): 0.95573\n",
      "Epoch 97/200 - TrainLoss 0.6848 ValLoss 0.8584\n",
      "Val RMSE (all frames): 0.95378\n",
      "Epoch 98/200 - TrainLoss 0.6990 ValLoss 0.8557\n",
      "Val RMSE (all frames): 0.95245\n",
      " New best model found at epoch 98 with ValLoss 0.8557\n",
      "Epoch 99/200 - TrainLoss 0.6900 ValLoss 0.8558\n",
      "Val RMSE (all frames): 0.95244\n",
      "Epoch 100/200 - TrainLoss 0.6868 ValLoss 0.8569\n",
      "Val RMSE (all frames): 0.95302\n",
      "Epoch 101/200 - TrainLoss 0.6903 ValLoss 0.8548\n",
      "Val RMSE (all frames): 0.95199\n",
      " New best model found at epoch 101 with ValLoss 0.8548\n",
      "Epoch 102/200 - TrainLoss 0.6667 ValLoss 0.8566\n",
      "Val RMSE (all frames): 0.95289\n",
      "Epoch 103/200 - TrainLoss 0.6931 ValLoss 0.8573\n",
      "Val RMSE (all frames): 0.95325\n",
      "Epoch 104/200 - TrainLoss 0.6764 ValLoss 0.8560\n",
      "Val RMSE (all frames): 0.95255\n",
      "Epoch 105/200 - TrainLoss 0.6961 ValLoss 0.8563\n",
      "Val RMSE (all frames): 0.95282\n",
      "Epoch 106/200 - TrainLoss 0.6899 ValLoss 0.8571\n",
      "Val RMSE (all frames): 0.95323\n",
      "Epoch 107/200 - TrainLoss 0.6838 ValLoss 0.8585\n",
      "Val RMSE (all frames): 0.95390\n",
      "Epoch 108/200 - TrainLoss 0.6927 ValLoss 0.8574\n",
      "Val RMSE (all frames): 0.95331\n",
      "Epoch 109/200 - TrainLoss 0.6773 ValLoss 0.8566\n",
      "Val RMSE (all frames): 0.95291\n",
      "Epoch 110/200 - TrainLoss 0.6840 ValLoss 0.8558\n",
      "Val RMSE (all frames): 0.95243\n",
      "Epoch 111/200 - TrainLoss 0.6869 ValLoss 0.8559\n",
      "Val RMSE (all frames): 0.95246\n",
      "Epoch 112/200 - TrainLoss 0.7011 ValLoss 0.8540\n",
      "Val RMSE (all frames): 0.95159\n",
      " New best model found at epoch 112 with ValLoss 0.8540\n",
      "Epoch 113/200 - TrainLoss 0.6729 ValLoss 0.8540\n",
      "Val RMSE (all frames): 0.95152\n",
      " New best model found at epoch 113 with ValLoss 0.8540\n",
      "Epoch 114/200 - TrainLoss 0.6852 ValLoss 0.8541\n",
      "Val RMSE (all frames): 0.95158\n",
      "Epoch 115/200 - TrainLoss 0.6847 ValLoss 0.8552\n",
      "Val RMSE (all frames): 0.95222\n",
      "Epoch 116/200 - TrainLoss 0.6863 ValLoss 0.8544\n",
      "Val RMSE (all frames): 0.95175\n",
      "Epoch 117/200 - TrainLoss 0.6921 ValLoss 0.8566\n",
      "Val RMSE (all frames): 0.95287\n",
      "Epoch 118/200 - TrainLoss 0.6894 ValLoss 0.8540\n",
      "Val RMSE (all frames): 0.95159\n",
      "Epoch 119/200 - TrainLoss 0.6812 ValLoss 0.8536\n",
      "Val RMSE (all frames): 0.95137\n",
      " New best model found at epoch 119 with ValLoss 0.8536\n",
      "Epoch 120/200 - TrainLoss 0.6815 ValLoss 0.8537\n",
      "Val RMSE (all frames): 0.95139\n",
      "Epoch 121/200 - TrainLoss 0.6786 ValLoss 0.8535\n",
      "Val RMSE (all frames): 0.95127\n",
      " New best model found at epoch 121 with ValLoss 0.8535\n",
      "Epoch 122/200 - TrainLoss 0.6908 ValLoss 0.8534\n",
      "Val RMSE (all frames): 0.95125\n",
      " New best model found at epoch 122 with ValLoss 0.8534\n",
      "Epoch 123/200 - TrainLoss 0.6727 ValLoss 0.8542\n",
      "Val RMSE (all frames): 0.95168\n",
      "Epoch 124/200 - TrainLoss 0.6789 ValLoss 0.8541\n",
      "Val RMSE (all frames): 0.95167\n",
      "Epoch 125/200 - TrainLoss 0.6931 ValLoss 0.8553\n",
      "Val RMSE (all frames): 0.95222\n",
      "Epoch 126/200 - TrainLoss 0.6759 ValLoss 0.8541\n",
      "Val RMSE (all frames): 0.95167\n",
      "Epoch 127/200 - TrainLoss 0.6798 ValLoss 0.8543\n",
      "Val RMSE (all frames): 0.95181\n",
      "Epoch 128/200 - TrainLoss 0.6830 ValLoss 0.8546\n",
      "Val RMSE (all frames): 0.95192\n",
      "Epoch 129/200 - TrainLoss 0.6868 ValLoss 0.8546\n",
      "Val RMSE (all frames): 0.95191\n",
      "Epoch 130/200 - TrainLoss 0.6742 ValLoss 0.8546\n",
      "Val RMSE (all frames): 0.95191\n",
      "Epoch 131/200 - TrainLoss 0.6810 ValLoss 0.8549\n",
      "Val RMSE (all frames): 0.95206\n",
      "Epoch 132/200 - TrainLoss 0.6730 ValLoss 0.8546\n",
      "Val RMSE (all frames): 0.95192\n",
      "Epoch 133/200 - TrainLoss 0.6712 ValLoss 0.8548\n",
      "Val RMSE (all frames): 0.95203\n",
      "Epoch 134/200 - TrainLoss 0.6860 ValLoss 0.8550\n",
      "Val RMSE (all frames): 0.95209\n",
      "Epoch 135/200 - TrainLoss 0.6714 ValLoss 0.8549\n",
      "Val RMSE (all frames): 0.95206\n",
      "Epoch 136/200 - TrainLoss 0.6899 ValLoss 0.8543\n",
      "Val RMSE (all frames): 0.95173\n",
      "Epoch 137/200 - TrainLoss 0.6796 ValLoss 0.8542\n",
      "Val RMSE (all frames): 0.95174\n",
      "Epoch 138/200 - TrainLoss 0.6767 ValLoss 0.8541\n",
      "Val RMSE (all frames): 0.95168\n",
      "Epoch 139/200 - TrainLoss 0.6767 ValLoss 0.8544\n",
      "Val RMSE (all frames): 0.95183\n",
      "Epoch 140/200 - TrainLoss 0.6918 ValLoss 0.8543\n",
      "Val RMSE (all frames): 0.95175\n",
      "Epoch 141/200 - TrainLoss 0.6802 ValLoss 0.8540\n",
      "Val RMSE (all frames): 0.95160\n",
      "Epoch 142/200 - TrainLoss 0.6864 ValLoss 0.8540\n",
      "Val RMSE (all frames): 0.95158\n",
      "Epoch 143/200 - TrainLoss 0.6849 ValLoss 0.8538\n",
      "Val RMSE (all frames): 0.95149\n",
      "Epoch 144/200 - TrainLoss 0.6786 ValLoss 0.8539\n",
      "Val RMSE (all frames): 0.95154\n",
      "Epoch 145/200 - TrainLoss 0.6630 ValLoss 0.8539\n",
      "Val RMSE (all frames): 0.95153\n",
      "Epoch 146/200 - TrainLoss 0.6688 ValLoss 0.8538\n",
      "Val RMSE (all frames): 0.95149\n",
      "Epoch 147/200 - TrainLoss 0.6812 ValLoss 0.8539\n",
      "Val RMSE (all frames): 0.95152\n",
      "Epoch 148/200 - TrainLoss 0.6713 ValLoss 0.8539\n",
      "Val RMSE (all frames): 0.95151\n",
      "Epoch 149/200 - TrainLoss 0.6819 ValLoss 0.8537\n",
      "Val RMSE (all frames): 0.95144\n",
      "Epoch 150/200 - TrainLoss 0.6733 ValLoss 0.8537\n",
      "Val RMSE (all frames): 0.95145\n",
      "Epoch 151/200 - TrainLoss 0.6811 ValLoss 0.8537\n",
      "Val RMSE (all frames): 0.95142\n",
      "Epoch 152/200 - TrainLoss 0.6833 ValLoss 0.8537\n",
      "Val RMSE (all frames): 0.95144\n",
      "Early stopping epoch 152\n",
      "Scaler for fold 4 saved to 'fold_4/lstm_feature_scaler_fold.joblib'\n",
      "Model for fold 4 saved to 'fold_4/lstm_model_fold.pt'\n",
      "shape of oof_pred_fold: (113207, 3)\n",
      "\n",
      "--- Training Fold 5/5 ---\n",
      "Maximum output frames: 94\n",
      "Using device: cpu\n",
      "sucessfully moved model to device\n",
      "Epoch 1/200 - TrainLoss 7.3982 ValLoss 2.1960\n",
      "Val RMSE (all frames): 1.49267\n",
      " New best model found at epoch 1 with ValLoss 2.1960\n",
      "Epoch 2/200 - TrainLoss 2.4969 ValLoss 1.5116\n",
      "Val RMSE (all frames): 1.23905\n",
      " New best model found at epoch 2 with ValLoss 1.5116\n",
      "Epoch 3/200 - TrainLoss 1.9331 ValLoss 1.2001\n",
      "Val RMSE (all frames): 1.10411\n",
      " New best model found at epoch 3 with ValLoss 1.2001\n",
      "Epoch 4/200 - TrainLoss 1.6489 ValLoss 1.0540\n",
      "Val RMSE (all frames): 1.03533\n",
      " New best model found at epoch 4 with ValLoss 1.0540\n",
      "Epoch 5/200 - TrainLoss 1.5305 ValLoss 1.0402\n",
      "Val RMSE (all frames): 1.02813\n",
      " New best model found at epoch 5 with ValLoss 1.0402\n",
      "Epoch 6/200 - TrainLoss 1.4226 ValLoss 0.9882\n",
      "Val RMSE (all frames): 1.00265\n",
      " New best model found at epoch 6 with ValLoss 0.9882\n",
      "Epoch 7/200 - TrainLoss 1.3656 ValLoss 0.9547\n",
      "Val RMSE (all frames): 0.98564\n",
      " New best model found at epoch 7 with ValLoss 0.9547\n",
      "Epoch 8/200 - TrainLoss 1.3079 ValLoss 0.9190\n",
      "Val RMSE (all frames): 0.96718\n",
      " New best model found at epoch 8 with ValLoss 0.9190\n",
      "Epoch 9/200 - TrainLoss 1.2846 ValLoss 0.9017\n",
      "Val RMSE (all frames): 0.95784\n",
      " New best model found at epoch 9 with ValLoss 0.9017\n",
      "Epoch 10/200 - TrainLoss 1.2435 ValLoss 0.8726\n",
      "Val RMSE (all frames): 0.94272\n",
      " New best model found at epoch 10 with ValLoss 0.8726\n",
      "Epoch 11/200 - TrainLoss 1.2188 ValLoss 0.8117\n",
      "Val RMSE (all frames): 0.90943\n",
      " New best model found at epoch 11 with ValLoss 0.8117\n",
      "Epoch 12/200 - TrainLoss 1.1951 ValLoss 0.8411\n",
      "Val RMSE (all frames): 0.92508\n",
      "Epoch 13/200 - TrainLoss 1.1725 ValLoss 0.7941\n",
      "Val RMSE (all frames): 0.89897\n",
      " New best model found at epoch 13 with ValLoss 0.7941\n",
      "Epoch 14/200 - TrainLoss 1.1451 ValLoss 0.8252\n",
      "Val RMSE (all frames): 0.91648\n",
      "Epoch 15/200 - TrainLoss 1.1304 ValLoss 0.8137\n",
      "Val RMSE (all frames): 0.91042\n",
      "Epoch 16/200 - TrainLoss 1.1070 ValLoss 0.7598\n",
      "Val RMSE (all frames): 0.87975\n",
      " New best model found at epoch 16 with ValLoss 0.7598\n",
      "Epoch 17/200 - TrainLoss 1.1004 ValLoss 0.7391\n",
      "Val RMSE (all frames): 0.86709\n",
      " New best model found at epoch 17 with ValLoss 0.7391\n",
      "Epoch 18/200 - TrainLoss 1.0728 ValLoss 0.7486\n",
      "Val RMSE (all frames): 0.87292\n",
      "Epoch 19/200 - TrainLoss 1.0807 ValLoss 0.7590\n",
      "Val RMSE (all frames): 0.87935\n",
      "Epoch 20/200 - TrainLoss 1.0537 ValLoss 0.7418\n",
      "Val RMSE (all frames): 0.86925\n",
      "Epoch 21/200 - TrainLoss 1.0453 ValLoss 0.7700\n",
      "Val RMSE (all frames): 0.88556\n",
      "Epoch 22/200 - TrainLoss 1.0420 ValLoss 0.7318\n",
      "Val RMSE (all frames): 0.86314\n",
      " New best model found at epoch 22 with ValLoss 0.7318\n",
      "Epoch 23/200 - TrainLoss 1.0252 ValLoss 0.7271\n",
      "Val RMSE (all frames): 0.86023\n",
      " New best model found at epoch 23 with ValLoss 0.7271\n",
      "Epoch 24/200 - TrainLoss 1.0093 ValLoss 0.7273\n",
      "Val RMSE (all frames): 0.86053\n",
      "Epoch 25/200 - TrainLoss 0.9895 ValLoss 0.7158\n",
      "Val RMSE (all frames): 0.85378\n",
      " New best model found at epoch 25 with ValLoss 0.7158\n",
      "Epoch 26/200 - TrainLoss 0.9991 ValLoss 0.7272\n",
      "Val RMSE (all frames): 0.86088\n",
      "Epoch 27/200 - TrainLoss 0.9828 ValLoss 0.7055\n",
      "Val RMSE (all frames): 0.84792\n",
      " New best model found at epoch 27 with ValLoss 0.7055\n",
      "Epoch 28/200 - TrainLoss 0.9916 ValLoss 0.7040\n",
      "Val RMSE (all frames): 0.84659\n",
      " New best model found at epoch 28 with ValLoss 0.7040\n",
      "Epoch 29/200 - TrainLoss 0.9606 ValLoss 0.7068\n",
      "Val RMSE (all frames): 0.84879\n",
      "Epoch 30/200 - TrainLoss 0.9567 ValLoss 0.6864\n",
      "Val RMSE (all frames): 0.83624\n",
      " New best model found at epoch 30 with ValLoss 0.6864\n",
      "Epoch 31/200 - TrainLoss 0.9809 ValLoss 0.6899\n",
      "Val RMSE (all frames): 0.83804\n",
      "Epoch 32/200 - TrainLoss 0.9460 ValLoss 0.6931\n",
      "Val RMSE (all frames): 0.84037\n",
      "Epoch 33/200 - TrainLoss 0.9524 ValLoss 0.7142\n",
      "Val RMSE (all frames): 0.85232\n",
      "Epoch 34/200 - TrainLoss 0.9209 ValLoss 0.6917\n",
      "Val RMSE (all frames): 0.83908\n",
      "Epoch 35/200 - TrainLoss 0.9293 ValLoss 0.6921\n",
      "Val RMSE (all frames): 0.83969\n",
      "Epoch 36/200 - TrainLoss 0.9185 ValLoss 0.7128\n",
      "Val RMSE (all frames): 0.85225\n",
      "Epoch 37/200 - TrainLoss 0.8879 ValLoss 0.6507\n",
      "Val RMSE (all frames): 0.81430\n",
      " New best model found at epoch 37 with ValLoss 0.6507\n",
      "Epoch 38/200 - TrainLoss 0.8668 ValLoss 0.6575\n",
      "Val RMSE (all frames): 0.81861\n",
      "Epoch 39/200 - TrainLoss 0.8821 ValLoss 0.6461\n",
      "Val RMSE (all frames): 0.81127\n",
      " New best model found at epoch 39 with ValLoss 0.6461\n",
      "Epoch 40/200 - TrainLoss 0.8510 ValLoss 0.6490\n",
      "Val RMSE (all frames): 0.81338\n",
      "Epoch 41/200 - TrainLoss 0.8479 ValLoss 0.6467\n",
      "Val RMSE (all frames): 0.81177\n",
      "Epoch 42/200 - TrainLoss 0.8329 ValLoss 0.6488\n",
      "Val RMSE (all frames): 0.81299\n",
      "Epoch 43/200 - TrainLoss 0.8380 ValLoss 0.6302\n",
      "Val RMSE (all frames): 0.80125\n",
      " New best model found at epoch 43 with ValLoss 0.6302\n",
      "Epoch 44/200 - TrainLoss 0.8335 ValLoss 0.6246\n",
      "Val RMSE (all frames): 0.79761\n",
      " New best model found at epoch 44 with ValLoss 0.6246\n",
      "Epoch 45/200 - TrainLoss 0.8349 ValLoss 0.6351\n",
      "Val RMSE (all frames): 0.80445\n",
      "Epoch 46/200 - TrainLoss 0.8153 ValLoss 0.6429\n",
      "Val RMSE (all frames): 0.80953\n",
      "Epoch 47/200 - TrainLoss 0.8158 ValLoss 0.6244\n",
      "Val RMSE (all frames): 0.79782\n",
      " New best model found at epoch 47 with ValLoss 0.6244\n",
      "Epoch 48/200 - TrainLoss 0.8191 ValLoss 0.6165\n",
      "Val RMSE (all frames): 0.79297\n",
      " New best model found at epoch 48 with ValLoss 0.6165\n",
      "Epoch 49/200 - TrainLoss 0.8245 ValLoss 0.6119\n",
      "Val RMSE (all frames): 0.78978\n",
      " New best model found at epoch 49 with ValLoss 0.6119\n",
      "Epoch 50/200 - TrainLoss 0.8126 ValLoss 0.6168\n",
      "Val RMSE (all frames): 0.79275\n",
      "Epoch 51/200 - TrainLoss 0.8250 ValLoss 0.6187\n",
      "Val RMSE (all frames): 0.79421\n",
      "Epoch 52/200 - TrainLoss 0.8003 ValLoss 0.6302\n",
      "Val RMSE (all frames): 0.80136\n",
      "Epoch 53/200 - TrainLoss 0.8138 ValLoss 0.6170\n",
      "Val RMSE (all frames): 0.79310\n",
      "Epoch 54/200 - TrainLoss 0.8037 ValLoss 0.6207\n",
      "Val RMSE (all frames): 0.79534\n",
      "Epoch 55/200 - TrainLoss 0.8088 ValLoss 0.6059\n",
      "Val RMSE (all frames): 0.78582\n",
      " New best model found at epoch 55 with ValLoss 0.6059\n",
      "Epoch 56/200 - TrainLoss 0.7931 ValLoss 0.6121\n",
      "Val RMSE (all frames): 0.79017\n",
      "Epoch 57/200 - TrainLoss 0.7841 ValLoss 0.6155\n",
      "Val RMSE (all frames): 0.79245\n",
      "Epoch 58/200 - TrainLoss 0.7892 ValLoss 0.6077\n",
      "Val RMSE (all frames): 0.78700\n",
      "Epoch 59/200 - TrainLoss 0.7741 ValLoss 0.5998\n",
      "Val RMSE (all frames): 0.78204\n",
      " New best model found at epoch 59 with ValLoss 0.5998\n",
      "Epoch 60/200 - TrainLoss 0.7813 ValLoss 0.6073\n",
      "Val RMSE (all frames): 0.78696\n",
      "Epoch 61/200 - TrainLoss 0.7701 ValLoss 0.6060\n",
      "Val RMSE (all frames): 0.78607\n",
      "Epoch 62/200 - TrainLoss 0.7712 ValLoss 0.5928\n",
      "Val RMSE (all frames): 0.77706\n",
      " New best model found at epoch 62 with ValLoss 0.5928\n",
      "Epoch 63/200 - TrainLoss 0.7745 ValLoss 0.6109\n",
      "Val RMSE (all frames): 0.78914\n",
      "Epoch 64/200 - TrainLoss 0.7581 ValLoss 0.6086\n",
      "Val RMSE (all frames): 0.78751\n",
      "Epoch 65/200 - TrainLoss 0.7735 ValLoss 0.6114\n",
      "Val RMSE (all frames): 0.78968\n",
      "Epoch 66/200 - TrainLoss 0.7775 ValLoss 0.5932\n",
      "Val RMSE (all frames): 0.77764\n",
      "Epoch 67/200 - TrainLoss 0.7462 ValLoss 0.5783\n",
      "Val RMSE (all frames): 0.76756\n",
      " New best model found at epoch 67 with ValLoss 0.5783\n",
      "Epoch 68/200 - TrainLoss 0.7725 ValLoss 0.5912\n",
      "Val RMSE (all frames): 0.77634\n",
      "Epoch 69/200 - TrainLoss 0.7650 ValLoss 0.6102\n",
      "Val RMSE (all frames): 0.78876\n",
      "Epoch 70/200 - TrainLoss 0.7507 ValLoss 0.5984\n",
      "Val RMSE (all frames): 0.78090\n",
      "Epoch 71/200 - TrainLoss 0.7417 ValLoss 0.5952\n",
      "Val RMSE (all frames): 0.77899\n",
      "Epoch 72/200 - TrainLoss 0.7386 ValLoss 0.6002\n",
      "Val RMSE (all frames): 0.78226\n",
      "Epoch 73/200 - TrainLoss 0.7422 ValLoss 0.5878\n",
      "Val RMSE (all frames): 0.77364\n",
      "Epoch 74/200 - TrainLoss 0.7170 ValLoss 0.5876\n",
      "Val RMSE (all frames): 0.77396\n",
      "Epoch 75/200 - TrainLoss 0.7235 ValLoss 0.5853\n",
      "Val RMSE (all frames): 0.77206\n",
      "Epoch 76/200 - TrainLoss 0.7197 ValLoss 0.5826\n",
      "Val RMSE (all frames): 0.77076\n",
      "Epoch 77/200 - TrainLoss 0.7205 ValLoss 0.5844\n",
      "Val RMSE (all frames): 0.77203\n",
      "Epoch 78/200 - TrainLoss 0.7202 ValLoss 0.5840\n",
      "Val RMSE (all frames): 0.77154\n",
      "Epoch 79/200 - TrainLoss 0.7277 ValLoss 0.5767\n",
      "Val RMSE (all frames): 0.76675\n",
      " New best model found at epoch 79 with ValLoss 0.5767\n",
      "Epoch 80/200 - TrainLoss 0.7140 ValLoss 0.5825\n",
      "Val RMSE (all frames): 0.77062\n",
      "Epoch 81/200 - TrainLoss 0.7046 ValLoss 0.5790\n",
      "Val RMSE (all frames): 0.76839\n",
      "Epoch 82/200 - TrainLoss 0.7074 ValLoss 0.5734\n",
      "Val RMSE (all frames): 0.76460\n",
      " New best model found at epoch 82 with ValLoss 0.5734\n",
      "Epoch 83/200 - TrainLoss 0.7155 ValLoss 0.5763\n",
      "Val RMSE (all frames): 0.76689\n",
      "Epoch 84/200 - TrainLoss 0.7004 ValLoss 0.5792\n",
      "Val RMSE (all frames): 0.76835\n",
      "Epoch 85/200 - TrainLoss 0.7120 ValLoss 0.5824\n",
      "Val RMSE (all frames): 0.77046\n",
      "Epoch 86/200 - TrainLoss 0.7066 ValLoss 0.5789\n",
      "Val RMSE (all frames): 0.76826\n",
      "Epoch 87/200 - TrainLoss 0.6997 ValLoss 0.5810\n",
      "Val RMSE (all frames): 0.76981\n",
      "Epoch 88/200 - TrainLoss 0.6992 ValLoss 0.5866\n",
      "Val RMSE (all frames): 0.77335\n",
      "Epoch 89/200 - TrainLoss 0.6913 ValLoss 0.5718\n",
      "Val RMSE (all frames): 0.76367\n",
      " New best model found at epoch 89 with ValLoss 0.5718\n",
      "Epoch 90/200 - TrainLoss 0.6866 ValLoss 0.5749\n",
      "Val RMSE (all frames): 0.76565\n",
      "Epoch 91/200 - TrainLoss 0.6948 ValLoss 0.5691\n",
      "Val RMSE (all frames): 0.76167\n",
      " New best model found at epoch 91 with ValLoss 0.5691\n",
      "Epoch 92/200 - TrainLoss 0.6969 ValLoss 0.5716\n",
      "Val RMSE (all frames): 0.76337\n",
      "Epoch 93/200 - TrainLoss 0.6980 ValLoss 0.5668\n",
      "Val RMSE (all frames): 0.76029\n",
      " New best model found at epoch 93 with ValLoss 0.5668\n",
      "Epoch 94/200 - TrainLoss 0.6829 ValLoss 0.5692\n",
      "Val RMSE (all frames): 0.76165\n",
      "Epoch 95/200 - TrainLoss 0.6828 ValLoss 0.5699\n",
      "Val RMSE (all frames): 0.76229\n",
      "Epoch 96/200 - TrainLoss 0.6889 ValLoss 0.5731\n",
      "Val RMSE (all frames): 0.76453\n",
      "Epoch 97/200 - TrainLoss 0.6791 ValLoss 0.5685\n",
      "Val RMSE (all frames): 0.76140\n",
      "Epoch 98/200 - TrainLoss 0.6794 ValLoss 0.5668\n",
      "Val RMSE (all frames): 0.76025\n",
      "Epoch 99/200 - TrainLoss 0.6797 ValLoss 0.5745\n",
      "Val RMSE (all frames): 0.76537\n",
      "Epoch 100/200 - TrainLoss 0.6725 ValLoss 0.5675\n",
      "Val RMSE (all frames): 0.76072\n",
      "Epoch 101/200 - TrainLoss 0.6697 ValLoss 0.5658\n",
      "Val RMSE (all frames): 0.75957\n",
      " New best model found at epoch 101 with ValLoss 0.5658\n",
      "Epoch 102/200 - TrainLoss 0.6768 ValLoss 0.5609\n",
      "Val RMSE (all frames): 0.75627\n",
      " New best model found at epoch 102 with ValLoss 0.5609\n",
      "Epoch 103/200 - TrainLoss 0.6748 ValLoss 0.5669\n",
      "Val RMSE (all frames): 0.76041\n",
      "Epoch 104/200 - TrainLoss 0.6753 ValLoss 0.5662\n",
      "Val RMSE (all frames): 0.76000\n",
      "Epoch 105/200 - TrainLoss 0.6638 ValLoss 0.5618\n",
      "Val RMSE (all frames): 0.75704\n",
      "Epoch 106/200 - TrainLoss 0.6723 ValLoss 0.5649\n",
      "Val RMSE (all frames): 0.75905\n",
      "Epoch 107/200 - TrainLoss 0.6751 ValLoss 0.5634\n",
      "Val RMSE (all frames): 0.75813\n",
      "Epoch 108/200 - TrainLoss 0.6657 ValLoss 0.5670\n",
      "Val RMSE (all frames): 0.76051\n",
      "Epoch 109/200 - TrainLoss 0.6787 ValLoss 0.5641\n",
      "Val RMSE (all frames): 0.75863\n",
      "Epoch 110/200 - TrainLoss 0.6582 ValLoss 0.5624\n",
      "Val RMSE (all frames): 0.75745\n",
      "Epoch 111/200 - TrainLoss 0.6622 ValLoss 0.5619\n",
      "Val RMSE (all frames): 0.75704\n",
      "Epoch 112/200 - TrainLoss 0.6606 ValLoss 0.5645\n",
      "Val RMSE (all frames): 0.75880\n",
      "Epoch 113/200 - TrainLoss 0.6623 ValLoss 0.5648\n",
      "Val RMSE (all frames): 0.75915\n",
      "Epoch 114/200 - TrainLoss 0.6649 ValLoss 0.5611\n",
      "Val RMSE (all frames): 0.75650\n",
      "Epoch 115/200 - TrainLoss 0.6704 ValLoss 0.5609\n",
      "Val RMSE (all frames): 0.75635\n",
      " New best model found at epoch 115 with ValLoss 0.5609\n",
      "Epoch 116/200 - TrainLoss 0.6749 ValLoss 0.5628\n",
      "Val RMSE (all frames): 0.75766\n",
      "Epoch 117/200 - TrainLoss 0.6639 ValLoss 0.5612\n",
      "Val RMSE (all frames): 0.75657\n",
      "Epoch 118/200 - TrainLoss 0.6629 ValLoss 0.5613\n",
      "Val RMSE (all frames): 0.75665\n",
      "Epoch 119/200 - TrainLoss 0.6761 ValLoss 0.5614\n",
      "Val RMSE (all frames): 0.75667\n",
      "Epoch 120/200 - TrainLoss 0.6614 ValLoss 0.5624\n",
      "Val RMSE (all frames): 0.75736\n",
      "Epoch 121/200 - TrainLoss 0.6654 ValLoss 0.5613\n",
      "Val RMSE (all frames): 0.75662\n",
      "Epoch 122/200 - TrainLoss 0.6645 ValLoss 0.5616\n",
      "Val RMSE (all frames): 0.75686\n",
      "Epoch 123/200 - TrainLoss 0.6729 ValLoss 0.5615\n",
      "Val RMSE (all frames): 0.75680\n",
      "Epoch 124/200 - TrainLoss 0.6521 ValLoss 0.5605\n",
      "Val RMSE (all frames): 0.75609\n",
      " New best model found at epoch 124 with ValLoss 0.5605\n",
      "Epoch 125/200 - TrainLoss 0.6629 ValLoss 0.5612\n",
      "Val RMSE (all frames): 0.75660\n",
      "Epoch 126/200 - TrainLoss 0.6653 ValLoss 0.5611\n",
      "Val RMSE (all frames): 0.75652\n",
      "Epoch 127/200 - TrainLoss 0.6644 ValLoss 0.5612\n",
      "Val RMSE (all frames): 0.75659\n",
      "Epoch 128/200 - TrainLoss 0.6671 ValLoss 0.5612\n",
      "Val RMSE (all frames): 0.75660\n",
      "Epoch 129/200 - TrainLoss 0.6767 ValLoss 0.5607\n",
      "Val RMSE (all frames): 0.75626\n",
      "Epoch 130/200 - TrainLoss 0.6745 ValLoss 0.5603\n",
      "Val RMSE (all frames): 0.75599\n",
      " New best model found at epoch 130 with ValLoss 0.5603\n",
      "Epoch 131/200 - TrainLoss 0.6707 ValLoss 0.5606\n",
      "Val RMSE (all frames): 0.75619\n",
      "Epoch 132/200 - TrainLoss 0.6576 ValLoss 0.5604\n",
      "Val RMSE (all frames): 0.75601\n",
      "Epoch 133/200 - TrainLoss 0.6615 ValLoss 0.5607\n",
      "Val RMSE (all frames): 0.75624\n",
      "Epoch 134/200 - TrainLoss 0.6748 ValLoss 0.5613\n",
      "Val RMSE (all frames): 0.75666\n",
      "Epoch 135/200 - TrainLoss 0.6566 ValLoss 0.5614\n",
      "Val RMSE (all frames): 0.75673\n",
      "Epoch 136/200 - TrainLoss 0.6574 ValLoss 0.5611\n",
      "Val RMSE (all frames): 0.75657\n",
      "Epoch 137/200 - TrainLoss 0.6652 ValLoss 0.5614\n",
      "Val RMSE (all frames): 0.75676\n",
      "Epoch 138/200 - TrainLoss 0.6637 ValLoss 0.5619\n",
      "Val RMSE (all frames): 0.75704\n",
      "Epoch 139/200 - TrainLoss 0.6595 ValLoss 0.5621\n",
      "Val RMSE (all frames): 0.75721\n",
      "Epoch 140/200 - TrainLoss 0.6665 ValLoss 0.5618\n",
      "Val RMSE (all frames): 0.75700\n",
      "Epoch 141/200 - TrainLoss 0.6630 ValLoss 0.5619\n",
      "Val RMSE (all frames): 0.75707\n",
      "Epoch 142/200 - TrainLoss 0.6663 ValLoss 0.5616\n",
      "Val RMSE (all frames): 0.75685\n",
      "Epoch 143/200 - TrainLoss 0.6733 ValLoss 0.5615\n",
      "Val RMSE (all frames): 0.75682\n",
      "Epoch 144/200 - TrainLoss 0.6579 ValLoss 0.5613\n",
      "Val RMSE (all frames): 0.75668\n",
      "Epoch 145/200 - TrainLoss 0.6642 ValLoss 0.5616\n",
      "Val RMSE (all frames): 0.75686\n",
      "Epoch 146/200 - TrainLoss 0.6593 ValLoss 0.5612\n",
      "Val RMSE (all frames): 0.75660\n",
      "Epoch 147/200 - TrainLoss 0.6664 ValLoss 0.5612\n",
      "Val RMSE (all frames): 0.75660\n",
      "Epoch 148/200 - TrainLoss 0.6749 ValLoss 0.5610\n",
      "Val RMSE (all frames): 0.75650\n",
      "Epoch 149/200 - TrainLoss 0.6590 ValLoss 0.5611\n",
      "Val RMSE (all frames): 0.75655\n",
      "Epoch 150/200 - TrainLoss 0.6570 ValLoss 0.5612\n",
      "Val RMSE (all frames): 0.75660\n",
      "Epoch 151/200 - TrainLoss 0.6668 ValLoss 0.5611\n",
      "Val RMSE (all frames): 0.75654\n",
      "Epoch 152/200 - TrainLoss 0.6717 ValLoss 0.5611\n",
      "Val RMSE (all frames): 0.75656\n",
      "Epoch 153/200 - TrainLoss 0.6722 ValLoss 0.5610\n",
      "Val RMSE (all frames): 0.75643\n",
      "Epoch 154/200 - TrainLoss 0.6712 ValLoss 0.5609\n",
      "Val RMSE (all frames): 0.75642\n",
      "Epoch 155/200 - TrainLoss 0.6604 ValLoss 0.5609\n",
      "Val RMSE (all frames): 0.75637\n",
      "Epoch 156/200 - TrainLoss 0.6722 ValLoss 0.5608\n",
      "Val RMSE (all frames): 0.75630\n",
      "Epoch 157/200 - TrainLoss 0.6594 ValLoss 0.5607\n",
      "Val RMSE (all frames): 0.75628\n",
      "Epoch 158/200 - TrainLoss 0.6668 ValLoss 0.5607\n",
      "Val RMSE (all frames): 0.75628\n",
      "Epoch 159/200 - TrainLoss 0.6712 ValLoss 0.5607\n",
      "Val RMSE (all frames): 0.75628\n",
      "Epoch 160/200 - TrainLoss 0.6599 ValLoss 0.5608\n",
      "Val RMSE (all frames): 0.75633\n",
      "Early stopping epoch 160\n",
      "Scaler for fold 5 saved to 'fold_5/lstm_feature_scaler_fold.joblib'\n",
      "Model for fold 5 saved to 'fold_5/lstm_model_fold.pt'\n",
      "shape of oof_pred_fold: (112586, 3)\n",
      "OOF predictions example:\n",
      "                        id          x          y\n",
      "0  2023090700_1300_55876_1  39.040442  15.897775\n",
      "1  2023090700_1300_55876_2  38.847175  15.358525\n",
      "2  2023090700_1300_55876_3  38.661019  14.805094\n",
      "3  2023090700_1300_55876_4  38.483101  14.241280\n",
      "4  2023090700_1300_55876_5  38.314150  13.671270\n",
      "OOF truth example:\n",
      "                        id      x      y\n",
      "0  2023090700_1300_55876_1  38.97  15.85\n",
      "1  2023090700_1300_55876_2  38.73  15.27\n",
      "2  2023090700_1300_55876_3  38.52  14.68\n",
      "3  2023090700_1300_55876_4  38.34  14.08\n",
      "4  2023090700_1300_55876_5  38.18  13.46\n",
      "\n",
      "OOF predictions shape: (562936, 3), OOF truth shape: (562936, 3)\n",
      "\n",
      "--- Multi-Fold Training Summary ---\n",
      "Fold 1: 0.76560\n",
      "Fold 2: 0.68442\n",
      "Fold 3: 0.71675\n",
      "Fold 4: 0.95125\n",
      "Fold 5: 0.75599\n",
      "Mean Single-Model Fold Score: 0.77480 ± 0.09286\n",
      "OOF CV Score: 0.78097\n"
     ]
    }
   ],
   "source": [
    "models,scores,scalers,ensemble_score,oof_pred_df=run_multi_fold_training(sequences, targets_dx, targets_dy,targets_frame_ids, ids,n_folds=Config.N_FOLDS,epochs=Config.EPOCHS,patience=Config.PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b186f7",
   "metadata": {
    "papermill": {
     "duration": 0.212396,
     "end_time": "2025-10-06T20:14:13.976897",
     "exception": false,
     "start_time": "2025-10-06T20:14:13.764501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a2aa606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T20:14:14.508204Z",
     "iopub.status.busy": "2025-10-06T20:14:14.506810Z",
     "iopub.status.idle": "2025-10-06T20:14:17.095852Z",
     "shell.execute_reply": "2025-10-06T20:14:17.094292Z"
    },
    "papermill": {
     "duration": 2.904284,
     "end_time": "2025-10-06T20:14:17.097492",
     "exception": false,
     "start_time": "2025-10-06T20:14:14.193208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing sequences for LSTM...\n",
      "Using window size =  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [00:00<00:00, 495.06it/s]\n"
     ]
    }
   ],
   "source": [
    "test_sequences, test_seq_ids = prepare_sequences_for_lstm(test_input,test_template=test_template,is_training=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddd280e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T20:14:17.596188Z",
     "iopub.status.busy": "2025-10-06T20:14:17.595830Z",
     "iopub.status.idle": "2025-10-06T20:14:17.605910Z",
     "shell.execute_reply": "2025-10-06T20:14:17.603848Z"
    },
    "papermill": {
     "duration": 0.275901,
     "end_time": "2025-10-06T20:14:17.608206",
     "exception": false,
     "start_time": "2025-10-06T20:14:17.332305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472, 472)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sequences), len(test_seq_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5acef43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T20:14:18.062704Z",
     "iopub.status.busy": "2025-10-06T20:14:18.062280Z",
     "iopub.status.idle": "2025-10-06T20:14:18.117398Z",
     "shell.execute_reply": "2025-10-06T20:14:18.116143Z"
    },
    "papermill": {
     "duration": 0.281212,
     "end_time": "2025-10-06T20:14:18.119141",
     "exception": false,
     "start_time": "2025-10-06T20:14:17.837929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fold 1 from checkpoint with config...\n",
      "Loaded fold 1 (hidden=128, layers=2, max_out=94)\n",
      "Loaded scaler for fold 1\n",
      "Loading fold 2 from checkpoint with config...\n",
      "Loaded fold 2 (hidden=128, layers=2, max_out=94)\n",
      "Loaded scaler for fold 2\n",
      "Loading fold 3 from checkpoint with config...\n",
      "Loaded fold 3 (hidden=128, layers=2, max_out=94)\n",
      "Loaded scaler for fold 3\n",
      "Loading fold 4 from checkpoint with config...\n",
      "Loaded fold 4 (hidden=128, layers=2, max_out=94)\n",
      "Loaded scaler for fold 4\n",
      "Loading fold 5 from checkpoint with config...\n",
      "Loaded fold 5 (hidden=128, layers=2, max_out=94)\n",
      "Loaded scaler for fold 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of making ensemble predictions:\n",
    "loaded_models, scalers = load_trained_models(\n",
    "    num_models=Config.N_FOLDS,\n",
    "    input_dim=sequences.shape[-1],\n",
    "    # max_frames_output=targets_dx[0].shape[0]\n",
    "    max_frames_output=94,\n",
    "    models_dir=Config.PRETRAIN_DIR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d24bc846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T20:14:18.561950Z",
     "iopub.status.busy": "2025-10-06T20:14:18.561623Z",
     "iopub.status.idle": "2025-10-06T20:14:19.374680Z",
     "shell.execute_reply": "2025-10-06T20:14:19.373489Z"
    },
    "papermill": {
     "duration": 1.040057,
     "end_time": "2025-10-06T20:14:19.376521",
     "exception": false,
     "start_time": "2025-10-06T20:14:18.336464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble predictions saved to 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ensemble_submission = create_ensemble_predictions(\n",
    "    models=loaded_models,\n",
    "    scalers=scalers,                 # previously returned\n",
    "    X_test_unscaled=test_sequences,\n",
    "    test_seq_ids=test_seq_ids,\n",
    "    test_template=test_template,\n",
    ")\n",
    "ensemble_submission.to_csv('submission.csv', index=False)\n",
    "print(\"Ensemble predictions saved to 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7c3748d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T20:14:19.816265Z",
     "iopub.status.busy": "2025-10-06T20:14:19.815934Z",
     "iopub.status.idle": "2025-10-06T20:14:19.836849Z",
     "shell.execute_reply": "2025-10-06T20:14:19.835775Z"
    },
    "papermill": {
     "duration": 0.248346,
     "end_time": "2025-10-06T20:14:19.838693",
     "exception": false,
     "start_time": "2025-10-06T20:14:19.590347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024120805_74_54586_1</td>\n",
       "      <td>88.415390</td>\n",
       "      <td>34.348167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024120805_74_54586_2</td>\n",
       "      <td>88.771545</td>\n",
       "      <td>34.416477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024120805_74_54586_3</td>\n",
       "      <td>89.126511</td>\n",
       "      <td>34.526451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024120805_74_54586_4</td>\n",
       "      <td>89.477997</td>\n",
       "      <td>34.679218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024120805_74_54586_5</td>\n",
       "      <td>89.824234</td>\n",
       "      <td>34.874180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>2025010515_3902_55112_26</td>\n",
       "      <td>99.588326</td>\n",
       "      <td>28.182251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>2025010515_3902_55112_27</td>\n",
       "      <td>100.341484</td>\n",
       "      <td>28.585392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>2025010515_3902_55112_28</td>\n",
       "      <td>101.006310</td>\n",
       "      <td>29.088970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>2025010515_3902_55112_29</td>\n",
       "      <td>101.655327</td>\n",
       "      <td>29.399042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>2025010515_3902_55112_30</td>\n",
       "      <td>102.131905</td>\n",
       "      <td>29.339214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5837 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id           x          y\n",
       "0        2024120805_74_54586_1   88.415390  34.348167\n",
       "1        2024120805_74_54586_2   88.771545  34.416477\n",
       "2        2024120805_74_54586_3   89.126511  34.526451\n",
       "3        2024120805_74_54586_4   89.477997  34.679218\n",
       "4        2024120805_74_54586_5   89.824234  34.874180\n",
       "...                        ...         ...        ...\n",
       "5832  2025010515_3902_55112_26   99.588326  28.182251\n",
       "5833  2025010515_3902_55112_27  100.341484  28.585392\n",
       "5834  2025010515_3902_55112_28  101.006310  29.088970\n",
       "5835  2025010515_3902_55112_29  101.655327  29.399042\n",
       "5836  2025010515_3902_55112_30  102.131905  29.339214\n",
       "\n",
       "[5837 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13825858,
     "sourceId": 114239,
     "sourceType": "competition"
    },
    {
     "sourceId": 265179171,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7488.70716,
   "end_time": "2025-10-06T20:14:22.805124",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-06T18:09:34.097964",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
